[2022-04-07 17:34:14,622] {processor.py:163} INFO - Started process (PID=196) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:34:14,634] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:34:14,636] {logging_mixin.py:109} INFO - [2022-04-07 17:34:14,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:34:17,431] {logging_mixin.py:109} INFO - [2022-04-07 17:34:17,429] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:34:17,431] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:34:17,453] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 2.836 seconds
[2022-04-07 17:34:47,616] {processor.py:163} INFO - Started process (PID=223) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:34:47,623] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:34:47,626] {logging_mixin.py:109} INFO - [2022-04-07 17:34:47,626] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:34:49,925] {logging_mixin.py:109} INFO - [2022-04-07 17:34:49,920] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:34:49,927] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:34:49,997] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 2.395 seconds
[2022-04-07 17:35:20,148] {processor.py:163} INFO - Started process (PID=263) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:35:20,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:35:20,152] {logging_mixin.py:109} INFO - [2022-04-07 17:35:20,152] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:35:21,127] {logging_mixin.py:109} INFO - [2022-04-07 17:35:21,126] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:35:21,128] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:35:21,149] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 17:35:51,267] {processor.py:163} INFO - Started process (PID=293) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:35:51,273] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:35:51,274] {logging_mixin.py:109} INFO - [2022-04-07 17:35:51,274] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:35:52,113] {logging_mixin.py:109} INFO - [2022-04-07 17:35:52,111] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:35:52,113] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:35:52,135] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.874 seconds
[2022-04-07 17:36:22,245] {processor.py:163} INFO - Started process (PID=331) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:36:22,246] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:36:22,247] {logging_mixin.py:109} INFO - [2022-04-07 17:36:22,247] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:36:23,189] {logging_mixin.py:109} INFO - [2022-04-07 17:36:23,186] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:36:23,189] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:36:23,215] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.975 seconds
[2022-04-07 17:36:53,312] {processor.py:163} INFO - Started process (PID=361) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:36:53,315] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:36:53,316] {logging_mixin.py:109} INFO - [2022-04-07 17:36:53,315] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:36:54,162] {logging_mixin.py:109} INFO - [2022-04-07 17:36:54,161] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:36:54,163] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:36:54,185] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.878 seconds
[2022-04-07 17:37:24,304] {processor.py:163} INFO - Started process (PID=398) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:37:24,306] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:37:24,307] {logging_mixin.py:109} INFO - [2022-04-07 17:37:24,307] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:37:25,221] {logging_mixin.py:109} INFO - [2022-04-07 17:37:25,220] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:37:25,222] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:37:25,246] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 17:37:55,346] {processor.py:163} INFO - Started process (PID=426) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:37:55,348] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:37:55,349] {logging_mixin.py:109} INFO - [2022-04-07 17:37:55,349] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:37:56,194] {logging_mixin.py:109} INFO - [2022-04-07 17:37:56,193] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:37:56,195] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:37:56,217] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.877 seconds
[2022-04-07 17:38:26,323] {processor.py:163} INFO - Started process (PID=469) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:38:26,329] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:38:26,331] {logging_mixin.py:109} INFO - [2022-04-07 17:38:26,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:38:27,235] {logging_mixin.py:109} INFO - [2022-04-07 17:38:27,233] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:38:27,236] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:38:27,258] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.941 seconds
[2022-04-07 17:38:57,361] {processor.py:163} INFO - Started process (PID=497) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:38:57,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:38:57,364] {logging_mixin.py:109} INFO - [2022-04-07 17:38:57,364] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:38:58,705] {logging_mixin.py:109} INFO - [2022-04-07 17:38:58,703] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:38:58,706] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:38:58,746] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.391 seconds
[2022-04-07 17:39:28,893] {processor.py:163} INFO - Started process (PID=525) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:39:28,895] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:39:28,896] {logging_mixin.py:109} INFO - [2022-04-07 17:39:28,896] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:39:29,995] {logging_mixin.py:109} INFO - [2022-04-07 17:39:29,993] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:39:29,995] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:39:30,031] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.143 seconds
[2022-04-07 17:40:00,139] {processor.py:163} INFO - Started process (PID=563) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:40:00,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:40:00,142] {logging_mixin.py:109} INFO - [2022-04-07 17:40:00,141] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:40:00,975] {logging_mixin.py:109} INFO - [2022-04-07 17:40:00,973] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:40:00,976] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:40:01,002] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.869 seconds
[2022-04-07 17:40:31,119] {processor.py:163} INFO - Started process (PID=591) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:40:31,121] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:40:31,122] {logging_mixin.py:109} INFO - [2022-04-07 17:40:31,122] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:40:31,994] {logging_mixin.py:109} INFO - [2022-04-07 17:40:31,991] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:40:31,995] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:40:32,024] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.910 seconds
[2022-04-07 17:41:02,133] {processor.py:163} INFO - Started process (PID=631) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:41:02,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:41:02,137] {logging_mixin.py:109} INFO - [2022-04-07 17:41:02,137] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:41:02,949] {logging_mixin.py:109} INFO - [2022-04-07 17:41:02,948] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:41:02,950] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:41:02,972] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.844 seconds
[2022-04-07 17:41:33,075] {processor.py:163} INFO - Started process (PID=658) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:41:33,077] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:41:33,078] {logging_mixin.py:109} INFO - [2022-04-07 17:41:33,078] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:41:33,956] {logging_mixin.py:109} INFO - [2022-04-07 17:41:33,954] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:41:33,957] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:41:34,082] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.012 seconds
[2022-04-07 17:42:04,196] {processor.py:163} INFO - Started process (PID=696) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:42:04,198] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:42:04,199] {logging_mixin.py:109} INFO - [2022-04-07 17:42:04,199] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:42:05,020] {logging_mixin.py:109} INFO - [2022-04-07 17:42:05,018] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:42:05,021] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:42:05,145] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.954 seconds
[2022-04-07 17:42:35,296] {processor.py:163} INFO - Started process (PID=724) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:42:35,299] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:42:35,300] {logging_mixin.py:109} INFO - [2022-04-07 17:42:35,300] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:42:36,170] {logging_mixin.py:109} INFO - [2022-04-07 17:42:36,169] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:42:36,171] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:42:36,320] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.029 seconds
[2022-04-07 17:43:06,417] {processor.py:163} INFO - Started process (PID=763) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:43:06,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:43:06,419] {logging_mixin.py:109} INFO - [2022-04-07 17:43:06,419] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:43:07,406] {logging_mixin.py:109} INFO - [2022-04-07 17:43:07,404] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:43:07,407] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:43:07,431] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.019 seconds
[2022-04-07 17:43:37,549] {processor.py:163} INFO - Started process (PID=791) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:43:37,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:43:37,553] {logging_mixin.py:109} INFO - [2022-04-07 17:43:37,553] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:43:38,575] {logging_mixin.py:109} INFO - [2022-04-07 17:43:38,574] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:43:38,576] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:43:38,604] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.060 seconds
[2022-04-07 17:44:08,738] {processor.py:163} INFO - Started process (PID=832) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:44:08,741] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:44:08,742] {logging_mixin.py:109} INFO - [2022-04-07 17:44:08,741] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:44:09,770] {logging_mixin.py:109} INFO - [2022-04-07 17:44:09,769] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:44:09,771] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:44:09,794] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.062 seconds
[2022-04-07 17:44:39,846] {processor.py:163} INFO - Started process (PID=861) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:44:39,849] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:44:39,850] {logging_mixin.py:109} INFO - [2022-04-07 17:44:39,850] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:44:40,843] {logging_mixin.py:109} INFO - [2022-04-07 17:44:40,842] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:44:40,844] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:44:40,865] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 17:45:11,011] {processor.py:163} INFO - Started process (PID=900) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:45:11,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:45:11,014] {logging_mixin.py:109} INFO - [2022-04-07 17:45:11,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:45:11,979] {logging_mixin.py:109} INFO - [2022-04-07 17:45:11,977] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:45:11,979] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:45:12,001] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.995 seconds
[2022-04-07 17:45:42,139] {processor.py:163} INFO - Started process (PID=929) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:45:42,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:45:42,142] {logging_mixin.py:109} INFO - [2022-04-07 17:45:42,142] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:45:43,097] {logging_mixin.py:109} INFO - [2022-04-07 17:45:43,095] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:45:43,098] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:45:43,121] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.986 seconds
[2022-04-07 17:46:13,262] {processor.py:163} INFO - Started process (PID=968) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:46:13,264] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:46:13,265] {logging_mixin.py:109} INFO - [2022-04-07 17:46:13,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:46:14,258] {logging_mixin.py:109} INFO - [2022-04-07 17:46:14,257] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:46:14,259] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:46:14,281] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 17:46:44,407] {processor.py:163} INFO - Started process (PID=999) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:46:44,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:46:44,410] {logging_mixin.py:109} INFO - [2022-04-07 17:46:44,409] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:46:45,383] {logging_mixin.py:109} INFO - [2022-04-07 17:46:45,381] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:46:45,383] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:46:45,410] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.008 seconds
[2022-04-07 17:47:15,542] {processor.py:163} INFO - Started process (PID=1038) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:47:15,546] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:47:15,547] {logging_mixin.py:109} INFO - [2022-04-07 17:47:15,547] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:47:16,494] {logging_mixin.py:109} INFO - [2022-04-07 17:47:16,492] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:47:16,494] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:47:16,517] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.980 seconds
[2022-04-07 17:47:46,666] {processor.py:163} INFO - Started process (PID=1068) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:47:46,670] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:47:46,671] {logging_mixin.py:109} INFO - [2022-04-07 17:47:46,671] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:47:47,634] {logging_mixin.py:109} INFO - [2022-04-07 17:47:47,632] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:47:47,635] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:47:47,662] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.000 seconds
[2022-04-07 17:48:17,792] {processor.py:163} INFO - Started process (PID=1108) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:48:17,794] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:48:17,795] {logging_mixin.py:109} INFO - [2022-04-07 17:48:17,795] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:48:18,773] {logging_mixin.py:109} INFO - [2022-04-07 17:48:18,772] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 54, in <module>
    move_object=True
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 198, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (move_badges_stack_overflow_data _files_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:48:18,774] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:48:18,796] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.009 seconds
[2022-04-07 17:48:48,915] {processor.py:163} INFO - Started process (PID=1136) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:48:48,917] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:48:48,917] {logging_mixin.py:109} INFO - [2022-04-07 17:48:48,917] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:48:49,839] {logging_mixin.py:109} INFO - [2022-04-07 17:48:49,837] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:48:49,839] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:48:49,860] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 17:49:20,041] {processor.py:163} INFO - Started process (PID=1175) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:49:20,043] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:49:20,044] {logging_mixin.py:109} INFO - [2022-04-07 17:49:20,044] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:49:20,966] {logging_mixin.py:109} INFO - [2022-04-07 17:49:20,964] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:49:20,967] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:49:20,989] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.953 seconds
[2022-04-07 17:49:51,145] {processor.py:163} INFO - Started process (PID=1204) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:49:51,148] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:49:51,149] {logging_mixin.py:109} INFO - [2022-04-07 17:49:51,149] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:49:52,138] {logging_mixin.py:109} INFO - [2022-04-07 17:49:52,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:49:52,138] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:49:52,162] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.022 seconds
[2022-04-07 17:50:22,277] {processor.py:163} INFO - Started process (PID=1242) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:50:22,280] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:50:22,281] {logging_mixin.py:109} INFO - [2022-04-07 17:50:22,281] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:50:23,260] {logging_mixin.py:109} INFO - [2022-04-07 17:50:23,258] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:50:23,261] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:50:23,285] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.012 seconds
[2022-04-07 17:50:53,399] {processor.py:163} INFO - Started process (PID=1272) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:50:53,401] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:50:53,402] {logging_mixin.py:109} INFO - [2022-04-07 17:50:53,402] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:50:54,366] {logging_mixin.py:109} INFO - [2022-04-07 17:50:54,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:50:54,366] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:50:54,388] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.994 seconds
[2022-04-07 17:51:24,533] {processor.py:163} INFO - Started process (PID=1308) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:51:24,535] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:51:24,536] {logging_mixin.py:109} INFO - [2022-04-07 17:51:24,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:51:25,500] {logging_mixin.py:109} INFO - [2022-04-07 17:51:25,498] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:51:25,500] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:51:25,525] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.998 seconds
[2022-04-07 17:51:55,661] {processor.py:163} INFO - Started process (PID=1336) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:51:55,663] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:51:55,664] {logging_mixin.py:109} INFO - [2022-04-07 17:51:55,664] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:51:56,615] {logging_mixin.py:109} INFO - [2022-04-07 17:51:56,613] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:51:56,616] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:51:56,639] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.982 seconds
[2022-04-07 17:52:26,797] {processor.py:163} INFO - Started process (PID=1376) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:52:26,798] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:52:26,799] {logging_mixin.py:109} INFO - [2022-04-07 17:52:26,799] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:52:27,807] {logging_mixin.py:109} INFO - [2022-04-07 17:52:27,805] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:52:27,808] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:52:27,830] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.038 seconds
[2022-04-07 17:52:57,950] {processor.py:163} INFO - Started process (PID=1406) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:52:57,955] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:52:57,957] {logging_mixin.py:109} INFO - [2022-04-07 17:52:57,956] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:52:58,966] {logging_mixin.py:109} INFO - [2022-04-07 17:52:58,964] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:52:58,966] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:52:58,991] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.056 seconds
[2022-04-07 17:53:29,056] {processor.py:163} INFO - Started process (PID=1447) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:53:29,059] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:53:29,060] {logging_mixin.py:109} INFO - [2022-04-07 17:53:29,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:53:30,445] {logging_mixin.py:109} INFO - [2022-04-07 17:53:30,442] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:53:30,445] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:53:30,469] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.419 seconds
[2022-04-07 17:54:00,574] {processor.py:163} INFO - Started process (PID=1475) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:54:00,577] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:54:00,577] {logging_mixin.py:109} INFO - [2022-04-07 17:54:00,577] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:54:01,576] {logging_mixin.py:109} INFO - [2022-04-07 17:54:01,574] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:54:01,576] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:54:01,597] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.028 seconds
[2022-04-07 17:54:31,714] {processor.py:163} INFO - Started process (PID=1513) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:54:31,716] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:54:31,718] {logging_mixin.py:109} INFO - [2022-04-07 17:54:31,717] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:54:32,916] {logging_mixin.py:109} INFO - [2022-04-07 17:54:32,914] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:54:32,917] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:54:32,942] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.234 seconds
[2022-04-07 17:55:03,040] {processor.py:163} INFO - Started process (PID=1542) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:55:03,043] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:55:03,044] {logging_mixin.py:109} INFO - [2022-04-07 17:55:03,044] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:55:03,993] {logging_mixin.py:109} INFO - [2022-04-07 17:55:03,991] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:55:03,993] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:55:04,017] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.982 seconds
[2022-04-07 17:55:34,178] {processor.py:163} INFO - Started process (PID=1580) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:55:34,180] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:55:34,181] {logging_mixin.py:109} INFO - [2022-04-07 17:55:34,181] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:55:35,204] {logging_mixin.py:109} INFO - [2022-04-07 17:55:35,202] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:55:35,204] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:55:35,231] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.059 seconds
[2022-04-07 17:56:05,297] {processor.py:163} INFO - Started process (PID=1607) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:56:05,299] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:56:05,300] {logging_mixin.py:109} INFO - [2022-04-07 17:56:05,300] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:56:06,266] {logging_mixin.py:109} INFO - [2022-04-07 17:56:06,264] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:56:06,266] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:56:06,291] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.999 seconds
[2022-04-07 17:56:36,440] {processor.py:163} INFO - Started process (PID=1643) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:56:36,442] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:56:36,444] {logging_mixin.py:109} INFO - [2022-04-07 17:56:36,444] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:56:37,794] {logging_mixin.py:109} INFO - [2022-04-07 17:56:37,792] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:56:37,794] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:56:37,821] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.388 seconds
[2022-04-07 17:57:07,919] {processor.py:163} INFO - Started process (PID=1676) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:57:07,921] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:57:07,922] {logging_mixin.py:109} INFO - [2022-04-07 17:57:07,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:57:08,922] {logging_mixin.py:109} INFO - [2022-04-07 17:57:08,920] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:57:08,922] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:57:08,944] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.030 seconds
[2022-04-07 17:57:39,047] {processor.py:163} INFO - Started process (PID=1706) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:57:39,049] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:57:39,050] {logging_mixin.py:109} INFO - [2022-04-07 17:57:39,050] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:57:40,260] {logging_mixin.py:109} INFO - [2022-04-07 17:57:40,258] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:57:40,261] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:57:40,286] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.244 seconds
[2022-04-07 17:58:10,397] {processor.py:163} INFO - Started process (PID=1744) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:58:10,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:58:10,404] {logging_mixin.py:109} INFO - [2022-04-07 17:58:10,403] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:58:11,380] {logging_mixin.py:109} INFO - [2022-04-07 17:58:11,378] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:58:11,380] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:58:11,404] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.013 seconds
[2022-04-07 17:58:41,524] {processor.py:163} INFO - Started process (PID=1773) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:58:41,527] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:58:41,528] {logging_mixin.py:109} INFO - [2022-04-07 17:58:41,527] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:58:42,750] {logging_mixin.py:109} INFO - [2022-04-07 17:58:42,747] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:58:42,751] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:58:42,782] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.264 seconds
[2022-04-07 17:59:12,889] {processor.py:163} INFO - Started process (PID=1810) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:59:12,892] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:59:12,892] {logging_mixin.py:109} INFO - [2022-04-07 17:59:12,892] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:59:13,842] {logging_mixin.py:109} INFO - [2022-04-07 17:59:13,840] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:59:13,843] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:59:13,867] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.982 seconds
[2022-04-07 17:59:44,026] {processor.py:163} INFO - Started process (PID=1841) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:59:44,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 17:59:44,028] {logging_mixin.py:109} INFO - [2022-04-07 17:59:44,028] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:59:45,038] {logging_mixin.py:109} INFO - [2022-04-07 17:59:45,035] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 17:59:45,039] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 17:59:45,068] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.047 seconds
[2022-04-07 18:00:15,144] {processor.py:163} INFO - Started process (PID=1880) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:00:15,147] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:00:15,148] {logging_mixin.py:109} INFO - [2022-04-07 18:00:15,148] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:00:16,188] {logging_mixin.py:109} INFO - [2022-04-07 18:00:16,184] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:00:16,189] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:00:16,213] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.074 seconds
[2022-04-07 18:00:46,301] {processor.py:163} INFO - Started process (PID=1909) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:00:46,304] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:00:46,305] {logging_mixin.py:109} INFO - [2022-04-07 18:00:46,305] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:00:47,551] {logging_mixin.py:109} INFO - [2022-04-07 18:00:47,548] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:00:47,552] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:00:47,583] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.289 seconds
[2022-04-07 18:01:17,689] {processor.py:163} INFO - Started process (PID=1948) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:01:17,692] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:01:17,693] {logging_mixin.py:109} INFO - [2022-04-07 18:01:17,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:01:18,678] {logging_mixin.py:109} INFO - [2022-04-07 18:01:18,676] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:01:18,679] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:01:18,701] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.017 seconds
[2022-04-07 18:01:48,814] {processor.py:163} INFO - Started process (PID=1976) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:01:48,815] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:01:48,816] {logging_mixin.py:109} INFO - [2022-04-07 18:01:48,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:01:49,789] {logging_mixin.py:109} INFO - [2022-04-07 18:01:49,787] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:01:49,790] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:01:49,814] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.005 seconds
[2022-04-07 18:02:19,937] {processor.py:163} INFO - Started process (PID=2013) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:02:19,940] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:02:19,941] {logging_mixin.py:109} INFO - [2022-04-07 18:02:19,941] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:02:20,915] {logging_mixin.py:109} INFO - [2022-04-07 18:02:20,913] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:02:20,916] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:02:20,937] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.005 seconds
[2022-04-07 18:02:51,062] {processor.py:163} INFO - Started process (PID=2042) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:02:51,064] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:02:51,065] {logging_mixin.py:109} INFO - [2022-04-07 18:02:51,065] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:02:52,030] {logging_mixin.py:109} INFO - [2022-04-07 18:02:52,029] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:02:52,031] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:02:52,052] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.995 seconds
[2022-04-07 18:03:22,202] {processor.py:163} INFO - Started process (PID=2079) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:03:22,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:03:22,205] {logging_mixin.py:109} INFO - [2022-04-07 18:03:22,205] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:03:23,138] {logging_mixin.py:109} INFO - [2022-04-07 18:03:23,136] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:03:23,139] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:03:23,162] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.965 seconds
[2022-04-07 18:03:53,312] {processor.py:163} INFO - Started process (PID=2107) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:03:53,315] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:03:53,316] {logging_mixin.py:109} INFO - [2022-04-07 18:03:53,316] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:03:54,295] {logging_mixin.py:109} INFO - [2022-04-07 18:03:54,292] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:03:54,296] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:03:54,323] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.016 seconds
[2022-04-07 18:04:24,487] {processor.py:163} INFO - Started process (PID=2147) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:04:24,489] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:04:24,490] {logging_mixin.py:109} INFO - [2022-04-07 18:04:24,490] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:04:25,425] {logging_mixin.py:109} INFO - [2022-04-07 18:04:25,423] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:04:25,425] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:04:25,448] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.966 seconds
[2022-04-07 18:04:55,613] {processor.py:163} INFO - Started process (PID=2176) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:04:55,615] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:04:55,616] {logging_mixin.py:109} INFO - [2022-04-07 18:04:55,616] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:04:56,636] {logging_mixin.py:109} INFO - [2022-04-07 18:04:56,634] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:04:56,636] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:04:56,659] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.051 seconds
[2022-04-07 18:05:26,750] {processor.py:163} INFO - Started process (PID=2213) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:05:26,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:05:26,753] {logging_mixin.py:109} INFO - [2022-04-07 18:05:26,753] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:05:27,716] {logging_mixin.py:109} INFO - [2022-04-07 18:05:27,714] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:05:27,717] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:05:27,744] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.001 seconds
[2022-04-07 18:05:57,870] {processor.py:163} INFO - Started process (PID=2242) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:05:57,873] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:05:57,874] {logging_mixin.py:109} INFO - [2022-04-07 18:05:57,874] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:05:58,858] {logging_mixin.py:109} INFO - [2022-04-07 18:05:58,856] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:05:58,858] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:05:58,882] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.016 seconds
[2022-04-07 18:06:29,001] {processor.py:163} INFO - Started process (PID=2282) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:06:29,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:06:29,003] {logging_mixin.py:109} INFO - [2022-04-07 18:06:29,003] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:06:29,976] {logging_mixin.py:109} INFO - [2022-04-07 18:06:29,974] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:06:29,977] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:06:29,999] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.003 seconds
[2022-04-07 18:07:00,135] {processor.py:163} INFO - Started process (PID=2312) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:07:00,137] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:07:00,138] {logging_mixin.py:109} INFO - [2022-04-07 18:07:00,138] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:07:01,096] {logging_mixin.py:109} INFO - [2022-04-07 18:07:01,094] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:07:01,096] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:07:01,116] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.987 seconds
[2022-04-07 18:07:31,255] {processor.py:163} INFO - Started process (PID=2350) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:07:31,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:07:31,258] {logging_mixin.py:109} INFO - [2022-04-07 18:07:31,258] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:07:32,216] {logging_mixin.py:109} INFO - [2022-04-07 18:07:32,214] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:07:32,217] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:07:32,241] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.991 seconds
[2022-04-07 18:08:02,370] {processor.py:163} INFO - Started process (PID=2377) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:08:02,375] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:08:02,376] {logging_mixin.py:109} INFO - [2022-04-07 18:08:02,376] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:08:03,384] {logging_mixin.py:109} INFO - [2022-04-07 18:08:03,382] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:08:03,385] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:08:03,408] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.043 seconds
[2022-04-07 18:08:33,496] {processor.py:163} INFO - Started process (PID=2416) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:08:33,497] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:08:33,498] {logging_mixin.py:109} INFO - [2022-04-07 18:08:33,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:08:34,475] {logging_mixin.py:109} INFO - [2022-04-07 18:08:34,473] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:08:34,475] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:08:34,499] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.008 seconds
[2022-04-07 18:09:04,620] {processor.py:163} INFO - Started process (PID=2444) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:09:04,622] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:09:04,623] {logging_mixin.py:109} INFO - [2022-04-07 18:09:04,623] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:09:05,700] {logging_mixin.py:109} INFO - [2022-04-07 18:09:05,698] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:09:05,701] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:09:05,726] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.112 seconds
[2022-04-07 18:09:35,826] {processor.py:163} INFO - Started process (PID=2483) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:09:35,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:09:35,830] {logging_mixin.py:109} INFO - [2022-04-07 18:09:35,830] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:09:36,954] {logging_mixin.py:109} INFO - [2022-04-07 18:09:36,952] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:09:36,955] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:09:36,977] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.158 seconds
[2022-04-07 18:10:07,095] {processor.py:163} INFO - Started process (PID=2512) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:10:07,099] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:10:07,100] {logging_mixin.py:109} INFO - [2022-04-07 18:10:07,100] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:10:08,115] {logging_mixin.py:109} INFO - [2022-04-07 18:10:08,113] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:10:08,115] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:10:08,139] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.051 seconds
[2022-04-07 18:10:38,196] {processor.py:163} INFO - Started process (PID=2549) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:10:38,199] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:10:38,200] {logging_mixin.py:109} INFO - [2022-04-07 18:10:38,200] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:10:39,219] {logging_mixin.py:109} INFO - [2022-04-07 18:10:39,217] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:10:39,220] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:10:39,241] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.050 seconds
[2022-04-07 18:11:09,351] {processor.py:163} INFO - Started process (PID=2577) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:11:09,353] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:11:09,354] {logging_mixin.py:109} INFO - [2022-04-07 18:11:09,354] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:11:10,322] {logging_mixin.py:109} INFO - [2022-04-07 18:11:10,320] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:11:10,322] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:11:10,348] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.002 seconds
[2022-04-07 18:11:40,486] {processor.py:163} INFO - Started process (PID=2615) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:11:40,488] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:11:40,489] {logging_mixin.py:109} INFO - [2022-04-07 18:11:40,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:11:41,629] {logging_mixin.py:109} INFO - [2022-04-07 18:11:41,627] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:11:41,630] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:11:41,654] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.174 seconds
[2022-04-07 18:12:11,748] {processor.py:163} INFO - Started process (PID=2644) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:12:11,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:12:11,751] {logging_mixin.py:109} INFO - [2022-04-07 18:12:11,751] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:12:12,686] {logging_mixin.py:109} INFO - [2022-04-07 18:12:12,684] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:12:12,686] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:12:12,707] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.965 seconds
[2022-04-07 18:12:42,826] {processor.py:163} INFO - Started process (PID=2681) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:12:42,834] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:12:42,840] {logging_mixin.py:109} INFO - [2022-04-07 18:12:42,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:12:43,799] {logging_mixin.py:109} INFO - [2022-04-07 18:12:43,797] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:12:43,799] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:12:43,825] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.015 seconds
[2022-04-07 18:13:13,933] {processor.py:163} INFO - Started process (PID=2714) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:13:13,935] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:13:13,936] {logging_mixin.py:109} INFO - [2022-04-07 18:13:13,936] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:13:14,840] {logging_mixin.py:109} INFO - [2022-04-07 18:13:14,838] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:13:14,840] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:13:14,862] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 18:13:44,981] {processor.py:163} INFO - Started process (PID=2751) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:13:44,984] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:13:44,985] {logging_mixin.py:109} INFO - [2022-04-07 18:13:44,985] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:13:45,970] {logging_mixin.py:109} INFO - [2022-04-07 18:13:45,966] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:13:45,971] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:13:45,992] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.018 seconds
[2022-04-07 18:14:16,053] {processor.py:163} INFO - Started process (PID=2780) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:14:16,055] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:14:16,056] {logging_mixin.py:109} INFO - [2022-04-07 18:14:16,056] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:14:16,992] {logging_mixin.py:109} INFO - [2022-04-07 18:14:16,990] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:14:16,992] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:14:17,016] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.969 seconds
[2022-04-07 18:14:47,146] {processor.py:163} INFO - Started process (PID=2817) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:14:47,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:14:47,151] {logging_mixin.py:109} INFO - [2022-04-07 18:14:47,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:14:48,221] {logging_mixin.py:109} INFO - [2022-04-07 18:14:48,218] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:14:48,221] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:14:48,242] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.102 seconds
[2022-04-07 18:15:18,349] {processor.py:163} INFO - Started process (PID=2847) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:15:18,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:15:18,353] {logging_mixin.py:109} INFO - [2022-04-07 18:15:18,353] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:15:19,272] {logging_mixin.py:109} INFO - [2022-04-07 18:15:19,270] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:15:19,273] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:15:19,295] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.952 seconds
[2022-04-07 18:15:49,442] {processor.py:163} INFO - Started process (PID=2883) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:15:49,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:15:49,449] {logging_mixin.py:109} INFO - [2022-04-07 18:15:49,449] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:15:50,756] {logging_mixin.py:109} INFO - [2022-04-07 18:15:50,753] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:15:50,757] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:15:50,785] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.349 seconds
[2022-04-07 18:16:20,907] {processor.py:163} INFO - Started process (PID=2913) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:16:20,909] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:16:20,910] {logging_mixin.py:109} INFO - [2022-04-07 18:16:20,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:16:21,879] {logging_mixin.py:109} INFO - [2022-04-07 18:16:21,875] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:16:21,880] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:16:21,914] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.013 seconds
[2022-04-07 18:16:52,031] {processor.py:163} INFO - Started process (PID=2940) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:16:52,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:16:52,034] {logging_mixin.py:109} INFO - [2022-04-07 18:16:52,034] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:16:53,257] {logging_mixin.py:109} INFO - [2022-04-07 18:16:53,255] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:16:53,258] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:16:53,280] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.255 seconds
[2022-04-07 18:17:23,383] {processor.py:163} INFO - Started process (PID=2977) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:17:23,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:17:23,387] {logging_mixin.py:109} INFO - [2022-04-07 18:17:23,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:17:24,403] {logging_mixin.py:109} INFO - [2022-04-07 18:17:24,401] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:17:24,404] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:17:24,425] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.047 seconds
[2022-04-07 18:17:54,509] {processor.py:163} INFO - Started process (PID=3004) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:17:54,510] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:17:54,511] {logging_mixin.py:109} INFO - [2022-04-07 18:17:54,511] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:17:55,527] {logging_mixin.py:109} INFO - [2022-04-07 18:17:55,525] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:17:55,528] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:17:55,551] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.047 seconds
[2022-04-07 18:18:25,635] {processor.py:163} INFO - Started process (PID=3043) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:18:25,637] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:18:25,637] {logging_mixin.py:109} INFO - [2022-04-07 18:18:25,637] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:18:26,584] {logging_mixin.py:109} INFO - [2022-04-07 18:18:26,582] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:18:26,585] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:18:26,609] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.978 seconds
[2022-04-07 18:18:56,754] {processor.py:163} INFO - Started process (PID=3071) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:18:56,756] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:18:56,757] {logging_mixin.py:109} INFO - [2022-04-07 18:18:56,757] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:18:57,743] {logging_mixin.py:109} INFO - [2022-04-07 18:18:57,741] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:18:57,744] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:18:57,768] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.018 seconds
[2022-04-07 18:19:27,893] {processor.py:163} INFO - Started process (PID=3110) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:19:27,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:19:27,897] {logging_mixin.py:109} INFO - [2022-04-07 18:19:27,897] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:19:28,883] {logging_mixin.py:109} INFO - [2022-04-07 18:19:28,881] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:19:28,884] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:19:28,907] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.018 seconds
[2022-04-07 18:19:59,020] {processor.py:163} INFO - Started process (PID=3139) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:19:59,025] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:19:59,026] {logging_mixin.py:109} INFO - [2022-04-07 18:19:59,025] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:19:59,976] {logging_mixin.py:109} INFO - [2022-04-07 18:19:59,974] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:19:59,976] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:20:00,002] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.987 seconds
[2022-04-07 18:20:30,160] {processor.py:163} INFO - Started process (PID=3178) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:20:30,162] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:20:30,163] {logging_mixin.py:109} INFO - [2022-04-07 18:20:30,163] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:20:31,253] {logging_mixin.py:109} INFO - [2022-04-07 18:20:31,249] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:20:31,253] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:20:31,277] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.122 seconds
[2022-04-07 18:21:01,377] {processor.py:163} INFO - Started process (PID=3207) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:21:01,379] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:21:01,380] {logging_mixin.py:109} INFO - [2022-04-07 18:21:01,380] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:21:02,452] {logging_mixin.py:109} INFO - [2022-04-07 18:21:02,450] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:21:02,452] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:21:02,475] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.104 seconds
[2022-04-07 18:21:32,570] {processor.py:163} INFO - Started process (PID=3245) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:21:32,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:21:32,576] {logging_mixin.py:109} INFO - [2022-04-07 18:21:32,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:21:33,580] {logging_mixin.py:109} INFO - [2022-04-07 18:21:33,577] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:21:33,580] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:21:33,607] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.042 seconds
[2022-04-07 18:22:03,692] {processor.py:163} INFO - Started process (PID=3273) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:22:03,694] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:22:03,695] {logging_mixin.py:109} INFO - [2022-04-07 18:22:03,695] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:22:04,798] {logging_mixin.py:109} INFO - [2022-04-07 18:22:04,796] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:22:04,799] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:22:04,821] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.134 seconds
[2022-04-07 18:22:34,916] {processor.py:163} INFO - Started process (PID=3310) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:22:34,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:22:34,920] {logging_mixin.py:109} INFO - [2022-04-07 18:22:34,920] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:22:35,886] {logging_mixin.py:109} INFO - [2022-04-07 18:22:35,884] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:22:35,887] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:22:35,911] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.000 seconds
[2022-04-07 18:23:06,046] {processor.py:163} INFO - Started process (PID=3338) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:23:06,048] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:23:06,049] {logging_mixin.py:109} INFO - [2022-04-07 18:23:06,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:23:07,075] {logging_mixin.py:109} INFO - [2022-04-07 18:23:07,073] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:23:07,076] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:23:07,102] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.060 seconds
[2022-04-07 18:23:37,161] {processor.py:163} INFO - Started process (PID=3376) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:23:37,164] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:23:37,165] {logging_mixin.py:109} INFO - [2022-04-07 18:23:37,164] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:23:38,132] {logging_mixin.py:109} INFO - [2022-04-07 18:23:38,130] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:23:38,132] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:23:38,156] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.001 seconds
[2022-04-07 18:24:08,285] {processor.py:163} INFO - Started process (PID=3414) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:24:08,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:24:08,287] {logging_mixin.py:109} INFO - [2022-04-07 18:24:08,287] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:24:09,428] {logging_mixin.py:109} INFO - [2022-04-07 18:24:09,426] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:24:09,429] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:24:09,451] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.171 seconds
[2022-04-07 18:24:39,553] {processor.py:163} INFO - Started process (PID=3443) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:24:39,555] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:24:39,555] {logging_mixin.py:109} INFO - [2022-04-07 18:24:39,555] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:24:40,481] {logging_mixin.py:109} INFO - [2022-04-07 18:24:40,479] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:24:40,482] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:24:40,508] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.961 seconds
[2022-04-07 18:25:10,605] {processor.py:163} INFO - Started process (PID=3482) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:25:10,608] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:25:10,609] {logging_mixin.py:109} INFO - [2022-04-07 18:25:10,609] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:25:11,584] {logging_mixin.py:109} INFO - [2022-04-07 18:25:11,582] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:25:11,585] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:25:11,607] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.008 seconds
[2022-04-07 18:25:41,725] {processor.py:163} INFO - Started process (PID=3510) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:25:41,727] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:25:41,727] {logging_mixin.py:109} INFO - [2022-04-07 18:25:41,727] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:25:42,686] {logging_mixin.py:109} INFO - [2022-04-07 18:25:42,683] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:25:42,686] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:25:42,712] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.992 seconds
[2022-04-07 18:26:12,852] {processor.py:163} INFO - Started process (PID=3547) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:26:12,855] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:26:12,856] {logging_mixin.py:109} INFO - [2022-04-07 18:26:12,856] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:26:13,863] {logging_mixin.py:109} INFO - [2022-04-07 18:26:13,861] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:26:13,864] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:26:13,886] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.038 seconds
[2022-04-07 18:26:43,971] {processor.py:163} INFO - Started process (PID=3574) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:26:43,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:26:43,974] {logging_mixin.py:109} INFO - [2022-04-07 18:26:43,974] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:26:44,888] {logging_mixin.py:109} INFO - [2022-04-07 18:26:44,886] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:26:44,889] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:26:44,916] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.950 seconds
[2022-04-07 18:27:15,073] {processor.py:163} INFO - Started process (PID=3610) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:27:15,076] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:27:15,077] {logging_mixin.py:109} INFO - [2022-04-07 18:27:15,077] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:27:16,060] {logging_mixin.py:109} INFO - [2022-04-07 18:27:16,058] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:27:16,060] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:27:16,082] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.014 seconds
[2022-04-07 18:27:46,196] {processor.py:163} INFO - Started process (PID=3638) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:27:46,198] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:27:46,199] {logging_mixin.py:109} INFO - [2022-04-07 18:27:46,199] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:27:47,142] {logging_mixin.py:109} INFO - [2022-04-07 18:27:47,140] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:27:47,142] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:27:47,171] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.980 seconds
[2022-04-07 18:28:17,328] {processor.py:163} INFO - Started process (PID=3677) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:28:17,333] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:28:17,334] {logging_mixin.py:109} INFO - [2022-04-07 18:28:17,334] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:28:18,302] {logging_mixin.py:109} INFO - [2022-04-07 18:28:18,300] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:28:18,302] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:28:18,327] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.004 seconds
[2022-04-07 18:28:33,408] {processor.py:163} INFO - Started process (PID=3696) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:28:33,410] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:28:33,411] {logging_mixin.py:109} INFO - [2022-04-07 18:28:33,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:28:34,336] {logging_mixin.py:109} INFO - [2022-04-07 18:28:34,333] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:28:34,336] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:28:34,360] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.957 seconds
[2022-04-07 18:29:04,522] {processor.py:163} INFO - Started process (PID=3725) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:29:04,524] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:29:04,525] {logging_mixin.py:109} INFO - [2022-04-07 18:29:04,525] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:29:05,513] {logging_mixin.py:109} INFO - [2022-04-07 18:29:05,511] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:29:05,514] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:29:05,537] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.020 seconds
[2022-04-07 18:29:35,655] {processor.py:163} INFO - Started process (PID=3763) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:29:35,658] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:29:35,659] {logging_mixin.py:109} INFO - [2022-04-07 18:29:35,659] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:29:36,563] {logging_mixin.py:109} INFO - [2022-04-07 18:29:36,561] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:29:36,563] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:29:36,585] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 18:30:06,695] {processor.py:163} INFO - Started process (PID=3791) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:30:06,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:30:06,698] {logging_mixin.py:109} INFO - [2022-04-07 18:30:06,698] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:30:07,626] {logging_mixin.py:109} INFO - [2022-04-07 18:30:07,624] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:30:07,627] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:30:07,649] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.960 seconds
[2022-04-07 18:30:37,764] {processor.py:163} INFO - Started process (PID=3831) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:30:37,767] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:30:37,768] {logging_mixin.py:109} INFO - [2022-04-07 18:30:37,768] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:30:38,778] {logging_mixin.py:109} INFO - [2022-04-07 18:30:38,775] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:30:38,779] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:30:38,806] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.047 seconds
[2022-04-07 18:31:08,936] {processor.py:163} INFO - Started process (PID=3859) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:31:08,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:31:08,940] {logging_mixin.py:109} INFO - [2022-04-07 18:31:08,939] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:31:09,926] {logging_mixin.py:109} INFO - [2022-04-07 18:31:09,923] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:31:09,927] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:31:09,956] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.026 seconds
[2022-04-07 18:31:40,055] {processor.py:163} INFO - Started process (PID=3897) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:31:40,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:31:40,058] {logging_mixin.py:109} INFO - [2022-04-07 18:31:40,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:31:41,043] {logging_mixin.py:109} INFO - [2022-04-07 18:31:41,040] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:31:41,043] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:31:41,067] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.017 seconds
[2022-04-07 18:32:11,176] {processor.py:163} INFO - Started process (PID=3933) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:32:11,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:32:11,180] {logging_mixin.py:109} INFO - [2022-04-07 18:32:11,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:32:12,130] {logging_mixin.py:109} INFO - [2022-04-07 18:32:12,128] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:32:12,131] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:32:12,152] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.981 seconds
[2022-04-07 18:32:42,298] {processor.py:163} INFO - Started process (PID=3964) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:32:42,301] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:32:42,301] {logging_mixin.py:109} INFO - [2022-04-07 18:32:42,301] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:32:43,250] {logging_mixin.py:109} INFO - [2022-04-07 18:32:43,248] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:32:43,251] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:32:43,272] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.979 seconds
[2022-04-07 18:33:13,422] {processor.py:163} INFO - Started process (PID=4002) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:33:13,423] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:33:13,424] {logging_mixin.py:109} INFO - [2022-04-07 18:33:13,424] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:33:14,358] {logging_mixin.py:109} INFO - [2022-04-07 18:33:14,356] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:33:14,359] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:33:14,384] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.967 seconds
[2022-04-07 18:33:44,540] {processor.py:163} INFO - Started process (PID=4030) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:33:44,543] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:33:44,544] {logging_mixin.py:109} INFO - [2022-04-07 18:33:44,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:33:45,486] {logging_mixin.py:109} INFO - [2022-04-07 18:33:45,483] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:33:45,486] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:33:45,516] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.981 seconds
[2022-04-07 18:34:15,664] {processor.py:163} INFO - Started process (PID=4068) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:34:15,666] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:34:15,667] {logging_mixin.py:109} INFO - [2022-04-07 18:34:15,666] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:34:16,719] {logging_mixin.py:109} INFO - [2022-04-07 18:34:16,717] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:34:16,719] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:34:16,746] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.087 seconds
[2022-04-07 18:34:46,801] {processor.py:163} INFO - Started process (PID=4098) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:34:46,803] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:34:46,804] {logging_mixin.py:109} INFO - [2022-04-07 18:34:46,804] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:34:47,785] {logging_mixin.py:109} INFO - [2022-04-07 18:34:47,783] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:34:47,785] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:34:47,807] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.011 seconds
[2022-04-07 18:35:17,949] {processor.py:163} INFO - Started process (PID=4137) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:35:17,951] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:35:17,952] {logging_mixin.py:109} INFO - [2022-04-07 18:35:17,952] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:35:18,959] {logging_mixin.py:109} INFO - [2022-04-07 18:35:18,957] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:35:18,960] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:35:18,981] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.038 seconds
[2022-04-07 18:35:49,064] {processor.py:163} INFO - Started process (PID=4167) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:35:49,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:35:49,068] {logging_mixin.py:109} INFO - [2022-04-07 18:35:49,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:35:50,050] {logging_mixin.py:109} INFO - [2022-04-07 18:35:50,047] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:35:50,050] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:35:50,073] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.014 seconds
[2022-04-07 18:36:20,205] {processor.py:163} INFO - Started process (PID=4205) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:36:20,208] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:36:20,209] {logging_mixin.py:109} INFO - [2022-04-07 18:36:20,209] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:36:21,189] {logging_mixin.py:109} INFO - [2022-04-07 18:36:21,187] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:36:21,189] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:36:21,211] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.013 seconds
[2022-04-07 18:36:51,438] {processor.py:163} INFO - Started process (PID=4233) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:36:51,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:36:51,441] {logging_mixin.py:109} INFO - [2022-04-07 18:36:51,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:36:52,321] {logging_mixin.py:109} INFO - [2022-04-07 18:36:52,319] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:36:52,321] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:36:52,345] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.911 seconds
[2022-04-07 18:37:22,457] {processor.py:163} INFO - Started process (PID=4272) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:37:22,460] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:37:22,461] {logging_mixin.py:109} INFO - [2022-04-07 18:37:22,460] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:37:23,311] {logging_mixin.py:109} INFO - [2022-04-07 18:37:23,309] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:37:23,311] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:37:23,334] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.883 seconds
[2022-04-07 18:37:53,439] {processor.py:163} INFO - Started process (PID=4300) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:37:53,441] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:37:53,442] {logging_mixin.py:109} INFO - [2022-04-07 18:37:53,442] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:37:54,320] {logging_mixin.py:109} INFO - [2022-04-07 18:37:54,318] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:37:54,321] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:37:54,344] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.911 seconds
[2022-04-07 18:38:24,451] {processor.py:163} INFO - Started process (PID=4338) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:38:24,455] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:38:24,456] {logging_mixin.py:109} INFO - [2022-04-07 18:38:24,456] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:38:25,297] {logging_mixin.py:109} INFO - [2022-04-07 18:38:25,295] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:38:25,297] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:38:25,318] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.873 seconds
[2022-04-07 18:38:55,417] {processor.py:163} INFO - Started process (PID=4369) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:38:55,419] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:38:55,420] {logging_mixin.py:109} INFO - [2022-04-07 18:38:55,420] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:38:56,332] {logging_mixin.py:109} INFO - [2022-04-07 18:38:56,329] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:38:56,332] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:38:56,355] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 18:39:26,456] {processor.py:163} INFO - Started process (PID=4405) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:39:26,458] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:39:26,459] {logging_mixin.py:109} INFO - [2022-04-07 18:39:26,459] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:39:27,347] {logging_mixin.py:109} INFO - [2022-04-07 18:39:27,345] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:39:27,348] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:39:27,376] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.926 seconds
[2022-04-07 18:39:57,478] {processor.py:163} INFO - Started process (PID=4432) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:39:57,480] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:39:57,481] {logging_mixin.py:109} INFO - [2022-04-07 18:39:57,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:39:58,405] {logging_mixin.py:109} INFO - [2022-04-07 18:39:58,403] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:39:58,406] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:39:58,436] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.963 seconds
[2022-04-07 18:40:28,541] {processor.py:163} INFO - Started process (PID=4471) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:40:28,543] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:40:28,544] {logging_mixin.py:109} INFO - [2022-04-07 18:40:28,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:40:29,447] {logging_mixin.py:109} INFO - [2022-04-07 18:40:29,445] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:40:29,448] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:40:29,470] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 18:40:59,576] {processor.py:163} INFO - Started process (PID=4500) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:40:59,580] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:40:59,581] {logging_mixin.py:109} INFO - [2022-04-07 18:40:59,581] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:41:00,465] {logging_mixin.py:109} INFO - [2022-04-07 18:41:00,463] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:41:00,466] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:41:00,490] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.919 seconds
[2022-04-07 18:41:30,592] {processor.py:163} INFO - Started process (PID=4539) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:41:30,593] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:41:30,594] {logging_mixin.py:109} INFO - [2022-04-07 18:41:30,594] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:41:31,437] {logging_mixin.py:109} INFO - [2022-04-07 18:41:31,435] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:41:31,437] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:41:31,458] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.872 seconds
[2022-04-07 18:42:01,550] {processor.py:163} INFO - Started process (PID=4566) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:01,553] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:42:01,554] {logging_mixin.py:109} INFO - [2022-04-07 18:42:01,554] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:02,496] {logging_mixin.py:109} INFO - [2022-04-07 18:42:02,494] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{{ execution_date.strftime(\'%Y-%m\') }}/*"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (bq_badges_stack_overflow_data _external_table_task) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:42:02,496] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:02,518] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.973 seconds
[2022-04-07 18:42:08,521] {processor.py:163} INFO - Started process (PID=4587) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:08,522] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:42:08,523] {logging_mixin.py:109} INFO - [2022-04-07 18:42:08,523] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:09,367] {logging_mixin.py:109} INFO - [2022-04-07 18:42:09,365] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}-{{ execution_date.strftime(\'%Y-%m\') }}/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:42:09,368] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:09,389] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.874 seconds
[2022-04-07 18:42:39,496] {processor.py:163} INFO - Started process (PID=4615) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:39,499] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:42:39,500] {logging_mixin.py:109} INFO - [2022-04-07 18:42:39,500] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:40,389] {logging_mixin.py:109} INFO - [2022-04-07 18:42:40,387] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}-{{ execution_date.strftime(\'%Y-%m\') }}/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:42:40,390] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:40,414] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.924 seconds
[2022-04-07 18:42:53,480] {processor.py:163} INFO - Started process (PID=4633) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:53,483] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:42:53,484] {logging_mixin.py:109} INFO - [2022-04-07 18:42:53,484] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:54,339] {logging_mixin.py:109} INFO - [2022-04-07 18:42:54,337] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:42:54,340] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:42:54,363] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.888 seconds
[2022-04-07 18:43:24,469] {processor.py:163} INFO - Started process (PID=4670) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:43:24,471] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:43:24,472] {logging_mixin.py:109} INFO - [2022-04-07 18:43:24,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:43:25,313] {logging_mixin.py:109} INFO - [2022-04-07 18:43:25,310] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:43:25,313] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:43:25,336] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.872 seconds
[2022-04-07 18:43:55,441] {processor.py:163} INFO - Started process (PID=4698) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:43:55,444] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:43:55,445] {logging_mixin.py:109} INFO - [2022-04-07 18:43:55,445] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:43:56,316] {logging_mixin.py:109} INFO - [2022-04-07 18:43:56,313] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:43:56,316] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:43:56,339] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.903 seconds
[2022-04-07 18:44:26,443] {processor.py:163} INFO - Started process (PID=4736) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:44:26,445] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:44:26,446] {logging_mixin.py:109} INFO - [2022-04-07 18:44:26,446] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:44:27,299] {logging_mixin.py:109} INFO - [2022-04-07 18:44:27,297] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:44:27,299] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:44:27,323] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.885 seconds
[2022-04-07 18:44:57,423] {processor.py:163} INFO - Started process (PID=4765) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:44:57,425] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:44:57,426] {logging_mixin.py:109} INFO - [2022-04-07 18:44:57,426] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:44:58,360] {logging_mixin.py:109} INFO - [2022-04-07 18:44:58,356] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:44:58,360] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:44:58,392] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.974 seconds
[2022-04-07 18:45:28,531] {processor.py:163} INFO - Started process (PID=4803) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:45:28,533] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:45:28,534] {logging_mixin.py:109} INFO - [2022-04-07 18:45:28,534] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:45:29,387] {logging_mixin.py:109} INFO - [2022-04-07 18:45:29,385] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:45:29,387] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:45:29,410] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.883 seconds
[2022-04-07 18:45:59,518] {processor.py:163} INFO - Started process (PID=4841) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:45:59,520] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:45:59,521] {logging_mixin.py:109} INFO - [2022-04-07 18:45:59,521] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:46:00,414] {logging_mixin.py:109} INFO - [2022-04-07 18:46:00,412] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:46:00,414] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:46:00,438] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.925 seconds
[2022-04-07 18:46:30,549] {processor.py:163} INFO - Started process (PID=4869) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:46:30,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:46:30,552] {logging_mixin.py:109} INFO - [2022-04-07 18:46:30,552] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:46:31,426] {logging_mixin.py:109} INFO - [2022-04-07 18:46:31,423] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:46:31,426] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:46:31,448] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.904 seconds
[2022-04-07 18:47:01,554] {processor.py:163} INFO - Started process (PID=4907) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:47:01,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:47:01,558] {logging_mixin.py:109} INFO - [2022-04-07 18:47:01,558] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:47:02,449] {logging_mixin.py:109} INFO - [2022-04-07 18:47:02,446] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:47:02,449] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:47:02,472] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.923 seconds
[2022-04-07 18:47:32,576] {processor.py:163} INFO - Started process (PID=4935) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:47:32,578] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:47:32,579] {logging_mixin.py:109} INFO - [2022-04-07 18:47:32,579] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:47:33,461] {logging_mixin.py:109} INFO - [2022-04-07 18:47:33,458] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:47:33,462] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:47:33,504] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 18:48:03,616] {processor.py:163} INFO - Started process (PID=4974) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:48:03,620] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:48:03,622] {logging_mixin.py:109} INFO - [2022-04-07 18:48:03,621] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:48:04,532] {logging_mixin.py:109} INFO - [2022-04-07 18:48:04,530] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:48:04,532] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:48:04,555] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.945 seconds
[2022-04-07 18:48:34,664] {processor.py:163} INFO - Started process (PID=5001) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:48:34,665] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:48:34,666] {logging_mixin.py:109} INFO - [2022-04-07 18:48:34,666] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:48:35,708] {logging_mixin.py:109} INFO - [2022-04-07 18:48:35,704] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:48:35,708] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:48:35,739] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.081 seconds
[2022-04-07 18:49:05,844] {processor.py:163} INFO - Started process (PID=5038) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:49:05,847] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:49:05,848] {logging_mixin.py:109} INFO - [2022-04-07 18:49:05,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:49:06,707] {logging_mixin.py:109} INFO - [2022-04-07 18:49:06,705] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:49:06,708] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:49:06,729] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.890 seconds
[2022-04-07 18:49:36,897] {processor.py:163} INFO - Started process (PID=5067) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:49:36,899] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:49:36,900] {logging_mixin.py:109} INFO - [2022-04-07 18:49:36,900] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:49:37,758] {logging_mixin.py:109} INFO - [2022-04-07 18:49:37,756] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:49:37,758] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:49:37,782] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.890 seconds
[2022-04-07 18:50:07,887] {processor.py:163} INFO - Started process (PID=5107) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:50:07,890] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:50:07,891] {logging_mixin.py:109} INFO - [2022-04-07 18:50:07,891] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:50:08,795] {logging_mixin.py:109} INFO - [2022-04-07 18:50:08,793] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:50:08,795] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:50:08,817] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.935 seconds
[2022-04-07 18:50:38,915] {processor.py:163} INFO - Started process (PID=5136) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:50:38,916] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:50:38,917] {logging_mixin.py:109} INFO - [2022-04-07 18:50:38,917] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:50:39,804] {logging_mixin.py:109} INFO - [2022-04-07 18:50:39,801] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:50:39,805] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:50:39,832] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.923 seconds
[2022-04-07 18:51:09,941] {processor.py:163} INFO - Started process (PID=5175) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:09,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:51:09,945] {logging_mixin.py:109} INFO - [2022-04-07 18:51:09,945] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:10,839] {logging_mixin.py:109} INFO - [2022-04-07 18:51:10,837] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:51:10,840] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:10,863] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.927 seconds
[2022-04-07 18:51:18,923] {processor.py:163} INFO - Started process (PID=5184) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:18,925] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:51:18,926] {logging_mixin.py:109} INFO - [2022-04-07 18:51:18,926] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:19,775] {logging_mixin.py:109} INFO - [2022-04-07 18:51:19,773] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:51:19,775] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:19,798] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.882 seconds
[2022-04-07 18:51:49,903] {processor.py:163} INFO - Started process (PID=5224) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:49,906] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:51:49,907] {logging_mixin.py:109} INFO - [2022-04-07 18:51:49,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:50,748] {logging_mixin.py:109} INFO - [2022-04-07 18:51:50,746] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:51:50,748] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:51:50,771] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.874 seconds
[2022-04-07 18:52:20,873] {processor.py:163} INFO - Started process (PID=5252) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:52:20,875] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:52:20,876] {logging_mixin.py:109} INFO - [2022-04-07 18:52:20,876] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:52:21,729] {logging_mixin.py:109} INFO - [2022-04-07 18:52:21,727] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:52:21,729] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:52:21,752] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.884 seconds
[2022-04-07 18:52:51,853] {processor.py:163} INFO - Started process (PID=5291) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:52:51,856] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:52:51,857] {logging_mixin.py:109} INFO - [2022-04-07 18:52:51,857] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:52:52,713] {logging_mixin.py:109} INFO - [2022-04-07 18:52:52,711] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:52:52,713] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:52:52,735] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.887 seconds
[2022-04-07 18:53:22,834] {processor.py:163} INFO - Started process (PID=5320) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:53:22,837] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:53:22,838] {logging_mixin.py:109} INFO - [2022-04-07 18:53:22,838] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:53:23,692] {logging_mixin.py:109} INFO - [2022-04-07 18:53:23,690] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:53:23,692] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:53:23,715] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.886 seconds
[2022-04-07 18:53:53,776] {processor.py:163} INFO - Started process (PID=5360) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:53:53,780] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:53:53,782] {logging_mixin.py:109} INFO - [2022-04-07 18:53:53,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:53:54,661] {logging_mixin.py:109} INFO - [2022-04-07 18:53:54,659] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:53:54,661] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:53:54,687] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.916 seconds
[2022-04-07 18:54:24,794] {processor.py:163} INFO - Started process (PID=5390) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:54:24,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:54:24,798] {logging_mixin.py:109} INFO - [2022-04-07 18:54:24,797] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:54:25,645] {logging_mixin.py:109} INFO - [2022-04-07 18:54:25,643] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/load_to_BigQuery_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_to_BigQuery_dag.py", line 60, in <module>
    "sourceUris": [f"gs://{BUCKET}/BigQuery/{table}*/*.parquet"],
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1048, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 188, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 547, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (create_badges_stack_overflow_data _external_table) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2022-04-07 18:54:25,646] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:54:25,667] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.878 seconds
[2022-04-07 18:54:49,766] {processor.py:163} INFO - Started process (PID=5418) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:54:49,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:54:49,769] {logging_mixin.py:109} INFO - [2022-04-07 18:54:49,769] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:54:50,724] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:54:55,100] {logging_mixin.py:109} INFO - [2022-04-07 18:54:55,100] {manager.py:496} INFO - Created Permission View: can read on DAG:load_to_BigQuery
[2022-04-07 18:54:55,109] {logging_mixin.py:109} INFO - [2022-04-07 18:54:55,109] {manager.py:496} INFO - Created Permission View: can edit on DAG:load_to_BigQuery
[2022-04-07 18:54:55,109] {logging_mixin.py:109} INFO - [2022-04-07 18:54:55,109] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:54:55,117] {logging_mixin.py:109} INFO - [2022-04-07 18:54:55,117] {dag.py:2417} INFO - Creating ORM DAG for load_to_BigQuery
[2022-04-07 18:54:55,129] {logging_mixin.py:109} INFO - [2022-04-07 18:54:55,129] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 18:54:55,145] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.385 seconds
[2022-04-07 18:55:25,207] {processor.py:163} INFO - Started process (PID=5551) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:55:25,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:55:25,211] {logging_mixin.py:109} INFO - [2022-04-07 18:55:25,211] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:55:26,077] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:55:26,105] {logging_mixin.py:109} INFO - [2022-04-07 18:55:26,105] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:55:26,134] {logging_mixin.py:109} INFO - [2022-04-07 18:55:26,133] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:55:26,145] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.945 seconds
[2022-04-07 18:55:56,294] {processor.py:163} INFO - Started process (PID=5581) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:55:56,296] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:55:56,297] {logging_mixin.py:109} INFO - [2022-04-07 18:55:56,297] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:55:57,154] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:55:57,178] {logging_mixin.py:109} INFO - [2022-04-07 18:55:57,178] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:55:57,197] {logging_mixin.py:109} INFO - [2022-04-07 18:55:57,197] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:55:57,207] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.918 seconds
[2022-04-07 18:56:27,315] {processor.py:163} INFO - Started process (PID=5618) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:56:27,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:56:27,323] {logging_mixin.py:109} INFO - [2022-04-07 18:56:27,322] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:56:28,300] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:56:28,331] {logging_mixin.py:109} INFO - [2022-04-07 18:56:28,330] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:56:28,359] {logging_mixin.py:109} INFO - [2022-04-07 18:56:28,358] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:56:28,373] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.063 seconds
[2022-04-07 18:56:32,440] {processor.py:163} INFO - Started process (PID=5627) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:56:32,442] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:56:32,443] {logging_mixin.py:109} INFO - [2022-04-07 18:56:32,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:56:33,306] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:56:33,330] {logging_mixin.py:109} INFO - [2022-04-07 18:56:33,330] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:56:33,349] {logging_mixin.py:109} INFO - [2022-04-07 18:56:33,349] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:56:33,360] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.927 seconds
[2022-04-07 18:57:03,452] {processor.py:163} INFO - Started process (PID=5666) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:57:03,454] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:57:03,456] {logging_mixin.py:109} INFO - [2022-04-07 18:57:03,455] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:57:04,364] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:57:04,388] {logging_mixin.py:109} INFO - [2022-04-07 18:57:04,388] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:57:04,408] {logging_mixin.py:109} INFO - [2022-04-07 18:57:04,408] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:57:04,419] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.973 seconds
[2022-04-07 18:57:34,561] {processor.py:163} INFO - Started process (PID=5694) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:57:34,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:57:34,564] {logging_mixin.py:109} INFO - [2022-04-07 18:57:34,564] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:57:35,439] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:57:35,462] {logging_mixin.py:109} INFO - [2022-04-07 18:57:35,461] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:57:35,481] {logging_mixin.py:109} INFO - [2022-04-07 18:57:35,481] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:57:35,491] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.935 seconds
[2022-04-07 18:58:05,654] {processor.py:163} INFO - Started process (PID=5732) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:58:05,657] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:58:05,659] {logging_mixin.py:109} INFO - [2022-04-07 18:58:05,658] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:58:06,610] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:58:06,639] {logging_mixin.py:109} INFO - [2022-04-07 18:58:06,639] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:58:06,669] {logging_mixin.py:109} INFO - [2022-04-07 18:58:06,669] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:58:06,684] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.037 seconds
[2022-04-07 18:58:36,775] {processor.py:163} INFO - Started process (PID=5762) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:58:36,776] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:58:36,777] {logging_mixin.py:109} INFO - [2022-04-07 18:58:36,777] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:58:37,661] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:58:37,686] {logging_mixin.py:109} INFO - [2022-04-07 18:58:37,685] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:58:37,705] {logging_mixin.py:109} INFO - [2022-04-07 18:58:37,704] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:58:37,714] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 18:59:07,878] {processor.py:163} INFO - Started process (PID=5800) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:59:07,880] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:59:07,881] {logging_mixin.py:109} INFO - [2022-04-07 18:59:07,881] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:59:08,923] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:59:08,947] {logging_mixin.py:109} INFO - [2022-04-07 18:59:08,946] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:59:08,966] {logging_mixin.py:109} INFO - [2022-04-07 18:59:08,966] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:59:08,976] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.103 seconds
[2022-04-07 18:59:39,069] {processor.py:163} INFO - Started process (PID=5828) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:59:39,071] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 18:59:39,072] {logging_mixin.py:109} INFO - [2022-04-07 18:59:39,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:59:40,005] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 18:59:40,029] {logging_mixin.py:109} INFO - [2022-04-07 18:59:40,028] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 18:59:40,051] {logging_mixin.py:109} INFO - [2022-04-07 18:59:40,051] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 18:59:40,064] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.000 seconds
[2022-04-07 19:00:08,184] {processor.py:163} INFO - Started process (PID=5865) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:00:08,187] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:00:08,188] {logging_mixin.py:109} INFO - [2022-04-07 19:00:08,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:00:09,080] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:00:09,108] {logging_mixin.py:109} INFO - [2022-04-07 19:00:09,107] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:00:09,127] {logging_mixin.py:109} INFO - [2022-04-07 19:00:09,127] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-10-01T00:00:00+00:00
[2022-04-07 19:00:09,141] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.961 seconds
[2022-04-07 19:00:39,352] {processor.py:163} INFO - Started process (PID=5949) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:00:39,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:00:39,356] {logging_mixin.py:109} INFO - [2022-04-07 19:00:39,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:00:43,745] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:00:43,864] {logging_mixin.py:109} INFO - [2022-04-07 19:00:43,864] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:00:44,111] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.770 seconds
[2022-04-07 19:01:14,295] {processor.py:163} INFO - Started process (PID=6027) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:01:14,298] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:01:14,299] {logging_mixin.py:109} INFO - [2022-04-07 19:01:14,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:01:15,456] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:01:15,481] {logging_mixin.py:109} INFO - [2022-04-07 19:01:15,481] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:01:15,503] {logging_mixin.py:109} INFO - [2022-04-07 19:01:15,502] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:01:15,514] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.226 seconds
[2022-04-07 19:01:45,595] {processor.py:163} INFO - Started process (PID=6057) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:01:45,600] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:01:45,601] {logging_mixin.py:109} INFO - [2022-04-07 19:01:45,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:01:46,502] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:01:46,528] {logging_mixin.py:109} INFO - [2022-04-07 19:01:46,527] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:01:46,548] {logging_mixin.py:109} INFO - [2022-04-07 19:01:46,547] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:01:46,558] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.968 seconds
[2022-04-07 19:02:16,723] {processor.py:163} INFO - Started process (PID=6097) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:02:16,726] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:02:16,727] {logging_mixin.py:109} INFO - [2022-04-07 19:02:16,727] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:02:18,050] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:02:18,082] {logging_mixin.py:109} INFO - [2022-04-07 19:02:18,082] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:02:18,103] {logging_mixin.py:109} INFO - [2022-04-07 19:02:18,102] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:02:18,113] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.396 seconds
[2022-04-07 19:02:48,217] {processor.py:163} INFO - Started process (PID=6125) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:02:48,219] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:02:48,220] {logging_mixin.py:109} INFO - [2022-04-07 19:02:48,220] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:02:49,101] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:02:49,125] {logging_mixin.py:109} INFO - [2022-04-07 19:02:49,124] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:02:49,146] {logging_mixin.py:109} INFO - [2022-04-07 19:02:49,146] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:02:49,159] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.947 seconds
[2022-04-07 19:03:19,264] {processor.py:163} INFO - Started process (PID=6162) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:03:19,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:03:19,268] {logging_mixin.py:109} INFO - [2022-04-07 19:03:19,268] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:03:20,334] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:03:20,360] {logging_mixin.py:109} INFO - [2022-04-07 19:03:20,359] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:03:20,380] {logging_mixin.py:109} INFO - [2022-04-07 19:03:20,380] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:03:20,393] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.134 seconds
[2022-04-07 19:05:25,357] {processor.py:163} INFO - Started process (PID=194) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:05:25,364] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:05:25,365] {logging_mixin.py:109} INFO - [2022-04-07 19:05:25,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:05:28,213] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:05:28,239] {logging_mixin.py:109} INFO - [2022-04-07 19:05:28,238] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:05:28,261] {logging_mixin.py:109} INFO - [2022-04-07 19:05:28,260] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:05:28,274] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 2.922 seconds
[2022-04-07 19:05:58,384] {processor.py:163} INFO - Started process (PID=224) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:05:58,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:05:58,387] {logging_mixin.py:109} INFO - [2022-04-07 19:05:58,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:05:59,257] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:05:59,281] {logging_mixin.py:109} INFO - [2022-04-07 19:05:59,281] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:05:59,413] {logging_mixin.py:109} INFO - [2022-04-07 19:05:59,413] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:05:59,423] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.044 seconds
[2022-04-07 19:06:29,507] {processor.py:163} INFO - Started process (PID=265) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:06:29,509] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:06:29,510] {logging_mixin.py:109} INFO - [2022-04-07 19:06:29,509] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:06:30,342] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:06:30,366] {logging_mixin.py:109} INFO - [2022-04-07 19:06:30,366] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:06:30,495] {logging_mixin.py:109} INFO - [2022-04-07 19:06:30,495] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:06:30,507] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.004 seconds
[2022-04-07 19:07:00,628] {processor.py:163} INFO - Started process (PID=294) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:07:00,631] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:07:00,632] {logging_mixin.py:109} INFO - [2022-04-07 19:07:00,632] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:07:01,506] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:07:01,529] {logging_mixin.py:109} INFO - [2022-04-07 19:07:01,528] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:07:01,649] {logging_mixin.py:109} INFO - [2022-04-07 19:07:01,649] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-01-01T00:00:00+00:00
[2022-04-07 19:07:01,659] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.035 seconds
[2022-04-07 19:07:31,842] {processor.py:163} INFO - Started process (PID=400) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:07:31,845] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:07:31,846] {logging_mixin.py:109} INFO - [2022-04-07 19:07:31,846] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:07:39,017] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:07:39,972] {logging_mixin.py:109} INFO - [2022-04-07 19:07:39,964] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:07:40,195] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.375 seconds
[2022-04-07 19:08:10,516] {processor.py:163} INFO - Started process (PID=554) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:08:10,519] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:08:10,520] {logging_mixin.py:109} INFO - [2022-04-07 19:08:10,520] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:08:11,452] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:08:11,580] {logging_mixin.py:109} INFO - [2022-04-07 19:08:11,580] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:08:11,600] {logging_mixin.py:109} INFO - [2022-04-07 19:08:11,600] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:08:11,611] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.100 seconds
[2022-04-07 19:08:41,704] {processor.py:163} INFO - Started process (PID=584) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:08:41,706] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:08:41,707] {logging_mixin.py:109} INFO - [2022-04-07 19:08:41,707] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:08:42,652] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:08:42,675] {logging_mixin.py:109} INFO - [2022-04-07 19:08:42,675] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:08:42,696] {logging_mixin.py:109} INFO - [2022-04-07 19:08:42,696] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:08:42,708] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.009 seconds
[2022-04-07 19:09:12,842] {processor.py:163} INFO - Started process (PID=623) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:09:12,847] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:09:12,849] {logging_mixin.py:109} INFO - [2022-04-07 19:09:12,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:09:14,205] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:09:14,232] {logging_mixin.py:109} INFO - [2022-04-07 19:09:14,232] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:09:14,251] {logging_mixin.py:109} INFO - [2022-04-07 19:09:14,251] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:09:14,262] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.425 seconds
[2022-04-07 19:09:44,356] {processor.py:163} INFO - Started process (PID=653) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:09:44,359] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:09:44,360] {logging_mixin.py:109} INFO - [2022-04-07 19:09:44,360] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:09:45,338] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:09:45,360] {logging_mixin.py:109} INFO - [2022-04-07 19:09:45,360] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:09:45,379] {logging_mixin.py:109} INFO - [2022-04-07 19:09:45,379] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:09:45,388] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.037 seconds
[2022-04-07 19:10:15,481] {processor.py:163} INFO - Started process (PID=691) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:10:15,483] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:10:15,484] {logging_mixin.py:109} INFO - [2022-04-07 19:10:15,484] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:10:16,758] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:10:16,781] {logging_mixin.py:109} INFO - [2022-04-07 19:10:16,781] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:10:16,800] {logging_mixin.py:109} INFO - [2022-04-07 19:10:16,800] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:10:16,811] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.336 seconds
[2022-04-07 19:10:46,941] {processor.py:163} INFO - Started process (PID=720) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:10:46,943] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:10:46,944] {logging_mixin.py:109} INFO - [2022-04-07 19:10:46,944] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:10:47,924] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:10:47,956] {logging_mixin.py:109} INFO - [2022-04-07 19:10:47,956] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:10:47,981] {logging_mixin.py:109} INFO - [2022-04-07 19:10:47,981] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:10:47,992] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.056 seconds
[2022-04-07 19:11:18,053] {processor.py:163} INFO - Started process (PID=758) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:11:18,056] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:11:18,057] {logging_mixin.py:109} INFO - [2022-04-07 19:11:18,057] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:11:19,277] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:11:19,299] {logging_mixin.py:109} INFO - [2022-04-07 19:11:19,298] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:11:19,318] {logging_mixin.py:109} INFO - [2022-04-07 19:11:19,318] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:11:19,329] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.281 seconds
[2022-04-07 19:11:49,430] {processor.py:163} INFO - Started process (PID=787) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:11:49,433] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:11:49,434] {logging_mixin.py:109} INFO - [2022-04-07 19:11:49,434] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:11:50,479] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:11:50,502] {logging_mixin.py:109} INFO - [2022-04-07 19:11:50,501] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:11:50,530] {logging_mixin.py:109} INFO - [2022-04-07 19:11:50,530] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:11:50,542] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.117 seconds
[2022-04-07 19:12:20,672] {processor.py:163} INFO - Started process (PID=824) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:12:20,675] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:12:20,676] {logging_mixin.py:109} INFO - [2022-04-07 19:12:20,676] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:12:22,020] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:12:22,050] {logging_mixin.py:109} INFO - [2022-04-07 19:12:22,050] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:12:22,079] {logging_mixin.py:109} INFO - [2022-04-07 19:12:22,079] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:12:22,092] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.427 seconds
[2022-04-07 19:12:52,215] {processor.py:163} INFO - Started process (PID=917) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:12:52,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:12:52,221] {logging_mixin.py:109} INFO - [2022-04-07 19:12:52,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:14:41,392] {processor.py:163} INFO - Started process (PID=194) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:14:41,398] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:14:41,400] {logging_mixin.py:109} INFO - [2022-04-07 19:14:41,400] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:14:44,357] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:14:45,012] {logging_mixin.py:109} INFO - [2022-04-07 19:14:45,012] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:14:45,032] {logging_mixin.py:109} INFO - [2022-04-07 19:14:45,031] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:14:45,045] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.658 seconds
[2022-04-07 19:15:15,148] {processor.py:163} INFO - Started process (PID=228) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:15:15,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:15:15,153] {logging_mixin.py:109} INFO - [2022-04-07 19:15:15,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:15:16,194] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:15:16,218] {logging_mixin.py:109} INFO - [2022-04-07 19:15:16,217] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:15:16,339] {logging_mixin.py:109} INFO - [2022-04-07 19:15:16,339] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:15:16,349] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.206 seconds
[2022-04-07 19:15:46,446] {processor.py:163} INFO - Started process (PID=267) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:15:46,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:15:46,449] {logging_mixin.py:109} INFO - [2022-04-07 19:15:46,449] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:15:47,287] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:15:47,313] {logging_mixin.py:109} INFO - [2022-04-07 19:15:47,313] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:15:47,433] {logging_mixin.py:109} INFO - [2022-04-07 19:15:47,433] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:15:47,445] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.004 seconds
[2022-04-07 19:16:17,570] {processor.py:163} INFO - Started process (PID=295) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:16:17,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:16:17,576] {logging_mixin.py:109} INFO - [2022-04-07 19:16:17,575] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:16:18,499] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:16:18,522] {logging_mixin.py:109} INFO - [2022-04-07 19:16:18,522] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:16:18,643] {logging_mixin.py:109} INFO - [2022-04-07 19:16:18,643] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-08-01T00:00:00+00:00
[2022-04-07 19:16:18,662] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.097 seconds
[2022-04-07 19:16:48,749] {processor.py:163} INFO - Started process (PID=421) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:16:48,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:16:48,751] {logging_mixin.py:109} INFO - [2022-04-07 19:16:48,751] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:16:49,585] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:16:49,714] {logging_mixin.py:109} INFO - [2022-04-07 19:16:49,713] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:16:49,733] {logging_mixin.py:109} INFO - [2022-04-07 19:16:49,733] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2009-10-01T00:00:00+00:00
[2022-04-07 19:16:49,745] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.001 seconds
[2022-04-07 19:17:20,182] {processor.py:163} INFO - Started process (PID=656) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:17:20,193] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:17:20,194] {logging_mixin.py:109} INFO - [2022-04-07 19:17:20,194] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:17:25,030] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:17:25,389] {logging_mixin.py:109} INFO - [2022-04-07 19:17:25,389] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:17:25,416] {logging_mixin.py:109} INFO - [2022-04-07 19:17:25,415] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2010-07-01T00:00:00+00:00
[2022-04-07 19:17:25,434] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.257 seconds
[2022-04-07 19:17:55,859] {processor.py:163} INFO - Started process (PID=897) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:17:55,889] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:17:55,891] {logging_mixin.py:109} INFO - [2022-04-07 19:17:55,890] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:02,611] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:02,639] {logging_mixin.py:109} INFO - [2022-04-07 19:18:02,639] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:18:02,660] {logging_mixin.py:109} INFO - [2022-04-07 19:18:02,660] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2011-04-01T00:00:00+00:00
[2022-04-07 19:18:02,672] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.872 seconds
[2022-04-07 19:18:09,894] {processor.py:163} INFO - Started process (PID=968) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:09,914] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:18:09,915] {logging_mixin.py:109} INFO - [2022-04-07 19:18:09,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:18,773] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:20,113] {logging_mixin.py:109} INFO - [2022-04-07 19:18:20,112] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:18:20,178] {logging_mixin.py:109} INFO - [2022-04-07 19:18:20,178] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2011-09-01T00:00:00+00:00
[2022-04-07 19:18:20,280] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 10.415 seconds
[2022-04-07 19:18:50,531] {processor.py:163} INFO - Started process (PID=1281) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:50,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:18:50,619] {logging_mixin.py:109} INFO - [2022-04-07 19:18:50,619] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:58,950] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:18:59,001] {logging_mixin.py:109} INFO - [2022-04-07 19:18:59,000] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:18:59,085] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.560 seconds
[2022-04-07 19:19:29,238] {processor.py:163} INFO - Started process (PID=1523) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:19:29,243] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:19:29,245] {logging_mixin.py:109} INFO - [2022-04-07 19:19:29,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:19:36,966] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:19:37,093] {logging_mixin.py:109} INFO - [2022-04-07 19:19:37,092] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:19:37,341] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.110 seconds
[2022-04-07 19:20:07,818] {processor.py:163} INFO - Started process (PID=1826) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:20:07,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:20:07,834] {logging_mixin.py:109} INFO - [2022-04-07 19:20:07,834] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:20:16,589] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:20:16,616] {logging_mixin.py:109} INFO - [2022-04-07 19:20:16,616] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:20:16,642] {logging_mixin.py:109} INFO - [2022-04-07 19:20:16,642] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2014-01-01T00:00:00+00:00
[2022-04-07 19:20:16,657] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.888 seconds
[2022-04-07 19:20:30,853] {processor.py:163} INFO - Started process (PID=1967) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:20:30,867] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:20:30,874] {logging_mixin.py:109} INFO - [2022-04-07 19:20:30,874] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:20:34,229] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:20:35,035] {logging_mixin.py:109} INFO - [2022-04-07 19:20:35,035] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:20:35,061] {logging_mixin.py:109} INFO - [2022-04-07 19:20:35,061] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2014-06-01T00:00:00+00:00
[2022-04-07 19:20:35,094] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.289 seconds
[2022-04-07 19:21:05,270] {processor.py:163} INFO - Started process (PID=2204) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:21:05,273] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:21:05,273] {logging_mixin.py:109} INFO - [2022-04-07 19:21:05,273] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:21:06,290] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:21:06,333] {logging_mixin.py:109} INFO - [2022-04-07 19:21:06,332] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:21:06,384] {logging_mixin.py:109} INFO - [2022-04-07 19:21:06,384] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2014-12-01T00:00:00+00:00
[2022-04-07 19:21:06,400] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.137 seconds
[2022-04-07 19:21:36,694] {processor.py:163} INFO - Started process (PID=2448) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:21:36,696] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:21:36,697] {logging_mixin.py:109} INFO - [2022-04-07 19:21:36,697] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:21:43,979] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:21:44,028] {logging_mixin.py:109} INFO - [2022-04-07 19:21:44,028] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:21:44,135] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 7.456 seconds
[2022-04-07 19:22:14,531] {processor.py:163} INFO - Started process (PID=2739) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:22:14,566] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:22:14,582] {logging_mixin.py:109} INFO - [2022-04-07 19:22:14,579] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:22:22,931] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:22:23,085] {logging_mixin.py:109} INFO - [2022-04-07 19:22:23,085] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:22:23,246] {logging_mixin.py:109} INFO - [2022-04-07 19:22:23,245] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2015-09-01T00:00:00+00:00
[2022-04-07 19:22:23,352] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.852 seconds
[2022-04-07 19:22:53,737] {processor.py:163} INFO - Started process (PID=3047) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:22:53,794] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:22:53,848] {logging_mixin.py:109} INFO - [2022-04-07 19:22:53,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:22:58,414] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:22:58,465] {logging_mixin.py:109} INFO - [2022-04-07 19:22:58,464] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:22:58,519] {logging_mixin.py:109} INFO - [2022-04-07 19:22:58,518] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2016-02-01T00:00:00+00:00
[2022-04-07 19:22:58,534] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.945 seconds
[2022-04-07 19:23:28,962] {processor.py:163} INFO - Started process (PID=3312) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:23:28,969] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:23:28,977] {logging_mixin.py:109} INFO - [2022-04-07 19:23:28,973] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:23:34,161] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:23:34,319] {logging_mixin.py:109} INFO - [2022-04-07 19:23:34,319] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:23:34,459] {logging_mixin.py:109} INFO - [2022-04-07 19:23:34,459] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2016-09-01T00:00:00+00:00
[2022-04-07 19:23:34,540] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.596 seconds
[2022-04-07 19:24:04,847] {processor.py:163} INFO - Started process (PID=3597) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:24:04,889] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:24:04,891] {logging_mixin.py:109} INFO - [2022-04-07 19:24:04,890] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:24:12,684] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:24:12,775] {logging_mixin.py:109} INFO - [2022-04-07 19:24:12,774] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:24:12,849] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.028 seconds
[2022-04-07 19:24:43,322] {processor.py:163} INFO - Started process (PID=3895) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:24:43,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:24:43,350] {logging_mixin.py:109} INFO - [2022-04-07 19:24:43,350] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:24:49,862] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:24:50,095] {logging_mixin.py:109} INFO - [2022-04-07 19:24:50,094] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:24:50,515] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 7.199 seconds
[2022-04-07 19:25:21,015] {processor.py:163} INFO - Started process (PID=4142) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:25:21,024] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:25:21,078] {logging_mixin.py:109} INFO - [2022-04-07 19:25:21,078] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:25:24,254] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:25:24,280] {logging_mixin.py:109} INFO - [2022-04-07 19:25:24,280] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:25:24,303] {logging_mixin.py:109} INFO - [2022-04-07 19:25:24,303] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2017-10-01T00:00:00+00:00
[2022-04-07 19:25:24,314] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.347 seconds
[2022-04-07 19:25:54,635] {processor.py:163} INFO - Started process (PID=4377) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:25:54,672] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:25:54,674] {logging_mixin.py:109} INFO - [2022-04-07 19:25:54,673] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:25:58,705] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:25:58,769] {logging_mixin.py:109} INFO - [2022-04-07 19:25:58,769] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:25:58,819] {logging_mixin.py:109} INFO - [2022-04-07 19:25:58,818] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2018-03-01T00:00:00+00:00
[2022-04-07 19:25:58,852] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.223 seconds
[2022-04-07 19:26:01,652] {processor.py:163} INFO - Started process (PID=4427) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:26:01,655] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:26:01,656] {logging_mixin.py:109} INFO - [2022-04-07 19:26:01,656] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:26:10,715] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:26:11,949] {logging_mixin.py:109} INFO - [2022-04-07 19:26:11,948] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:26:12,119] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 10.506 seconds
[2022-04-07 19:26:42,457] {processor.py:163} INFO - Started process (PID=4723) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:26:42,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:26:42,469] {logging_mixin.py:109} INFO - [2022-04-07 19:26:42,469] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:26:52,867] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:26:53,035] {logging_mixin.py:109} INFO - [2022-04-07 19:26:53,035] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:26:53,273] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 10.855 seconds
[2022-04-07 19:27:23,678] {processor.py:163} INFO - Started process (PID=5030) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:27:23,701] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:27:23,710] {logging_mixin.py:109} INFO - [2022-04-07 19:27:23,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:27:27,684] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:27:27,784] {logging_mixin.py:109} INFO - [2022-04-07 19:27:27,784] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:27:27,923] {logging_mixin.py:109} INFO - [2022-04-07 19:27:27,922] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-03-01T00:00:00+00:00
[2022-04-07 19:27:28,020] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.375 seconds
[2022-04-07 19:27:29,928] {processor.py:163} INFO - Started process (PID=5083) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:27:29,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:27:29,934] {logging_mixin.py:109} INFO - [2022-04-07 19:27:29,931] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:27:39,531] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:27:41,850] {logging_mixin.py:109} INFO - [2022-04-07 19:27:41,850] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:27:41,972] {logging_mixin.py:109} INFO - [2022-04-07 19:27:41,972] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-06-01T00:00:00+00:00
[2022-04-07 19:27:42,078] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 12.188 seconds
[2022-04-07 19:28:12,621] {processor.py:163} INFO - Started process (PID=5413) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:28:12,624] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:28:12,625] {logging_mixin.py:109} INFO - [2022-04-07 19:28:12,625] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:28:22,507] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:28:22,917] {logging_mixin.py:109} INFO - [2022-04-07 19:28:22,916] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:28:23,404] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 10.788 seconds
[2022-04-07 19:28:53,846] {processor.py:163} INFO - Started process (PID=5546) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:28:53,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:28:53,849] {logging_mixin.py:109} INFO - [2022-04-07 19:28:53,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:28:54,912] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:28:54,933] {logging_mixin.py:109} INFO - [2022-04-07 19:28:54,933] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:28:54,951] {logging_mixin.py:109} INFO - [2022-04-07 19:28:54,951] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:28:54,960] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.119 seconds
[2022-04-07 19:29:25,055] {processor.py:163} INFO - Started process (PID=5587) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:29:25,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:29:25,061] {logging_mixin.py:109} INFO - [2022-04-07 19:29:25,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:29:26,071] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:29:26,094] {logging_mixin.py:109} INFO - [2022-04-07 19:29:26,094] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:29:26,114] {logging_mixin.py:109} INFO - [2022-04-07 19:29:26,114] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:29:26,124] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.074 seconds
[2022-04-07 19:29:56,240] {processor.py:163} INFO - Started process (PID=5614) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:29:56,244] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:29:56,245] {logging_mixin.py:109} INFO - [2022-04-07 19:29:56,245] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:29:57,207] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:29:57,231] {logging_mixin.py:109} INFO - [2022-04-07 19:29:57,231] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:29:57,253] {logging_mixin.py:109} INFO - [2022-04-07 19:29:57,253] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:29:57,264] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.028 seconds
[2022-04-07 19:30:27,353] {processor.py:163} INFO - Started process (PID=5652) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:30:27,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:30:27,356] {logging_mixin.py:109} INFO - [2022-04-07 19:30:27,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:30:28,358] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:30:28,388] {logging_mixin.py:109} INFO - [2022-04-07 19:30:28,387] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:30:28,416] {logging_mixin.py:109} INFO - [2022-04-07 19:30:28,416] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:30:28,427] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.080 seconds
[2022-04-07 19:30:58,467] {processor.py:163} INFO - Started process (PID=5680) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:30:58,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:30:58,470] {logging_mixin.py:109} INFO - [2022-04-07 19:30:58,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:30:59,502] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:30:59,525] {logging_mixin.py:109} INFO - [2022-04-07 19:30:59,525] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:30:59,547] {logging_mixin.py:109} INFO - [2022-04-07 19:30:59,547] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:30:59,557] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.096 seconds
[2022-04-07 19:31:29,635] {processor.py:163} INFO - Started process (PID=5719) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:31:29,636] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:31:29,637] {logging_mixin.py:109} INFO - [2022-04-07 19:31:29,637] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:31:30,675] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:31:30,699] {logging_mixin.py:109} INFO - [2022-04-07 19:31:30,699] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:31:30,721] {logging_mixin.py:109} INFO - [2022-04-07 19:31:30,721] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:31:30,732] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.104 seconds
[2022-04-07 19:32:00,822] {processor.py:163} INFO - Started process (PID=5747) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:32:00,825] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:32:00,826] {logging_mixin.py:109} INFO - [2022-04-07 19:32:00,826] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:32:01,789] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:32:01,814] {logging_mixin.py:109} INFO - [2022-04-07 19:32:01,814] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:32:01,843] {logging_mixin.py:109} INFO - [2022-04-07 19:32:01,843] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:32:01,856] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.039 seconds
[2022-04-07 19:32:31,934] {processor.py:163} INFO - Started process (PID=5785) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:32:31,936] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:32:31,937] {logging_mixin.py:109} INFO - [2022-04-07 19:32:31,937] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:32:32,886] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:32:32,909] {logging_mixin.py:109} INFO - [2022-04-07 19:32:32,909] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:32:32,928] {logging_mixin.py:109} INFO - [2022-04-07 19:32:32,928] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:32:32,939] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.009 seconds
[2022-04-07 19:33:03,063] {processor.py:163} INFO - Started process (PID=5813) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:33:03,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:33:03,066] {logging_mixin.py:109} INFO - [2022-04-07 19:33:03,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:33:04,040] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:33:04,070] {logging_mixin.py:109} INFO - [2022-04-07 19:33:04,069] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:33:04,090] {logging_mixin.py:109} INFO - [2022-04-07 19:33:04,090] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:33:04,101] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.042 seconds
[2022-04-07 19:33:34,196] {processor.py:163} INFO - Started process (PID=5850) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:33:34,197] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:33:34,198] {logging_mixin.py:109} INFO - [2022-04-07 19:33:34,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:33:35,167] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:33:35,192] {logging_mixin.py:109} INFO - [2022-04-07 19:33:35,192] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:33:35,213] {logging_mixin.py:109} INFO - [2022-04-07 19:33:35,213] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:33:35,223] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.032 seconds
[2022-04-07 19:34:05,327] {processor.py:163} INFO - Started process (PID=5878) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:34:05,330] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:34:05,331] {logging_mixin.py:109} INFO - [2022-04-07 19:34:05,331] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:34:06,305] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:34:06,328] {logging_mixin.py:109} INFO - [2022-04-07 19:34:06,328] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:34:06,348] {logging_mixin.py:109} INFO - [2022-04-07 19:34:06,348] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:34:06,357] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.034 seconds
[2022-04-07 19:34:36,452] {processor.py:163} INFO - Started process (PID=5917) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:34:36,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:34:36,454] {logging_mixin.py:109} INFO - [2022-04-07 19:34:36,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:34:37,393] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:34:37,415] {logging_mixin.py:109} INFO - [2022-04-07 19:34:37,415] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:34:37,435] {logging_mixin.py:109} INFO - [2022-04-07 19:34:37,435] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:34:37,445] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.998 seconds
[2022-04-07 19:35:07,580] {processor.py:163} INFO - Started process (PID=5953) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:35:07,583] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:35:07,583] {logging_mixin.py:109} INFO - [2022-04-07 19:35:07,583] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:35:08,561] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:35:08,584] {logging_mixin.py:109} INFO - [2022-04-07 19:35:08,584] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:35:08,602] {logging_mixin.py:109} INFO - [2022-04-07 19:35:08,602] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:35:08,613] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.037 seconds
[2022-04-07 19:35:38,697] {processor.py:163} INFO - Started process (PID=5985) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:35:38,699] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:35:38,700] {logging_mixin.py:109} INFO - [2022-04-07 19:35:38,700] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:35:39,641] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:35:39,665] {logging_mixin.py:109} INFO - [2022-04-07 19:35:39,665] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:35:39,689] {logging_mixin.py:109} INFO - [2022-04-07 19:35:39,689] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:35:39,699] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 19:36:09,822] {processor.py:163} INFO - Started process (PID=6026) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:36:09,824] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:36:09,825] {logging_mixin.py:109} INFO - [2022-04-07 19:36:09,825] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:36:10,875] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:36:10,901] {logging_mixin.py:109} INFO - [2022-04-07 19:36:10,900] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:36:10,919] {logging_mixin.py:109} INFO - [2022-04-07 19:36:10,919] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:36:10,929] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.112 seconds
[2022-04-07 19:36:41,019] {processor.py:163} INFO - Started process (PID=6054) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:36:41,021] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:36:41,022] {logging_mixin.py:109} INFO - [2022-04-07 19:36:41,022] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:36:41,972] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:36:41,993] {logging_mixin.py:109} INFO - [2022-04-07 19:36:41,992] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:36:42,012] {logging_mixin.py:109} INFO - [2022-04-07 19:36:42,012] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:36:42,022] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 19:37:12,142] {processor.py:163} INFO - Started process (PID=6092) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:37:12,145] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:37:12,146] {logging_mixin.py:109} INFO - [2022-04-07 19:37:12,146] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:37:13,194] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:37:13,219] {logging_mixin.py:109} INFO - [2022-04-07 19:37:13,218] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:37:13,239] {logging_mixin.py:109} INFO - [2022-04-07 19:37:13,239] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:37:13,249] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.114 seconds
[2022-04-07 19:37:43,344] {processor.py:163} INFO - Started process (PID=6123) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:37:43,346] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:37:43,347] {logging_mixin.py:109} INFO - [2022-04-07 19:37:43,347] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:37:44,604] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:37:44,644] {logging_mixin.py:109} INFO - [2022-04-07 19:37:44,643] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:37:44,672] {logging_mixin.py:109} INFO - [2022-04-07 19:37:44,672] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:37:44,685] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.345 seconds
[2022-04-07 19:38:14,800] {processor.py:163} INFO - Started process (PID=6160) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:38:14,804] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:38:14,806] {logging_mixin.py:109} INFO - [2022-04-07 19:38:14,805] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:38:15,865] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:38:15,888] {logging_mixin.py:109} INFO - [2022-04-07 19:38:15,888] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:38:15,908] {logging_mixin.py:109} INFO - [2022-04-07 19:38:15,908] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:38:15,918] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.125 seconds
[2022-04-07 19:38:46,008] {processor.py:163} INFO - Started process (PID=6188) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:38:46,009] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:38:46,010] {logging_mixin.py:109} INFO - [2022-04-07 19:38:46,010] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:38:46,959] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:38:46,983] {logging_mixin.py:109} INFO - [2022-04-07 19:38:46,982] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:38:47,002] {logging_mixin.py:109} INFO - [2022-04-07 19:38:47,002] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:38:47,012] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.010 seconds
[2022-04-07 19:39:17,133] {processor.py:163} INFO - Started process (PID=6215) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:39:17,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:39:17,137] {logging_mixin.py:109} INFO - [2022-04-07 19:39:17,137] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:39:18,147] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:39:18,170] {logging_mixin.py:109} INFO - [2022-04-07 19:39:18,170] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:39:18,190] {logging_mixin.py:109} INFO - [2022-04-07 19:39:18,190] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:39:18,201] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.073 seconds
[2022-04-07 19:39:48,264] {processor.py:163} INFO - Started process (PID=6254) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:39:48,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:39:48,267] {logging_mixin.py:109} INFO - [2022-04-07 19:39:48,267] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:39:49,228] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:39:49,250] {logging_mixin.py:109} INFO - [2022-04-07 19:39:49,250] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:39:49,269] {logging_mixin.py:109} INFO - [2022-04-07 19:39:49,269] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:39:49,279] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.019 seconds
[2022-04-07 19:40:19,409] {processor.py:163} INFO - Started process (PID=6283) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:40:19,412] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:40:19,413] {logging_mixin.py:109} INFO - [2022-04-07 19:40:19,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:40:20,381] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:40:20,405] {logging_mixin.py:109} INFO - [2022-04-07 19:40:20,404] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:40:20,425] {logging_mixin.py:109} INFO - [2022-04-07 19:40:20,425] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:40:20,435] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.030 seconds
[2022-04-07 19:40:50,525] {processor.py:163} INFO - Started process (PID=6319) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:40:50,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:40:50,527] {logging_mixin.py:109} INFO - [2022-04-07 19:40:50,527] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:40:51,477] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:40:51,499] {logging_mixin.py:109} INFO - [2022-04-07 19:40:51,498] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:40:51,518] {logging_mixin.py:109} INFO - [2022-04-07 19:40:51,518] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:40:51,527] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 19:41:21,648] {processor.py:163} INFO - Started process (PID=6352) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:41:21,650] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:41:21,651] {logging_mixin.py:109} INFO - [2022-04-07 19:41:21,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:41:22,634] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:41:22,658] {logging_mixin.py:109} INFO - [2022-04-07 19:41:22,658] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:41:22,678] {logging_mixin.py:109} INFO - [2022-04-07 19:41:22,678] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:41:22,688] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.044 seconds
[2022-04-07 19:41:52,769] {processor.py:163} INFO - Started process (PID=6388) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:41:52,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:41:52,774] {logging_mixin.py:109} INFO - [2022-04-07 19:41:52,774] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:41:53,737] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:41:53,760] {logging_mixin.py:109} INFO - [2022-04-07 19:41:53,759] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:41:53,779] {logging_mixin.py:109} INFO - [2022-04-07 19:41:53,779] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:41:53,788] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 19:42:23,886] {processor.py:163} INFO - Started process (PID=6416) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:42:23,889] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:42:23,890] {logging_mixin.py:109} INFO - [2022-04-07 19:42:23,890] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:42:24,853] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:42:24,875] {logging_mixin.py:109} INFO - [2022-04-07 19:42:24,874] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:42:24,894] {logging_mixin.py:109} INFO - [2022-04-07 19:42:24,894] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:42:24,903] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.022 seconds
[2022-04-07 19:42:55,014] {processor.py:163} INFO - Started process (PID=6455) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:42:55,016] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:42:55,017] {logging_mixin.py:109} INFO - [2022-04-07 19:42:55,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:42:55,988] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:42:56,012] {logging_mixin.py:109} INFO - [2022-04-07 19:42:56,011] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:42:56,031] {logging_mixin.py:109} INFO - [2022-04-07 19:42:56,031] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:42:56,040] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.031 seconds
[2022-04-07 19:43:26,129] {processor.py:163} INFO - Started process (PID=6483) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:43:26,131] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:43:26,133] {logging_mixin.py:109} INFO - [2022-04-07 19:43:26,132] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:43:27,142] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:43:27,174] {logging_mixin.py:109} INFO - [2022-04-07 19:43:27,174] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:43:27,206] {logging_mixin.py:109} INFO - [2022-04-07 19:43:27,206] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:43:27,219] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.095 seconds
[2022-04-07 19:43:57,261] {processor.py:163} INFO - Started process (PID=6523) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:43:57,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:43:57,264] {logging_mixin.py:109} INFO - [2022-04-07 19:43:57,264] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:43:58,241] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:43:58,269] {logging_mixin.py:109} INFO - [2022-04-07 19:43:58,268] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:43:58,288] {logging_mixin.py:109} INFO - [2022-04-07 19:43:58,288] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:43:58,298] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.042 seconds
[2022-04-07 19:44:28,432] {processor.py:163} INFO - Started process (PID=6552) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:44:28,434] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:44:28,435] {logging_mixin.py:109} INFO - [2022-04-07 19:44:28,435] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:44:29,443] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:44:29,466] {logging_mixin.py:109} INFO - [2022-04-07 19:44:29,466] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:44:29,487] {logging_mixin.py:109} INFO - [2022-04-07 19:44:29,486] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:44:29,496] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.069 seconds
[2022-04-07 19:44:59,580] {processor.py:163} INFO - Started process (PID=6590) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:44:59,582] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:44:59,583] {logging_mixin.py:109} INFO - [2022-04-07 19:44:59,583] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:45:00,543] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:45:00,566] {logging_mixin.py:109} INFO - [2022-04-07 19:45:00,566] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:45:00,585] {logging_mixin.py:109} INFO - [2022-04-07 19:45:00,585] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:45:00,595] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 19:45:30,706] {processor.py:163} INFO - Started process (PID=6618) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:45:30,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:45:30,710] {logging_mixin.py:109} INFO - [2022-04-07 19:45:30,710] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:45:31,682] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:45:31,705] {logging_mixin.py:109} INFO - [2022-04-07 19:45:31,704] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:45:31,727] {logging_mixin.py:109} INFO - [2022-04-07 19:45:31,727] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:45:31,741] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.040 seconds
[2022-04-07 19:46:01,827] {processor.py:163} INFO - Started process (PID=6655) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:01,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:46:01,830] {logging_mixin.py:109} INFO - [2022-04-07 19:46:01,829] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:02,838] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:02,861] {logging_mixin.py:109} INFO - [2022-04-07 19:46:02,861] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:46:02,882] {logging_mixin.py:109} INFO - [2022-04-07 19:46:02,882] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:46:02,895] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.073 seconds
[2022-04-07 19:46:22,921] {processor.py:163} INFO - Started process (PID=6682) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:22,925] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:46:22,926] {logging_mixin.py:109} INFO - [2022-04-07 19:46:22,926] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:24,104] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:24,374] {logging_mixin.py:109} INFO - [2022-04-07 19:46:24,373] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:46:24,394] {logging_mixin.py:109} INFO - [2022-04-07 19:46:24,394] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:46:24,409] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.494 seconds
[2022-04-07 19:46:54,531] {processor.py:163} INFO - Started process (PID=6710) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:54,533] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:46:54,534] {logging_mixin.py:109} INFO - [2022-04-07 19:46:54,533] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:55,526] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:46:55,550] {logging_mixin.py:109} INFO - [2022-04-07 19:46:55,550] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:46:55,575] {logging_mixin.py:109} INFO - [2022-04-07 19:46:55,575] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2019-12-01T00:00:00+00:00
[2022-04-07 19:46:55,586] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.061 seconds
[2022-04-07 19:47:25,867] {processor.py:163} INFO - Started process (PID=6898) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:47:25,901] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:47:25,902] {logging_mixin.py:109} INFO - [2022-04-07 19:47:25,902] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:47:32,233] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:47:32,273] {logging_mixin.py:109} INFO - [2022-04-07 19:47:32,271] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:47:32,326] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.470 seconds
[2022-04-07 19:48:02,543] {processor.py:163} INFO - Started process (PID=7190) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:48:02,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:48:02,557] {logging_mixin.py:109} INFO - [2022-04-07 19:48:02,557] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:48:07,980] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:48:08,157] {logging_mixin.py:109} INFO - [2022-04-07 19:48:08,156] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:48:08,348] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.812 seconds
[2022-04-07 19:48:38,662] {processor.py:163} INFO - Started process (PID=7501) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:48:38,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:48:38,708] {logging_mixin.py:109} INFO - [2022-04-07 19:48:38,708] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:48:46,792] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:48:46,861] {logging_mixin.py:109} INFO - [2022-04-07 19:48:46,860] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:48:46,953] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 8.335 seconds
[2022-04-07 19:49:04,307] {processor.py:163} INFO - Started process (PID=7674) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:49:04,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:49:04,323] {logging_mixin.py:109} INFO - [2022-04-07 19:49:04,323] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:49:12,927] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:49:14,499] {logging_mixin.py:109} INFO - [2022-04-07 19:49:14,498] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:49:14,689] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 10.388 seconds
[2022-04-07 19:49:44,862] {processor.py:163} INFO - Started process (PID=7806) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:49:44,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:49:44,865] {logging_mixin.py:109} INFO - [2022-04-07 19:49:44,865] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:49:45,886] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:49:46,138] {logging_mixin.py:109} INFO - [2022-04-07 19:49:46,137] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:49:46,146] {logging_mixin.py:109} INFO - [2022-04-07 19:49:46,145] {dag.py:2417} INFO - Creating ORM DAG for load_to_BigQuery
[2022-04-07 19:49:46,156] {logging_mixin.py:109} INFO - [2022-04-07 19:49:46,156] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:49:46,171] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.313 seconds
[2022-04-07 19:50:16,277] {processor.py:163} INFO - Started process (PID=7834) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:50:16,284] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:50:16,285] {logging_mixin.py:109} INFO - [2022-04-07 19:50:16,284] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:50:17,272] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:50:17,294] {logging_mixin.py:109} INFO - [2022-04-07 19:50:17,294] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:50:17,313] {logging_mixin.py:109} INFO - [2022-04-07 19:50:17,313] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:50:17,323] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.051 seconds
[2022-04-07 19:50:47,399] {processor.py:163} INFO - Started process (PID=7872) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:50:47,400] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:50:47,402] {logging_mixin.py:109} INFO - [2022-04-07 19:50:47,401] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:50:48,418] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:50:48,441] {logging_mixin.py:109} INFO - [2022-04-07 19:50:48,440] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:50:48,462] {logging_mixin.py:109} INFO - [2022-04-07 19:50:48,461] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:50:48,473] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.079 seconds
[2022-04-07 19:51:18,578] {processor.py:163} INFO - Started process (PID=7909) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:51:18,581] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:51:18,582] {logging_mixin.py:109} INFO - [2022-04-07 19:51:18,582] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:51:19,626] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:51:19,659] {logging_mixin.py:109} INFO - [2022-04-07 19:51:19,658] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:51:19,686] {logging_mixin.py:109} INFO - [2022-04-07 19:51:19,686] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:51:19,699] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.125 seconds
[2022-04-07 19:51:49,799] {processor.py:163} INFO - Started process (PID=7938) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:51:49,801] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:51:49,802] {logging_mixin.py:109} INFO - [2022-04-07 19:51:49,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:51:50,879] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:51:50,902] {logging_mixin.py:109} INFO - [2022-04-07 19:51:50,902] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:51:50,921] {logging_mixin.py:109} INFO - [2022-04-07 19:51:50,921] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:51:50,932] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.137 seconds
[2022-04-07 19:52:21,024] {processor.py:163} INFO - Started process (PID=7976) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:52:21,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:52:21,028] {logging_mixin.py:109} INFO - [2022-04-07 19:52:21,028] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:52:22,068] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:52:22,092] {logging_mixin.py:109} INFO - [2022-04-07 19:52:22,091] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:52:22,112] {logging_mixin.py:109} INFO - [2022-04-07 19:52:22,112] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:52:22,123] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.103 seconds
[2022-04-07 19:52:52,222] {processor.py:163} INFO - Started process (PID=8003) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:52:52,223] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:52:52,224] {logging_mixin.py:109} INFO - [2022-04-07 19:52:52,224] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:52:53,168] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:52:53,190] {logging_mixin.py:109} INFO - [2022-04-07 19:52:53,190] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:52:53,209] {logging_mixin.py:109} INFO - [2022-04-07 19:52:53,209] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:52:53,220] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.003 seconds
[2022-04-07 19:53:23,342] {processor.py:163} INFO - Started process (PID=8040) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:53:23,345] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:53:23,346] {logging_mixin.py:109} INFO - [2022-04-07 19:53:23,346] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:53:24,307] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:53:24,330] {logging_mixin.py:109} INFO - [2022-04-07 19:53:24,329] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:53:24,349] {logging_mixin.py:109} INFO - [2022-04-07 19:53:24,349] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:53:24,358] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.021 seconds
[2022-04-07 19:53:54,457] {processor.py:163} INFO - Started process (PID=8067) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:53:54,459] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:53:54,460] {logging_mixin.py:109} INFO - [2022-04-07 19:53:54,460] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:53:55,411] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:53:55,439] {logging_mixin.py:109} INFO - [2022-04-07 19:53:55,438] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:53:55,466] {logging_mixin.py:109} INFO - [2022-04-07 19:53:55,466] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:53:55,480] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.027 seconds
[2022-04-07 19:54:25,587] {processor.py:163} INFO - Started process (PID=8105) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:54:25,589] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:54:25,590] {logging_mixin.py:109} INFO - [2022-04-07 19:54:25,590] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:54:26,542] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:54:26,563] {logging_mixin.py:109} INFO - [2022-04-07 19:54:26,563] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:54:26,581] {logging_mixin.py:109} INFO - [2022-04-07 19:54:26,581] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:54:26,589] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 19:54:56,726] {processor.py:163} INFO - Started process (PID=8132) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:54:56,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:54:56,733] {logging_mixin.py:109} INFO - [2022-04-07 19:54:56,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:54:57,701] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:54:57,727] {logging_mixin.py:109} INFO - [2022-04-07 19:54:57,727] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:54:57,748] {logging_mixin.py:109} INFO - [2022-04-07 19:54:57,748] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:54:57,759] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.038 seconds
[2022-04-07 19:55:27,846] {processor.py:163} INFO - Started process (PID=8170) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:55:27,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:55:27,849] {logging_mixin.py:109} INFO - [2022-04-07 19:55:27,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:55:28,812] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:55:28,838] {logging_mixin.py:109} INFO - [2022-04-07 19:55:28,837] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:55:28,857] {logging_mixin.py:109} INFO - [2022-04-07 19:55:28,857] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:55:28,870] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.029 seconds
[2022-04-07 19:55:58,974] {processor.py:163} INFO - Started process (PID=8198) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:55:58,976] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:55:58,977] {logging_mixin.py:109} INFO - [2022-04-07 19:55:58,977] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:55:59,926] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:55:59,954] {logging_mixin.py:109} INFO - [2022-04-07 19:55:59,954] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:55:59,974] {logging_mixin.py:109} INFO - [2022-04-07 19:55:59,974] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:55:59,986] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.016 seconds
[2022-04-07 19:56:30,101] {processor.py:163} INFO - Started process (PID=8237) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:56:30,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:56:30,105] {logging_mixin.py:109} INFO - [2022-04-07 19:56:30,104] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:56:31,064] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:56:31,087] {logging_mixin.py:109} INFO - [2022-04-07 19:56:31,086] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:56:31,104] {logging_mixin.py:109} INFO - [2022-04-07 19:56:31,104] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:56:31,115] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.019 seconds
[2022-04-07 19:57:01,224] {processor.py:163} INFO - Started process (PID=8267) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:57:01,227] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:57:01,229] {logging_mixin.py:109} INFO - [2022-04-07 19:57:01,228] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:57:02,271] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:57:02,303] {logging_mixin.py:109} INFO - [2022-04-07 19:57:02,303] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:57:02,323] {logging_mixin.py:109} INFO - [2022-04-07 19:57:02,323] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:57:02,336] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.117 seconds
[2022-04-07 19:57:32,437] {processor.py:163} INFO - Started process (PID=8304) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:57:32,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:57:32,441] {logging_mixin.py:109} INFO - [2022-04-07 19:57:32,441] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:57:33,439] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:57:33,461] {logging_mixin.py:109} INFO - [2022-04-07 19:57:33,461] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:57:33,480] {logging_mixin.py:109} INFO - [2022-04-07 19:57:33,480] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:57:33,490] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.058 seconds
[2022-04-07 19:58:03,549] {processor.py:163} INFO - Started process (PID=8333) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:58:03,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:58:03,551] {logging_mixin.py:109} INFO - [2022-04-07 19:58:03,551] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:58:04,558] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:58:04,584] {logging_mixin.py:109} INFO - [2022-04-07 19:58:04,584] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:58:04,609] {logging_mixin.py:109} INFO - [2022-04-07 19:58:04,609] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:58:04,620] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.076 seconds
[2022-04-07 19:58:34,690] {processor.py:163} INFO - Started process (PID=8372) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:58:34,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:58:34,694] {logging_mixin.py:109} INFO - [2022-04-07 19:58:34,694] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:58:35,738] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:58:35,762] {logging_mixin.py:109} INFO - [2022-04-07 19:58:35,762] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:58:35,782] {logging_mixin.py:109} INFO - [2022-04-07 19:58:35,782] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:58:35,793] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.109 seconds
[2022-04-07 19:59:05,894] {processor.py:163} INFO - Started process (PID=8401) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:59:05,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:59:05,897] {logging_mixin.py:109} INFO - [2022-04-07 19:59:05,896] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:59:06,856] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:59:06,881] {logging_mixin.py:109} INFO - [2022-04-07 19:59:06,880] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:59:06,902] {logging_mixin.py:109} INFO - [2022-04-07 19:59:06,902] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:59:06,915] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.027 seconds
[2022-04-07 19:59:37,033] {processor.py:163} INFO - Started process (PID=8438) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:59:37,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 19:59:37,040] {logging_mixin.py:109} INFO - [2022-04-07 19:59:37,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:59:38,227] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 19:59:38,252] {logging_mixin.py:109} INFO - [2022-04-07 19:59:38,251] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 19:59:38,272] {logging_mixin.py:109} INFO - [2022-04-07 19:59:38,272] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 19:59:38,285] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.263 seconds
[2022-04-07 20:00:08,382] {processor.py:163} INFO - Started process (PID=8467) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:00:08,384] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:00:08,385] {logging_mixin.py:109} INFO - [2022-04-07 20:00:08,385] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:00:09,376] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:00:09,399] {logging_mixin.py:109} INFO - [2022-04-07 20:00:09,399] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:00:09,421] {logging_mixin.py:109} INFO - [2022-04-07 20:00:09,421] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:00:09,432] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.055 seconds
[2022-04-07 20:00:39,495] {processor.py:163} INFO - Started process (PID=8505) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:00:39,497] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:00:39,498] {logging_mixin.py:109} INFO - [2022-04-07 20:00:39,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:00:40,652] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:00:40,687] {logging_mixin.py:109} INFO - [2022-04-07 20:00:40,686] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:00:40,722] {logging_mixin.py:109} INFO - [2022-04-07 20:00:40,722] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:00:40,734] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.245 seconds
[2022-04-07 20:01:10,838] {processor.py:163} INFO - Started process (PID=8534) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:01:10,840] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:01:10,841] {logging_mixin.py:109} INFO - [2022-04-07 20:01:10,841] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:01:11,908] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:01:11,934] {logging_mixin.py:109} INFO - [2022-04-07 20:01:11,933] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:01:11,958] {logging_mixin.py:109} INFO - [2022-04-07 20:01:11,958] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:01:11,972] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.141 seconds
[2022-04-07 20:01:42,079] {processor.py:163} INFO - Started process (PID=8571) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:01:42,081] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:01:42,082] {logging_mixin.py:109} INFO - [2022-04-07 20:01:42,082] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:01:43,158] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:01:43,184] {logging_mixin.py:109} INFO - [2022-04-07 20:01:43,183] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:01:43,206] {logging_mixin.py:109} INFO - [2022-04-07 20:01:43,206] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:01:43,218] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.145 seconds
[2022-04-07 20:02:13,325] {processor.py:163} INFO - Started process (PID=8599) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:02:13,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:02:13,330] {logging_mixin.py:109} INFO - [2022-04-07 20:02:13,329] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:02:14,350] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:02:14,374] {logging_mixin.py:109} INFO - [2022-04-07 20:02:14,373] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:02:14,394] {logging_mixin.py:109} INFO - [2022-04-07 20:02:14,394] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:02:14,405] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.085 seconds
[2022-04-07 20:02:44,497] {processor.py:163} INFO - Started process (PID=8636) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:02:44,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:02:44,501] {logging_mixin.py:109} INFO - [2022-04-07 20:02:44,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:02:45,527] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:02:45,551] {logging_mixin.py:109} INFO - [2022-04-07 20:02:45,550] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:02:45,573] {logging_mixin.py:109} INFO - [2022-04-07 20:02:45,573] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:02:45,586] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.094 seconds
[2022-04-07 20:03:15,685] {processor.py:163} INFO - Started process (PID=8665) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:03:15,691] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:03:15,693] {logging_mixin.py:109} INFO - [2022-04-07 20:03:15,692] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:03:16,701] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:03:16,726] {logging_mixin.py:109} INFO - [2022-04-07 20:03:16,726] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:03:16,746] {logging_mixin.py:109} INFO - [2022-04-07 20:03:16,746] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:03:16,757] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.078 seconds
[2022-04-07 20:03:46,853] {processor.py:163} INFO - Started process (PID=8703) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:03:46,855] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:03:46,857] {logging_mixin.py:109} INFO - [2022-04-07 20:03:46,856] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:03:48,077] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:03:48,104] {logging_mixin.py:109} INFO - [2022-04-07 20:03:48,104] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:03:48,130] {logging_mixin.py:109} INFO - [2022-04-07 20:03:48,130] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:03:48,145] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.298 seconds
[2022-04-07 20:04:18,264] {processor.py:163} INFO - Started process (PID=8730) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:04:18,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:04:18,269] {logging_mixin.py:109} INFO - [2022-04-07 20:04:18,268] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:04:19,429] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:04:19,460] {logging_mixin.py:109} INFO - [2022-04-07 20:04:19,460] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:04:19,485] {logging_mixin.py:109} INFO - [2022-04-07 20:04:19,485] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:04:19,500] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.243 seconds
[2022-04-07 20:04:49,604] {processor.py:163} INFO - Started process (PID=8765) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:04:49,606] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:04:49,607] {logging_mixin.py:109} INFO - [2022-04-07 20:04:49,607] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:04:50,675] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:04:50,698] {logging_mixin.py:109} INFO - [2022-04-07 20:04:50,698] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:04:50,719] {logging_mixin.py:109} INFO - [2022-04-07 20:04:50,719] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:04:50,732] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.133 seconds
[2022-04-07 20:05:20,832] {processor.py:163} INFO - Started process (PID=8795) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:05:20,835] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:05:20,835] {logging_mixin.py:109} INFO - [2022-04-07 20:05:20,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:05:21,875] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:05:21,905] {logging_mixin.py:109} INFO - [2022-04-07 20:05:21,904] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:05:21,926] {logging_mixin.py:109} INFO - [2022-04-07 20:05:21,926] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:05:21,940] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.113 seconds
[2022-04-07 20:05:52,044] {processor.py:163} INFO - Started process (PID=8831) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:05:52,048] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:05:52,050] {logging_mixin.py:109} INFO - [2022-04-07 20:05:52,049] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:05:53,214] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:05:53,243] {logging_mixin.py:109} INFO - [2022-04-07 20:05:53,242] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:05:53,265] {logging_mixin.py:109} INFO - [2022-04-07 20:05:53,265] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:05:53,282] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.243 seconds
[2022-04-07 20:06:23,389] {processor.py:163} INFO - Started process (PID=8858) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:06:23,392] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:06:23,394] {logging_mixin.py:109} INFO - [2022-04-07 20:06:23,393] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:06:24,366] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:06:24,389] {logging_mixin.py:109} INFO - [2022-04-07 20:06:24,388] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:06:24,407] {logging_mixin.py:109} INFO - [2022-04-07 20:06:24,407] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:06:24,418] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.035 seconds
[2022-04-07 20:06:54,503] {processor.py:163} INFO - Started process (PID=8896) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:06:54,505] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:06:54,505] {logging_mixin.py:109} INFO - [2022-04-07 20:06:54,505] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:06:55,468] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:06:55,501] {logging_mixin.py:109} INFO - [2022-04-07 20:06:55,501] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:06:55,531] {logging_mixin.py:109} INFO - [2022-04-07 20:06:55,530] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:06:55,542] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.044 seconds
[2022-04-07 20:07:25,623] {processor.py:163} INFO - Started process (PID=8925) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:07:25,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:07:25,627] {logging_mixin.py:109} INFO - [2022-04-07 20:07:25,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:07:26,668] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:07:26,691] {logging_mixin.py:109} INFO - [2022-04-07 20:07:26,690] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:07:26,710] {logging_mixin.py:109} INFO - [2022-04-07 20:07:26,710] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:07:26,720] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.101 seconds
[2022-04-07 20:07:56,818] {processor.py:163} INFO - Started process (PID=8961) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:07:56,820] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:07:56,821] {logging_mixin.py:109} INFO - [2022-04-07 20:07:56,821] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:07:57,885] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:07:57,909] {logging_mixin.py:109} INFO - [2022-04-07 20:07:57,909] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:07:57,931] {logging_mixin.py:109} INFO - [2022-04-07 20:07:57,931] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:07:57,943] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.130 seconds
[2022-04-07 20:08:28,070] {processor.py:163} INFO - Started process (PID=8992) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:08:28,072] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:08:28,073] {logging_mixin.py:109} INFO - [2022-04-07 20:08:28,073] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:08:29,105] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:08:29,130] {logging_mixin.py:109} INFO - [2022-04-07 20:08:29,129] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:08:29,150] {logging_mixin.py:109} INFO - [2022-04-07 20:08:29,149] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:08:29,161] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.097 seconds
[2022-04-07 20:08:59,258] {processor.py:163} INFO - Started process (PID=9030) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:08:59,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:08:59,264] {logging_mixin.py:109} INFO - [2022-04-07 20:08:59,264] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:09:00,249] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:09:00,273] {logging_mixin.py:109} INFO - [2022-04-07 20:09:00,272] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:09:00,291] {logging_mixin.py:109} INFO - [2022-04-07 20:09:00,291] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:09:00,301] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.049 seconds
[2022-04-07 20:09:30,369] {processor.py:163} INFO - Started process (PID=9059) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:09:30,371] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:09:30,372] {logging_mixin.py:109} INFO - [2022-04-07 20:09:30,372] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:09:31,318] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:09:31,341] {logging_mixin.py:109} INFO - [2022-04-07 20:09:31,341] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:09:31,359] {logging_mixin.py:109} INFO - [2022-04-07 20:09:31,359] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:09:31,369] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.005 seconds
[2022-04-07 20:10:01,524] {processor.py:163} INFO - Started process (PID=9098) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:10:01,527] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:10:01,528] {logging_mixin.py:109} INFO - [2022-04-07 20:10:01,527] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:10:02,497] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:10:02,521] {logging_mixin.py:109} INFO - [2022-04-07 20:10:02,521] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:10:02,542] {logging_mixin.py:109} INFO - [2022-04-07 20:10:02,542] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:10:02,553] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.034 seconds
[2022-04-07 20:10:32,642] {processor.py:163} INFO - Started process (PID=9126) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:10:32,643] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:10:32,644] {logging_mixin.py:109} INFO - [2022-04-07 20:10:32,644] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:10:33,584] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:10:33,606] {logging_mixin.py:109} INFO - [2022-04-07 20:10:33,606] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:10:33,623] {logging_mixin.py:109} INFO - [2022-04-07 20:10:33,623] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:10:33,633] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.995 seconds
[2022-04-07 20:11:03,765] {processor.py:163} INFO - Started process (PID=9163) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:11:03,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:11:03,769] {logging_mixin.py:109} INFO - [2022-04-07 20:11:03,769] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:11:04,791] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:11:04,825] {logging_mixin.py:109} INFO - [2022-04-07 20:11:04,824] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:11:04,849] {logging_mixin.py:109} INFO - [2022-04-07 20:11:04,849] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:11:04,860] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.099 seconds
[2022-04-07 20:11:34,967] {processor.py:163} INFO - Started process (PID=9192) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:11:34,970] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:11:34,971] {logging_mixin.py:109} INFO - [2022-04-07 20:11:34,971] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:11:35,932] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:11:35,957] {logging_mixin.py:109} INFO - [2022-04-07 20:11:35,956] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:11:35,975] {logging_mixin.py:109} INFO - [2022-04-07 20:11:35,975] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:11:35,985] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.023 seconds
[2022-04-07 20:12:06,084] {processor.py:163} INFO - Started process (PID=9231) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:12:06,086] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:12:06,087] {logging_mixin.py:109} INFO - [2022-04-07 20:12:06,087] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:12:07,107] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:12:07,132] {logging_mixin.py:109} INFO - [2022-04-07 20:12:07,132] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:12:07,151] {logging_mixin.py:109} INFO - [2022-04-07 20:12:07,151] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:12:07,162] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.083 seconds
[2022-04-07 20:12:37,254] {processor.py:163} INFO - Started process (PID=9260) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:12:37,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:12:37,258] {logging_mixin.py:109} INFO - [2022-04-07 20:12:37,257] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:12:38,300] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:12:38,324] {logging_mixin.py:109} INFO - [2022-04-07 20:12:38,323] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:12:38,344] {logging_mixin.py:109} INFO - [2022-04-07 20:12:38,344] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:12:38,355] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.107 seconds
[2022-04-07 20:13:08,451] {processor.py:163} INFO - Started process (PID=9298) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:13:08,453] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:13:08,454] {logging_mixin.py:109} INFO - [2022-04-07 20:13:08,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:13:09,554] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:13:09,583] {logging_mixin.py:109} INFO - [2022-04-07 20:13:09,583] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:13:09,612] {logging_mixin.py:109} INFO - [2022-04-07 20:13:09,612] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:13:09,625] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.179 seconds
[2022-04-07 20:13:39,734] {processor.py:163} INFO - Started process (PID=9327) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:13:39,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:13:39,736] {logging_mixin.py:109} INFO - [2022-04-07 20:13:39,736] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:13:40,693] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:13:40,720] {logging_mixin.py:109} INFO - [2022-04-07 20:13:40,719] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:13:40,742] {logging_mixin.py:109} INFO - [2022-04-07 20:13:40,742] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:13:40,754] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.025 seconds
[2022-04-07 20:14:10,856] {processor.py:163} INFO - Started process (PID=9365) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:14:10,858] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:14:10,859] {logging_mixin.py:109} INFO - [2022-04-07 20:14:10,859] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:14:11,854] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:14:11,885] {logging_mixin.py:109} INFO - [2022-04-07 20:14:11,884] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:14:11,910] {logging_mixin.py:109} INFO - [2022-04-07 20:14:11,910] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:14:11,922] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.071 seconds
[2022-04-07 20:14:41,982] {processor.py:163} INFO - Started process (PID=9393) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:14:41,983] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:14:41,984] {logging_mixin.py:109} INFO - [2022-04-07 20:14:41,984] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:14:42,935] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:14:42,966] {logging_mixin.py:109} INFO - [2022-04-07 20:14:42,965] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:14:42,988] {logging_mixin.py:109} INFO - [2022-04-07 20:14:42,988] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:14:42,999] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.022 seconds
[2022-04-07 20:15:13,166] {processor.py:163} INFO - Started process (PID=9432) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:15:13,169] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:15:13,170] {logging_mixin.py:109} INFO - [2022-04-07 20:15:13,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:15:14,250] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:15:14,273] {logging_mixin.py:109} INFO - [2022-04-07 20:15:14,273] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:15:14,293] {logging_mixin.py:109} INFO - [2022-04-07 20:15:14,293] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:15:14,302] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.141 seconds
[2022-04-07 20:15:44,398] {processor.py:163} INFO - Started process (PID=9460) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:15:44,401] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:15:44,402] {logging_mixin.py:109} INFO - [2022-04-07 20:15:44,402] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:15:45,380] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:15:45,405] {logging_mixin.py:109} INFO - [2022-04-07 20:15:45,405] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:15:45,424] {logging_mixin.py:109} INFO - [2022-04-07 20:15:45,424] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:15:45,434] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.041 seconds
[2022-04-07 20:16:15,525] {processor.py:163} INFO - Started process (PID=9499) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:16:15,527] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:16:15,528] {logging_mixin.py:109} INFO - [2022-04-07 20:16:15,528] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:16:16,523] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:16:16,546] {logging_mixin.py:109} INFO - [2022-04-07 20:16:16,546] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:16:16,565] {logging_mixin.py:109} INFO - [2022-04-07 20:16:16,565] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:16:16,575] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.055 seconds
[2022-04-07 20:16:46,652] {processor.py:163} INFO - Started process (PID=9527) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:16:46,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:16:46,657] {logging_mixin.py:109} INFO - [2022-04-07 20:16:46,657] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:16:47,672] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:16:47,699] {logging_mixin.py:109} INFO - [2022-04-07 20:16:47,698] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:16:47,720] {logging_mixin.py:109} INFO - [2022-04-07 20:16:47,720] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:16:47,733] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.086 seconds
[2022-04-07 20:17:17,920] {processor.py:163} INFO - Started process (PID=9567) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:17:17,922] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:17:17,923] {logging_mixin.py:109} INFO - [2022-04-07 20:17:17,923] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:17:18,926] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:17:18,955] {logging_mixin.py:109} INFO - [2022-04-07 20:17:18,955] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:17:18,978] {logging_mixin.py:109} INFO - [2022-04-07 20:17:18,977] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:17:18,989] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.075 seconds
[2022-04-07 20:17:49,049] {processor.py:163} INFO - Started process (PID=9597) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:17:49,052] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:17:49,053] {logging_mixin.py:109} INFO - [2022-04-07 20:17:49,053] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:17:49,954] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:17:49,978] {logging_mixin.py:109} INFO - [2022-04-07 20:17:49,978] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:17:49,999] {logging_mixin.py:109} INFO - [2022-04-07 20:17:49,998] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:17:50,009] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.965 seconds
[2022-04-07 20:18:20,170] {processor.py:163} INFO - Started process (PID=9635) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:18:20,173] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:18:20,174] {logging_mixin.py:109} INFO - [2022-04-07 20:18:20,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:18:21,133] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:18:21,158] {logging_mixin.py:109} INFO - [2022-04-07 20:18:21,157] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:18:21,185] {logging_mixin.py:109} INFO - [2022-04-07 20:18:21,184] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:18:21,195] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.029 seconds
[2022-04-07 20:18:51,309] {processor.py:163} INFO - Started process (PID=9665) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:18:51,311] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:18:51,312] {logging_mixin.py:109} INFO - [2022-04-07 20:18:51,312] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:18:52,235] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:18:52,261] {logging_mixin.py:109} INFO - [2022-04-07 20:18:52,260] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:18:52,281] {logging_mixin.py:109} INFO - [2022-04-07 20:18:52,281] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:18:52,294] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.990 seconds
[2022-04-07 20:19:22,429] {processor.py:163} INFO - Started process (PID=9703) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:19:22,431] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:19:22,432] {logging_mixin.py:109} INFO - [2022-04-07 20:19:22,432] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:19:23,339] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:19:23,362] {logging_mixin.py:109} INFO - [2022-04-07 20:19:23,362] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:19:23,381] {logging_mixin.py:109} INFO - [2022-04-07 20:19:23,381] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:19:23,391] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.967 seconds
[2022-04-07 20:19:53,554] {processor.py:163} INFO - Started process (PID=9731) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:19:53,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:19:53,558] {logging_mixin.py:109} INFO - [2022-04-07 20:19:53,558] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:19:54,478] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:19:54,505] {logging_mixin.py:109} INFO - [2022-04-07 20:19:54,504] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:19:54,526] {logging_mixin.py:109} INFO - [2022-04-07 20:19:54,525] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:19:54,537] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.988 seconds
[2022-04-07 20:20:24,685] {processor.py:163} INFO - Started process (PID=9771) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:20:24,687] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:20:24,688] {logging_mixin.py:109} INFO - [2022-04-07 20:20:24,688] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:20:25,733] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:20:25,758] {logging_mixin.py:109} INFO - [2022-04-07 20:20:25,757] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:20:25,779] {logging_mixin.py:109} INFO - [2022-04-07 20:20:25,779] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:20:25,791] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.113 seconds
[2022-04-07 20:20:55,891] {processor.py:163} INFO - Started process (PID=9798) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:20:55,894] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:20:55,895] {logging_mixin.py:109} INFO - [2022-04-07 20:20:55,895] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:20:56,888] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:20:56,920] {logging_mixin.py:109} INFO - [2022-04-07 20:20:56,920] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:20:56,942] {logging_mixin.py:109} INFO - [2022-04-07 20:20:56,942] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:20:56,956] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.071 seconds
[2022-04-07 20:21:27,014] {processor.py:163} INFO - Started process (PID=9835) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:21:27,016] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:21:27,018] {logging_mixin.py:109} INFO - [2022-04-07 20:21:27,018] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:21:28,044] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:21:28,077] {logging_mixin.py:109} INFO - [2022-04-07 20:21:28,077] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:21:28,105] {logging_mixin.py:109} INFO - [2022-04-07 20:21:28,104] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:21:28,120] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.114 seconds
[2022-04-07 20:21:58,176] {processor.py:163} INFO - Started process (PID=9866) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:21:58,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:21:58,180] {logging_mixin.py:109} INFO - [2022-04-07 20:21:58,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:21:59,094] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:21:59,122] {logging_mixin.py:109} INFO - [2022-04-07 20:21:59,121] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:21:59,143] {logging_mixin.py:109} INFO - [2022-04-07 20:21:59,142] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:21:59,158] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.987 seconds
[2022-04-07 20:22:29,309] {processor.py:163} INFO - Started process (PID=9903) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:22:29,311] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:22:29,312] {logging_mixin.py:109} INFO - [2022-04-07 20:22:29,312] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:22:30,263] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:22:30,287] {logging_mixin.py:109} INFO - [2022-04-07 20:22:30,287] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:22:30,308] {logging_mixin.py:109} INFO - [2022-04-07 20:22:30,308] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:22:30,320] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.015 seconds
[2022-04-07 20:23:00,432] {processor.py:163} INFO - Started process (PID=9932) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:23:00,434] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:23:00,435] {logging_mixin.py:109} INFO - [2022-04-07 20:23:00,435] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:23:01,376] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:23:01,401] {logging_mixin.py:109} INFO - [2022-04-07 20:23:01,401] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:23:01,423] {logging_mixin.py:109} INFO - [2022-04-07 20:23:01,422] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:23:01,434] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 20:23:31,562] {processor.py:163} INFO - Started process (PID=9961) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:23:31,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:23:31,565] {logging_mixin.py:109} INFO - [2022-04-07 20:23:31,565] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:23:32,548] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:23:32,578] {logging_mixin.py:109} INFO - [2022-04-07 20:23:32,577] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:23:32,597] {logging_mixin.py:109} INFO - [2022-04-07 20:23:32,597] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:23:32,609] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.052 seconds
[2022-04-07 20:24:02,698] {processor.py:163} INFO - Started process (PID=9998) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:24:02,701] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:24:02,702] {logging_mixin.py:109} INFO - [2022-04-07 20:24:02,702] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:24:03,629] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:24:03,655] {logging_mixin.py:109} INFO - [2022-04-07 20:24:03,654] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:24:03,678] {logging_mixin.py:109} INFO - [2022-04-07 20:24:03,678] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:24:03,689] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.996 seconds
[2022-04-07 20:24:33,826] {processor.py:163} INFO - Started process (PID=10026) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:24:33,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:24:33,830] {logging_mixin.py:109} INFO - [2022-04-07 20:24:33,829] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:24:34,805] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:24:34,837] {logging_mixin.py:109} INFO - [2022-04-07 20:24:34,837] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:24:34,861] {logging_mixin.py:109} INFO - [2022-04-07 20:24:34,860] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:24:34,874] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.054 seconds
[2022-04-07 20:25:04,962] {processor.py:163} INFO - Started process (PID=10065) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:25:04,964] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:25:04,965] {logging_mixin.py:109} INFO - [2022-04-07 20:25:04,965] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:25:05,854] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:25:05,876] {logging_mixin.py:109} INFO - [2022-04-07 20:25:05,875] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:25:05,895] {logging_mixin.py:109} INFO - [2022-04-07 20:25:05,894] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:25:05,905] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.950 seconds
[2022-04-07 20:25:36,055] {processor.py:163} INFO - Started process (PID=10094) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:25:36,059] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:25:36,061] {logging_mixin.py:109} INFO - [2022-04-07 20:25:36,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:25:37,042] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:25:37,068] {logging_mixin.py:109} INFO - [2022-04-07 20:25:37,068] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:25:37,088] {logging_mixin.py:109} INFO - [2022-04-07 20:25:37,088] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:25:37,101] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.050 seconds
[2022-04-07 20:26:07,192] {processor.py:163} INFO - Started process (PID=10133) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:26:07,195] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:26:07,196] {logging_mixin.py:109} INFO - [2022-04-07 20:26:07,196] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:26:08,078] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:26:08,108] {logging_mixin.py:109} INFO - [2022-04-07 20:26:08,107] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:26:08,135] {logging_mixin.py:109} INFO - [2022-04-07 20:26:08,135] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:26:08,148] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.960 seconds
[2022-04-07 20:26:38,299] {processor.py:163} INFO - Started process (PID=10161) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:26:38,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:26:38,303] {logging_mixin.py:109} INFO - [2022-04-07 20:26:38,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:26:39,314] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:26:39,344] {logging_mixin.py:109} INFO - [2022-04-07 20:26:39,343] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:26:39,369] {logging_mixin.py:109} INFO - [2022-04-07 20:26:39,369] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:26:39,382] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.090 seconds
[2022-04-07 20:27:09,485] {processor.py:163} INFO - Started process (PID=10201) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:27:09,490] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:27:09,491] {logging_mixin.py:109} INFO - [2022-04-07 20:27:09,491] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:27:10,460] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:27:10,488] {logging_mixin.py:109} INFO - [2022-04-07 20:27:10,488] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:27:10,510] {logging_mixin.py:109} INFO - [2022-04-07 20:27:10,509] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:27:10,522] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.044 seconds
[2022-04-07 20:27:40,602] {processor.py:163} INFO - Started process (PID=10229) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:27:40,605] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:27:40,606] {logging_mixin.py:109} INFO - [2022-04-07 20:27:40,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:27:41,476] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:27:41,498] {logging_mixin.py:109} INFO - [2022-04-07 20:27:41,498] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:27:41,518] {logging_mixin.py:109} INFO - [2022-04-07 20:27:41,518] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:27:41,529] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.932 seconds
[2022-04-07 20:28:11,647] {processor.py:163} INFO - Started process (PID=10267) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:28:11,649] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:28:11,650] {logging_mixin.py:109} INFO - [2022-04-07 20:28:11,649] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:28:12,578] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:28:12,601] {logging_mixin.py:109} INFO - [2022-04-07 20:28:12,600] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:28:12,621] {logging_mixin.py:109} INFO - [2022-04-07 20:28:12,621] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:28:12,632] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.991 seconds
[2022-04-07 20:28:42,768] {processor.py:163} INFO - Started process (PID=10294) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:28:42,771] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:28:42,772] {logging_mixin.py:109} INFO - [2022-04-07 20:28:42,772] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:28:43,684] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:28:43,709] {logging_mixin.py:109} INFO - [2022-04-07 20:28:43,709] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:28:43,732] {logging_mixin.py:109} INFO - [2022-04-07 20:28:43,732] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:28:43,744] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.981 seconds
[2022-04-07 20:29:13,888] {processor.py:163} INFO - Started process (PID=10331) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:29:13,889] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:29:13,890] {logging_mixin.py:109} INFO - [2022-04-07 20:29:13,890] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:29:14,809] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:29:14,833] {logging_mixin.py:109} INFO - [2022-04-07 20:29:14,833] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:29:14,854] {logging_mixin.py:109} INFO - [2022-04-07 20:29:14,854] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:29:14,864] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.981 seconds
[2022-04-07 20:29:45,024] {processor.py:163} INFO - Started process (PID=10360) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:29:45,026] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:29:45,027] {logging_mixin.py:109} INFO - [2022-04-07 20:29:45,027] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:29:45,960] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:29:45,992] {logging_mixin.py:109} INFO - [2022-04-07 20:29:45,992] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:29:46,015] {logging_mixin.py:109} INFO - [2022-04-07 20:29:46,014] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:29:46,027] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 20:30:16,172] {processor.py:163} INFO - Started process (PID=10399) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:30:16,175] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:30:16,176] {logging_mixin.py:109} INFO - [2022-04-07 20:30:16,176] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:30:17,130] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:30:17,156] {logging_mixin.py:109} INFO - [2022-04-07 20:30:17,156] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:30:17,181] {logging_mixin.py:109} INFO - [2022-04-07 20:30:17,181] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:30:17,192] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.025 seconds
[2022-04-07 20:30:47,291] {processor.py:163} INFO - Started process (PID=10427) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:30:47,293] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:30:47,294] {logging_mixin.py:109} INFO - [2022-04-07 20:30:47,294] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:30:48,295] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:30:48,320] {logging_mixin.py:109} INFO - [2022-04-07 20:30:48,320] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:30:48,341] {logging_mixin.py:109} INFO - [2022-04-07 20:30:48,340] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:30:48,353] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.067 seconds
[2022-04-07 20:31:18,418] {processor.py:163} INFO - Started process (PID=10464) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:31:18,422] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:31:18,423] {logging_mixin.py:109} INFO - [2022-04-07 20:31:18,423] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:31:19,405] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:31:19,432] {logging_mixin.py:109} INFO - [2022-04-07 20:31:19,431] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:31:19,452] {logging_mixin.py:109} INFO - [2022-04-07 20:31:19,452] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:31:19,463] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.052 seconds
[2022-04-07 20:31:49,577] {processor.py:163} INFO - Started process (PID=10493) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:31:49,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:31:49,580] {logging_mixin.py:109} INFO - [2022-04-07 20:31:49,580] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:31:50,508] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:31:50,542] {logging_mixin.py:109} INFO - [2022-04-07 20:31:50,541] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:31:50,567] {logging_mixin.py:109} INFO - [2022-04-07 20:31:50,567] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:31:50,578] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.005 seconds
[2022-04-07 20:32:20,697] {processor.py:163} INFO - Started process (PID=10530) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:32:20,699] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:32:20,701] {logging_mixin.py:109} INFO - [2022-04-07 20:32:20,700] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:32:21,623] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:32:21,645] {logging_mixin.py:109} INFO - [2022-04-07 20:32:21,644] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:32:21,666] {logging_mixin.py:109} INFO - [2022-04-07 20:32:21,666] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:32:21,676] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.984 seconds
[2022-04-07 20:32:51,822] {processor.py:163} INFO - Started process (PID=10559) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:32:51,823] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:32:51,824] {logging_mixin.py:109} INFO - [2022-04-07 20:32:51,824] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:32:52,770] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:32:52,793] {logging_mixin.py:109} INFO - [2022-04-07 20:32:52,793] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:32:52,814] {logging_mixin.py:109} INFO - [2022-04-07 20:32:52,814] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:32:52,826] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.009 seconds
[2022-04-07 20:33:22,946] {processor.py:163} INFO - Started process (PID=10597) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:33:22,948] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:33:22,949] {logging_mixin.py:109} INFO - [2022-04-07 20:33:22,949] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:33:23,882] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:33:23,905] {logging_mixin.py:109} INFO - [2022-04-07 20:33:23,904] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:33:23,923] {logging_mixin.py:109} INFO - [2022-04-07 20:33:23,923] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:33:23,934] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.993 seconds
[2022-04-07 20:33:54,071] {processor.py:163} INFO - Started process (PID=10626) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:33:54,073] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:33:54,074] {logging_mixin.py:109} INFO - [2022-04-07 20:33:54,074] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:33:55,002] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:33:55,026] {logging_mixin.py:109} INFO - [2022-04-07 20:33:55,025] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:33:55,045] {logging_mixin.py:109} INFO - [2022-04-07 20:33:55,045] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:33:55,055] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.989 seconds
[2022-04-07 20:34:25,198] {processor.py:163} INFO - Started process (PID=10665) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:34:25,203] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:34:25,204] {logging_mixin.py:109} INFO - [2022-04-07 20:34:25,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:34:26,231] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:34:26,255] {logging_mixin.py:109} INFO - [2022-04-07 20:34:26,254] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:34:26,278] {logging_mixin.py:109} INFO - [2022-04-07 20:34:26,278] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:34:26,288] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.094 seconds
[2022-04-07 20:34:56,337] {processor.py:163} INFO - Started process (PID=10694) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:34:56,340] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:34:56,341] {logging_mixin.py:109} INFO - [2022-04-07 20:34:56,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:34:57,235] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:34:57,263] {logging_mixin.py:109} INFO - [2022-04-07 20:34:57,263] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:34:57,285] {logging_mixin.py:109} INFO - [2022-04-07 20:34:57,285] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:34:57,298] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.966 seconds
[2022-04-07 20:35:27,456] {processor.py:163} INFO - Started process (PID=10733) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:35:27,461] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:35:27,462] {logging_mixin.py:109} INFO - [2022-04-07 20:35:27,462] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:35:28,399] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:35:28,429] {logging_mixin.py:109} INFO - [2022-04-07 20:35:28,429] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:35:28,454] {logging_mixin.py:109} INFO - [2022-04-07 20:35:28,454] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:35:28,465] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.014 seconds
[2022-04-07 20:35:58,585] {processor.py:163} INFO - Started process (PID=10763) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:35:58,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:35:58,588] {logging_mixin.py:109} INFO - [2022-04-07 20:35:58,588] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:35:59,497] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:35:59,526] {logging_mixin.py:109} INFO - [2022-04-07 20:35:59,526] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:35:59,553] {logging_mixin.py:109} INFO - [2022-04-07 20:35:59,553] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:35:59,565] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.984 seconds
[2022-04-07 20:36:29,710] {processor.py:163} INFO - Started process (PID=10804) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:36:29,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:36:29,714] {logging_mixin.py:109} INFO - [2022-04-07 20:36:29,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:36:30,685] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:36:30,709] {logging_mixin.py:109} INFO - [2022-04-07 20:36:30,709] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:36:30,728] {logging_mixin.py:109} INFO - [2022-04-07 20:36:30,728] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:36:30,738] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.034 seconds
[2022-04-07 20:37:00,823] {processor.py:163} INFO - Started process (PID=10841) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:37:00,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:37:00,827] {logging_mixin.py:109} INFO - [2022-04-07 20:37:00,827] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:37:01,695] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:37:01,727] {logging_mixin.py:109} INFO - [2022-04-07 20:37:01,726] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:37:01,753] {logging_mixin.py:109} INFO - [2022-04-07 20:37:01,753] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:37:01,766] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.948 seconds
[2022-04-07 20:37:31,931] {processor.py:163} INFO - Started process (PID=10872) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:37:31,932] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:37:31,933] {logging_mixin.py:109} INFO - [2022-04-07 20:37:31,933] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:37:32,848] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:37:32,877] {logging_mixin.py:109} INFO - [2022-04-07 20:37:32,876] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:37:32,902] {logging_mixin.py:109} INFO - [2022-04-07 20:37:32,902] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:37:32,914] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.988 seconds
[2022-04-07 20:38:03,053] {processor.py:163} INFO - Started process (PID=10908) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:38:03,055] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:38:03,057] {logging_mixin.py:109} INFO - [2022-04-07 20:38:03,056] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:38:03,940] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:38:03,964] {logging_mixin.py:109} INFO - [2022-04-07 20:38:03,963] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:38:03,983] {logging_mixin.py:109} INFO - [2022-04-07 20:38:03,983] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:38:03,993] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.945 seconds
[2022-04-07 20:38:34,151] {processor.py:163} INFO - Started process (PID=10940) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:38:34,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:38:34,153] {logging_mixin.py:109} INFO - [2022-04-07 20:38:34,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:38:35,051] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:38:35,075] {logging_mixin.py:109} INFO - [2022-04-07 20:38:35,075] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:38:35,095] {logging_mixin.py:109} INFO - [2022-04-07 20:38:35,095] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:38:35,105] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.959 seconds
[2022-04-07 20:39:05,264] {processor.py:163} INFO - Started process (PID=10977) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:39:05,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:39:05,268] {logging_mixin.py:109} INFO - [2022-04-07 20:39:05,268] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:39:06,156] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:39:06,185] {logging_mixin.py:109} INFO - [2022-04-07 20:39:06,184] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:39:06,206] {logging_mixin.py:109} INFO - [2022-04-07 20:39:06,206] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:39:06,216] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.958 seconds
[2022-04-07 20:39:36,367] {processor.py:163} INFO - Started process (PID=11005) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:39:36,370] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:39:36,371] {logging_mixin.py:109} INFO - [2022-04-07 20:39:36,371] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:39:37,337] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:39:37,361] {logging_mixin.py:109} INFO - [2022-04-07 20:39:37,361] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:39:37,382] {logging_mixin.py:109} INFO - [2022-04-07 20:39:37,382] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:39:37,394] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.032 seconds
[2022-04-07 20:40:07,526] {processor.py:163} INFO - Started process (PID=11043) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:40:07,529] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:40:07,530] {logging_mixin.py:109} INFO - [2022-04-07 20:40:07,530] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:40:08,466] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:40:08,492] {logging_mixin.py:109} INFO - [2022-04-07 20:40:08,492] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:40:08,513] {logging_mixin.py:109} INFO - [2022-04-07 20:40:08,512] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:40:08,525] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.005 seconds
[2022-04-07 20:40:38,650] {processor.py:163} INFO - Started process (PID=11071) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:40:38,652] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:40:38,653] {logging_mixin.py:109} INFO - [2022-04-07 20:40:38,653] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:40:39,620] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:40:39,645] {logging_mixin.py:109} INFO - [2022-04-07 20:40:39,645] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:40:39,673] {logging_mixin.py:109} INFO - [2022-04-07 20:40:39,673] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:40:39,685] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.041 seconds
[2022-04-07 20:41:09,765] {processor.py:163} INFO - Started process (PID=11111) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:41:09,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:41:09,769] {logging_mixin.py:109} INFO - [2022-04-07 20:41:09,768] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:41:10,710] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:41:10,734] {logging_mixin.py:109} INFO - [2022-04-07 20:41:10,733] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:41:10,755] {logging_mixin.py:109} INFO - [2022-04-07 20:41:10,755] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:41:10,769] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.009 seconds
[2022-04-07 20:41:40,892] {processor.py:163} INFO - Started process (PID=11140) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:41:40,893] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:41:40,894] {logging_mixin.py:109} INFO - [2022-04-07 20:41:40,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:41:41,787] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:41:41,811] {logging_mixin.py:109} INFO - [2022-04-07 20:41:41,811] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:41:41,832] {logging_mixin.py:109} INFO - [2022-04-07 20:41:41,831] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:41:41,842] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.955 seconds
[2022-04-07 20:42:11,993] {processor.py:163} INFO - Started process (PID=11180) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:42:11,996] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:42:11,997] {logging_mixin.py:109} INFO - [2022-04-07 20:42:11,997] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:42:12,924] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:42:12,950] {logging_mixin.py:109} INFO - [2022-04-07 20:42:12,950] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:42:12,972] {logging_mixin.py:109} INFO - [2022-04-07 20:42:12,972] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:42:12,984] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.998 seconds
[2022-04-07 20:42:43,114] {processor.py:163} INFO - Started process (PID=11208) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:42:43,116] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:42:43,117] {logging_mixin.py:109} INFO - [2022-04-07 20:42:43,117] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:42:44,049] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:42:44,071] {logging_mixin.py:109} INFO - [2022-04-07 20:42:44,070] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:42:44,091] {logging_mixin.py:109} INFO - [2022-04-07 20:42:44,091] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:42:44,101] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.991 seconds
[2022-04-07 20:43:14,262] {processor.py:163} INFO - Started process (PID=11245) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:43:14,265] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:43:14,266] {logging_mixin.py:109} INFO - [2022-04-07 20:43:14,266] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:43:15,215] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:43:15,245] {logging_mixin.py:109} INFO - [2022-04-07 20:43:15,245] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:43:15,266] {logging_mixin.py:109} INFO - [2022-04-07 20:43:15,266] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:43:15,278] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 20:43:45,375] {processor.py:163} INFO - Started process (PID=11273) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:43:45,377] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:43:45,379] {logging_mixin.py:109} INFO - [2022-04-07 20:43:45,378] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:43:46,288] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:43:46,312] {logging_mixin.py:109} INFO - [2022-04-07 20:43:46,311] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:43:46,331] {logging_mixin.py:109} INFO - [2022-04-07 20:43:46,331] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:43:46,341] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.973 seconds
[2022-04-07 20:44:16,494] {processor.py:163} INFO - Started process (PID=11312) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:44:16,496] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:44:16,497] {logging_mixin.py:109} INFO - [2022-04-07 20:44:16,497] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:44:17,372] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:44:17,400] {logging_mixin.py:109} INFO - [2022-04-07 20:44:17,400] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:44:17,427] {logging_mixin.py:109} INFO - [2022-04-07 20:44:17,427] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:44:17,437] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 20:44:47,606] {processor.py:163} INFO - Started process (PID=11342) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:44:47,609] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:44:47,610] {logging_mixin.py:109} INFO - [2022-04-07 20:44:47,609] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:44:48,495] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:44:48,520] {logging_mixin.py:109} INFO - [2022-04-07 20:44:48,519] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:44:48,540] {logging_mixin.py:109} INFO - [2022-04-07 20:44:48,540] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:44:48,551] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 20:45:18,715] {processor.py:163} INFO - Started process (PID=11381) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:45:18,718] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:45:18,719] {logging_mixin.py:109} INFO - [2022-04-07 20:45:18,719] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:45:19,614] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:45:19,636] {logging_mixin.py:109} INFO - [2022-04-07 20:45:19,636] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:45:19,658] {logging_mixin.py:109} INFO - [2022-04-07 20:45:19,658] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:45:19,668] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.958 seconds
[2022-04-07 20:45:49,817] {processor.py:163} INFO - Started process (PID=11409) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:45:49,819] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:45:49,820] {logging_mixin.py:109} INFO - [2022-04-07 20:45:49,820] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:45:50,699] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:45:50,724] {logging_mixin.py:109} INFO - [2022-04-07 20:45:50,723] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:45:50,744] {logging_mixin.py:109} INFO - [2022-04-07 20:45:50,744] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:45:50,755] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.942 seconds
[2022-04-07 20:46:20,919] {processor.py:163} INFO - Started process (PID=11447) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:46:20,921] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:46:20,922] {logging_mixin.py:109} INFO - [2022-04-07 20:46:20,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:46:21,800] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:46:21,823] {logging_mixin.py:109} INFO - [2022-04-07 20:46:21,823] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:46:21,848] {logging_mixin.py:109} INFO - [2022-04-07 20:46:21,848] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:46:21,860] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.945 seconds
[2022-04-07 20:46:52,003] {processor.py:163} INFO - Started process (PID=11475) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:46:52,006] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:46:52,007] {logging_mixin.py:109} INFO - [2022-04-07 20:46:52,006] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:46:52,857] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:46:52,882] {logging_mixin.py:109} INFO - [2022-04-07 20:46:52,882] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:46:52,902] {logging_mixin.py:109} INFO - [2022-04-07 20:46:52,902] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:46:52,913] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.914 seconds
[2022-04-07 20:47:23,025] {processor.py:163} INFO - Started process (PID=11514) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:47:23,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:47:23,029] {logging_mixin.py:109} INFO - [2022-04-07 20:47:23,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:47:23,882] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:47:23,910] {logging_mixin.py:109} INFO - [2022-04-07 20:47:23,910] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:47:23,933] {logging_mixin.py:109} INFO - [2022-04-07 20:47:23,933] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:47:23,944] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.925 seconds
[2022-04-07 20:47:54,072] {processor.py:163} INFO - Started process (PID=11542) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:47:54,073] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:47:54,074] {logging_mixin.py:109} INFO - [2022-04-07 20:47:54,074] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:47:54,991] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:47:55,015] {logging_mixin.py:109} INFO - [2022-04-07 20:47:55,015] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:47:55,035] {logging_mixin.py:109} INFO - [2022-04-07 20:47:55,035] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:47:55,045] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.978 seconds
[2022-04-07 20:48:25,195] {processor.py:163} INFO - Started process (PID=11582) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:48:25,198] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:48:25,199] {logging_mixin.py:109} INFO - [2022-04-07 20:48:25,199] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:48:26,066] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:48:26,090] {logging_mixin.py:109} INFO - [2022-04-07 20:48:26,089] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:48:26,109] {logging_mixin.py:109} INFO - [2022-04-07 20:48:26,108] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:48:26,120] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.929 seconds
[2022-04-07 20:48:56,233] {processor.py:163} INFO - Started process (PID=11609) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:48:56,236] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:48:56,237] {logging_mixin.py:109} INFO - [2022-04-07 20:48:56,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:48:57,089] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:48:57,115] {logging_mixin.py:109} INFO - [2022-04-07 20:48:57,114] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:48:57,134] {logging_mixin.py:109} INFO - [2022-04-07 20:48:57,134] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:48:57,145] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.917 seconds
[2022-04-07 20:49:27,266] {processor.py:163} INFO - Started process (PID=11649) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:49:27,269] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:49:27,270] {logging_mixin.py:109} INFO - [2022-04-07 20:49:27,269] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:49:28,144] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:49:28,170] {logging_mixin.py:109} INFO - [2022-04-07 20:49:28,169] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:49:28,189] {logging_mixin.py:109} INFO - [2022-04-07 20:49:28,188] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:49:28,200] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.941 seconds
[2022-04-07 20:49:58,323] {processor.py:163} INFO - Started process (PID=11678) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:49:58,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:49:58,326] {logging_mixin.py:109} INFO - [2022-04-07 20:49:58,326] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:49:59,246] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:49:59,274] {logging_mixin.py:109} INFO - [2022-04-07 20:49:59,274] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:49:59,296] {logging_mixin.py:109} INFO - [2022-04-07 20:49:59,296] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:49:59,308] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.990 seconds
[2022-04-07 20:50:29,439] {processor.py:163} INFO - Started process (PID=11716) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:50:29,441] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:50:29,442] {logging_mixin.py:109} INFO - [2022-04-07 20:50:29,442] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:50:30,318] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:50:30,342] {logging_mixin.py:109} INFO - [2022-04-07 20:50:30,341] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:50:30,362] {logging_mixin.py:109} INFO - [2022-04-07 20:50:30,362] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:50:30,375] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.940 seconds
[2022-04-07 20:51:00,485] {processor.py:163} INFO - Started process (PID=11745) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:51:00,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:51:00,488] {logging_mixin.py:109} INFO - [2022-04-07 20:51:00,488] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:51:01,346] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:51:01,369] {logging_mixin.py:109} INFO - [2022-04-07 20:51:01,369] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:51:01,387] {logging_mixin.py:109} INFO - [2022-04-07 20:51:01,387] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:51:01,397] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.917 seconds
[2022-04-07 20:51:31,502] {processor.py:163} INFO - Started process (PID=11785) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:51:31,504] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:51:31,504] {logging_mixin.py:109} INFO - [2022-04-07 20:51:31,504] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:51:32,456] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:51:32,487] {logging_mixin.py:109} INFO - [2022-04-07 20:51:32,486] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:51:32,509] {logging_mixin.py:109} INFO - [2022-04-07 20:51:32,509] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:51:32,520] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 20:52:02,623] {processor.py:163} INFO - Started process (PID=11813) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:52:02,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:52:02,626] {logging_mixin.py:109} INFO - [2022-04-07 20:52:02,626] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:52:03,503] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:52:03,525] {logging_mixin.py:109} INFO - [2022-04-07 20:52:03,525] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:52:03,543] {logging_mixin.py:109} INFO - [2022-04-07 20:52:03,542] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:52:03,551] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.933 seconds
[2022-04-07 20:52:33,664] {processor.py:163} INFO - Started process (PID=11850) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:52:33,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:52:33,670] {logging_mixin.py:109} INFO - [2022-04-07 20:52:33,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:52:34,612] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:52:34,635] {logging_mixin.py:109} INFO - [2022-04-07 20:52:34,634] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:52:34,654] {logging_mixin.py:109} INFO - [2022-04-07 20:52:34,654] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:52:34,666] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 20:53:04,753] {processor.py:163} INFO - Started process (PID=11879) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:53:04,754] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:53:04,755] {logging_mixin.py:109} INFO - [2022-04-07 20:53:04,755] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:53:05,609] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:53:05,632] {logging_mixin.py:109} INFO - [2022-04-07 20:53:05,631] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:53:05,650] {logging_mixin.py:109} INFO - [2022-04-07 20:53:05,650] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:53:05,659] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.912 seconds
[2022-04-07 20:53:35,766] {processor.py:163} INFO - Started process (PID=11919) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:53:35,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:53:35,769] {logging_mixin.py:109} INFO - [2022-04-07 20:53:35,769] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:53:36,669] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:53:36,692] {logging_mixin.py:109} INFO - [2022-04-07 20:53:36,691] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:53:36,711] {logging_mixin.py:109} INFO - [2022-04-07 20:53:36,711] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:53:36,722] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.961 seconds
[2022-04-07 20:54:06,832] {processor.py:163} INFO - Started process (PID=11947) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:54:06,834] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:54:06,835] {logging_mixin.py:109} INFO - [2022-04-07 20:54:06,835] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:54:07,723] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:54:07,750] {logging_mixin.py:109} INFO - [2022-04-07 20:54:07,750] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:54:07,773] {logging_mixin.py:109} INFO - [2022-04-07 20:54:07,773] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:54:07,785] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.958 seconds
[2022-04-07 20:54:37,893] {processor.py:163} INFO - Started process (PID=11984) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:54:37,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:54:37,898] {logging_mixin.py:109} INFO - [2022-04-07 20:54:37,897] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:54:38,850] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:54:38,875] {logging_mixin.py:109} INFO - [2022-04-07 20:54:38,875] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:54:38,895] {logging_mixin.py:109} INFO - [2022-04-07 20:54:38,895] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:54:38,906] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.018 seconds
[2022-04-07 20:55:09,031] {processor.py:163} INFO - Started process (PID=12012) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:55:09,034] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:55:09,035] {logging_mixin.py:109} INFO - [2022-04-07 20:55:09,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:55:09,941] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:55:09,966] {logging_mixin.py:109} INFO - [2022-04-07 20:55:09,966] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:55:09,987] {logging_mixin.py:109} INFO - [2022-04-07 20:55:09,987] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:55:09,997] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.971 seconds
[2022-04-07 20:55:40,152] {processor.py:163} INFO - Started process (PID=12050) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:55:40,155] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:55:40,156] {logging_mixin.py:109} INFO - [2022-04-07 20:55:40,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:55:41,038] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:55:41,061] {logging_mixin.py:109} INFO - [2022-04-07 20:55:41,061] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:55:41,081] {logging_mixin.py:109} INFO - [2022-04-07 20:55:41,081] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:55:41,090] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.943 seconds
[2022-04-07 20:56:11,271] {processor.py:163} INFO - Started process (PID=12081) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:56:11,274] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:56:11,275] {logging_mixin.py:109} INFO - [2022-04-07 20:56:11,275] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:56:12,164] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:56:12,194] {logging_mixin.py:109} INFO - [2022-04-07 20:56:12,193] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:56:12,223] {logging_mixin.py:109} INFO - [2022-04-07 20:56:12,222] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:56:12,235] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.970 seconds
[2022-04-07 20:56:42,376] {processor.py:163} INFO - Started process (PID=12119) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:56:42,378] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:56:42,379] {logging_mixin.py:109} INFO - [2022-04-07 20:56:42,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:56:43,279] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:56:43,308] {logging_mixin.py:109} INFO - [2022-04-07 20:56:43,307] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:56:43,329] {logging_mixin.py:109} INFO - [2022-04-07 20:56:43,329] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:56:43,341] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.969 seconds
[2022-04-07 20:57:13,493] {processor.py:163} INFO - Started process (PID=12158) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:57:13,495] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:57:13,496] {logging_mixin.py:109} INFO - [2022-04-07 20:57:13,496] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:57:14,351] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:57:14,379] {logging_mixin.py:109} INFO - [2022-04-07 20:57:14,378] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:57:14,406] {logging_mixin.py:109} INFO - [2022-04-07 20:57:14,406] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:57:14,418] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.930 seconds
[2022-04-07 20:57:44,534] {processor.py:163} INFO - Started process (PID=12186) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:57:44,535] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:57:44,536] {logging_mixin.py:109} INFO - [2022-04-07 20:57:44,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:57:45,451] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:57:45,472] {logging_mixin.py:109} INFO - [2022-04-07 20:57:45,472] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:57:45,490] {logging_mixin.py:109} INFO - [2022-04-07 20:57:45,490] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:57:45,499] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.970 seconds
[2022-04-07 20:58:15,610] {processor.py:163} INFO - Started process (PID=12223) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:58:15,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:58:15,612] {logging_mixin.py:109} INFO - [2022-04-07 20:58:15,612] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:58:16,498] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:58:16,522] {logging_mixin.py:109} INFO - [2022-04-07 20:58:16,522] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:58:16,541] {logging_mixin.py:109} INFO - [2022-04-07 20:58:16,540] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:58:16,550] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.945 seconds
[2022-04-07 20:58:46,650] {processor.py:163} INFO - Started process (PID=12251) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:58:46,652] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:58:46,653] {logging_mixin.py:109} INFO - [2022-04-07 20:58:46,653] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:58:47,551] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:58:47,574] {logging_mixin.py:109} INFO - [2022-04-07 20:58:47,574] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:58:47,593] {logging_mixin.py:109} INFO - [2022-04-07 20:58:47,593] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:58:47,603] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.958 seconds
[2022-04-07 20:59:17,709] {processor.py:163} INFO - Started process (PID=12289) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:59:17,711] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:59:17,712] {logging_mixin.py:109} INFO - [2022-04-07 20:59:17,712] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:59:18,635] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:59:18,657] {logging_mixin.py:109} INFO - [2022-04-07 20:59:18,657] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:59:18,678] {logging_mixin.py:109} INFO - [2022-04-07 20:59:18,677] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:59:18,689] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.986 seconds
[2022-04-07 20:59:48,827] {processor.py:163} INFO - Started process (PID=12319) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:59:48,829] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 20:59:48,830] {logging_mixin.py:109} INFO - [2022-04-07 20:59:48,830] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:59:49,694] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 20:59:49,717] {logging_mixin.py:109} INFO - [2022-04-07 20:59:49,717] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 20:59:49,738] {logging_mixin.py:109} INFO - [2022-04-07 20:59:49,738] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 20:59:49,750] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.927 seconds
[2022-04-07 21:00:19,876] {processor.py:163} INFO - Started process (PID=12357) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:00:19,880] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:00:19,882] {logging_mixin.py:109} INFO - [2022-04-07 21:00:19,881] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:00:20,768] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:00:20,791] {logging_mixin.py:109} INFO - [2022-04-07 21:00:20,791] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:00:20,811] {logging_mixin.py:109} INFO - [2022-04-07 21:00:20,811] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:00:20,821] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.951 seconds
[2022-04-07 21:00:50,925] {processor.py:163} INFO - Started process (PID=12386) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:00:50,927] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:00:50,928] {logging_mixin.py:109} INFO - [2022-04-07 21:00:50,928] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:00:51,760] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:00:51,781] {logging_mixin.py:109} INFO - [2022-04-07 21:00:51,781] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:00:51,800] {logging_mixin.py:109} INFO - [2022-04-07 21:00:51,800] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:00:51,809] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.889 seconds
[2022-04-07 21:01:21,910] {processor.py:163} INFO - Started process (PID=12428) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:01:21,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:01:21,914] {logging_mixin.py:109} INFO - [2022-04-07 21:01:21,914] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:01:22,816] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:01:22,839] {logging_mixin.py:109} INFO - [2022-04-07 21:01:22,838] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:01:22,858] {logging_mixin.py:109} INFO - [2022-04-07 21:01:22,858] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:01:22,867] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.962 seconds
[2022-04-07 21:01:52,967] {processor.py:163} INFO - Started process (PID=12456) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:01:52,968] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:01:52,969] {logging_mixin.py:109} INFO - [2022-04-07 21:01:52,969] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:01:53,839] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:01:53,863] {logging_mixin.py:109} INFO - [2022-04-07 21:01:53,862] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:01:53,883] {logging_mixin.py:109} INFO - [2022-04-07 21:01:53,883] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:01:53,894] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.932 seconds
[2022-04-07 21:02:23,994] {processor.py:163} INFO - Started process (PID=12494) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:02:23,999] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:02:24,000] {logging_mixin.py:109} INFO - [2022-04-07 21:02:24,000] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:02:24,865] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:02:24,889] {logging_mixin.py:109} INFO - [2022-04-07 21:02:24,888] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:02:24,908] {logging_mixin.py:109} INFO - [2022-04-07 21:02:24,908] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:02:24,918] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.929 seconds
[2022-04-07 21:02:55,016] {processor.py:163} INFO - Started process (PID=12522) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:02:55,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:02:55,020] {logging_mixin.py:109} INFO - [2022-04-07 21:02:55,020] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:02:55,865] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:02:55,889] {logging_mixin.py:109} INFO - [2022-04-07 21:02:55,889] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:02:55,908] {logging_mixin.py:109} INFO - [2022-04-07 21:02:55,908] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:02:55,918] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.907 seconds
[2022-04-07 21:03:26,017] {processor.py:163} INFO - Started process (PID=12559) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:03:26,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:03:26,020] {logging_mixin.py:109} INFO - [2022-04-07 21:03:26,020] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:03:26,892] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:03:26,917] {logging_mixin.py:109} INFO - [2022-04-07 21:03:26,916] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:03:26,936] {logging_mixin.py:109} INFO - [2022-04-07 21:03:26,935] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:03:26,947] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 21:03:57,050] {processor.py:163} INFO - Started process (PID=12587) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:03:57,053] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:03:57,054] {logging_mixin.py:109} INFO - [2022-04-07 21:03:57,054] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:03:57,980] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:03:58,007] {logging_mixin.py:109} INFO - [2022-04-07 21:03:58,007] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:03:58,027] {logging_mixin.py:109} INFO - [2022-04-07 21:03:58,026] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:03:58,037] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.992 seconds
[2022-04-07 21:04:28,177] {processor.py:163} INFO - Started process (PID=12623) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:04:28,178] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:04:28,179] {logging_mixin.py:109} INFO - [2022-04-07 21:04:28,179] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:04:29,032] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:04:29,057] {logging_mixin.py:109} INFO - [2022-04-07 21:04:29,057] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:04:29,077] {logging_mixin.py:109} INFO - [2022-04-07 21:04:29,077] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:04:29,087] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.915 seconds
[2022-04-07 21:04:59,204] {processor.py:163} INFO - Started process (PID=12652) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:04:59,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:04:59,208] {logging_mixin.py:109} INFO - [2022-04-07 21:04:59,208] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:05:00,090] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:05:00,116] {logging_mixin.py:109} INFO - [2022-04-07 21:05:00,115] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:05:00,136] {logging_mixin.py:109} INFO - [2022-04-07 21:05:00,136] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:05:00,148] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 21:05:30,257] {processor.py:163} INFO - Started process (PID=12691) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:05:30,259] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:05:30,260] {logging_mixin.py:109} INFO - [2022-04-07 21:05:30,260] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:05:31,153] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:05:31,177] {logging_mixin.py:109} INFO - [2022-04-07 21:05:31,177] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:05:31,198] {logging_mixin.py:109} INFO - [2022-04-07 21:05:31,198] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:05:31,210] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.959 seconds
[2022-04-07 21:06:01,319] {processor.py:163} INFO - Started process (PID=12721) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:06:01,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:06:01,323] {logging_mixin.py:109} INFO - [2022-04-07 21:06:01,323] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:06:02,175] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:06:02,201] {logging_mixin.py:109} INFO - [2022-04-07 21:06:02,200] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:06:02,221] {logging_mixin.py:109} INFO - [2022-04-07 21:06:02,221] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:06:02,232] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.918 seconds
[2022-04-07 21:06:32,340] {processor.py:163} INFO - Started process (PID=12758) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:06:32,342] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:06:32,343] {logging_mixin.py:109} INFO - [2022-04-07 21:06:32,343] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:06:33,203] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:06:33,224] {logging_mixin.py:109} INFO - [2022-04-07 21:06:33,224] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:06:33,242] {logging_mixin.py:109} INFO - [2022-04-07 21:06:33,242] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:06:33,251] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.916 seconds
[2022-04-07 21:07:03,351] {processor.py:163} INFO - Started process (PID=12785) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:07:03,355] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:07:03,357] {logging_mixin.py:109} INFO - [2022-04-07 21:07:03,356] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:07:04,222] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:07:04,246] {logging_mixin.py:109} INFO - [2022-04-07 21:07:04,245] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:07:04,267] {logging_mixin.py:109} INFO - [2022-04-07 21:07:04,267] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:07:04,282] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.936 seconds
[2022-04-07 21:07:34,389] {processor.py:163} INFO - Started process (PID=12821) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:07:34,391] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:07:34,392] {logging_mixin.py:109} INFO - [2022-04-07 21:07:34,392] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:07:35,263] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:07:35,287] {logging_mixin.py:109} INFO - [2022-04-07 21:07:35,286] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:07:35,305] {logging_mixin.py:109} INFO - [2022-04-07 21:07:35,305] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:07:35,316] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.931 seconds
[2022-04-07 21:08:05,422] {processor.py:163} INFO - Started process (PID=12851) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:08:05,424] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:08:05,425] {logging_mixin.py:109} INFO - [2022-04-07 21:08:05,425] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:08:06,250] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:08:06,274] {logging_mixin.py:109} INFO - [2022-04-07 21:08:06,274] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:08:06,293] {logging_mixin.py:109} INFO - [2022-04-07 21:08:06,293] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:08:06,302] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.885 seconds
[2022-04-07 21:08:36,408] {processor.py:163} INFO - Started process (PID=12887) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:08:36,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:08:36,410] {logging_mixin.py:109} INFO - [2022-04-07 21:08:36,410] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:08:37,278] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:08:37,302] {logging_mixin.py:109} INFO - [2022-04-07 21:08:37,302] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:08:37,324] {logging_mixin.py:109} INFO - [2022-04-07 21:08:37,324] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:08:37,336] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.935 seconds
[2022-04-07 21:09:07,449] {processor.py:163} INFO - Started process (PID=12915) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:09:07,451] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:09:07,452] {logging_mixin.py:109} INFO - [2022-04-07 21:09:07,452] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:09:08,345] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:09:08,380] {logging_mixin.py:109} INFO - [2022-04-07 21:09:08,379] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:09:08,412] {logging_mixin.py:109} INFO - [2022-04-07 21:09:08,411] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:09:08,425] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.982 seconds
[2022-04-07 21:09:38,571] {processor.py:163} INFO - Started process (PID=12954) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:09:38,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:09:38,576] {logging_mixin.py:109} INFO - [2022-04-07 21:09:38,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:09:39,499] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:09:39,523] {logging_mixin.py:109} INFO - [2022-04-07 21:09:39,522] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:09:39,543] {logging_mixin.py:109} INFO - [2022-04-07 21:09:39,543] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:09:39,554] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.988 seconds
[2022-04-07 21:10:09,706] {processor.py:163} INFO - Started process (PID=12983) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:10:09,708] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:10:09,709] {logging_mixin.py:109} INFO - [2022-04-07 21:10:09,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:10:10,645] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:10:10,671] {logging_mixin.py:109} INFO - [2022-04-07 21:10:10,670] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:10:10,691] {logging_mixin.py:109} INFO - [2022-04-07 21:10:10,691] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:10:10,705] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.004 seconds
[2022-04-07 21:10:40,822] {processor.py:163} INFO - Started process (PID=13021) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:10:40,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:10:40,827] {logging_mixin.py:109} INFO - [2022-04-07 21:10:40,827] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:10:41,727] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:10:41,752] {logging_mixin.py:109} INFO - [2022-04-07 21:10:41,752] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:10:41,777] {logging_mixin.py:109} INFO - [2022-04-07 21:10:41,777] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:10:41,789] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.972 seconds
[2022-04-07 21:11:11,930] {processor.py:163} INFO - Started process (PID=13051) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:11:11,933] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:11:11,933] {logging_mixin.py:109} INFO - [2022-04-07 21:11:11,933] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:11:12,821] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:11:12,844] {logging_mixin.py:109} INFO - [2022-04-07 21:11:12,844] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:11:12,862] {logging_mixin.py:109} INFO - [2022-04-07 21:11:12,862] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:11:12,873] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.947 seconds
[2022-04-07 21:11:43,027] {processor.py:163} INFO - Started process (PID=13089) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:11:43,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:11:43,029] {logging_mixin.py:109} INFO - [2022-04-07 21:11:43,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:11:43,909] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:11:43,934] {logging_mixin.py:109} INFO - [2022-04-07 21:11:43,934] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:11:43,963] {logging_mixin.py:109} INFO - [2022-04-07 21:11:43,963] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:11:43,975] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.953 seconds
[2022-04-07 21:12:14,148] {processor.py:163} INFO - Started process (PID=13118) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:12:14,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:12:14,152] {logging_mixin.py:109} INFO - [2022-04-07 21:12:14,152] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:12:15,044] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:12:15,071] {logging_mixin.py:109} INFO - [2022-04-07 21:12:15,070] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:12:15,089] {logging_mixin.py:109} INFO - [2022-04-07 21:12:15,089] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:12:15,099] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.955 seconds
[2022-04-07 21:12:45,248] {processor.py:163} INFO - Started process (PID=13157) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:12:45,250] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:12:45,251] {logging_mixin.py:109} INFO - [2022-04-07 21:12:45,251] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:12:46,248] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:12:46,272] {logging_mixin.py:109} INFO - [2022-04-07 21:12:46,272] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:12:46,292] {logging_mixin.py:109} INFO - [2022-04-07 21:12:46,292] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:12:46,306] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.062 seconds
[2022-04-07 21:13:16,373] {processor.py:163} INFO - Started process (PID=13187) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:13:16,378] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:13:16,379] {logging_mixin.py:109} INFO - [2022-04-07 21:13:16,378] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:13:17,259] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:13:17,284] {logging_mixin.py:109} INFO - [2022-04-07 21:13:17,284] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:13:17,303] {logging_mixin.py:109} INFO - [2022-04-07 21:13:17,303] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:13:17,314] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.947 seconds
[2022-04-07 21:13:47,475] {processor.py:163} INFO - Started process (PID=13225) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:13:47,477] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:13:47,478] {logging_mixin.py:109} INFO - [2022-04-07 21:13:47,478] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:13:48,388] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:13:48,413] {logging_mixin.py:109} INFO - [2022-04-07 21:13:48,412] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:13:48,434] {logging_mixin.py:109} INFO - [2022-04-07 21:13:48,434] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:13:48,445] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.975 seconds
[2022-04-07 21:14:18,590] {processor.py:163} INFO - Started process (PID=13254) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:14:18,592] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:14:18,593] {logging_mixin.py:109} INFO - [2022-04-07 21:14:18,593] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:14:19,491] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:14:19,517] {logging_mixin.py:109} INFO - [2022-04-07 21:14:19,517] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:14:19,536] {logging_mixin.py:109} INFO - [2022-04-07 21:14:19,536] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:14:19,546] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.960 seconds
[2022-04-07 21:14:49,723] {processor.py:163} INFO - Started process (PID=13294) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:14:49,724] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:14:49,725] {logging_mixin.py:109} INFO - [2022-04-07 21:14:49,725] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:14:50,612] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:14:50,641] {logging_mixin.py:109} INFO - [2022-04-07 21:14:50,640] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:14:50,665] {logging_mixin.py:109} INFO - [2022-04-07 21:14:50,665] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:14:50,675] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.956 seconds
[2022-04-07 21:15:20,839] {processor.py:163} INFO - Started process (PID=13331) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:15:20,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:15:20,842] {logging_mixin.py:109} INFO - [2022-04-07 21:15:20,842] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:15:21,679] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:15:21,702] {logging_mixin.py:109} INFO - [2022-04-07 21:15:21,702] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:15:21,721] {logging_mixin.py:109} INFO - [2022-04-07 21:15:21,721] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:15:21,731] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.897 seconds
[2022-04-07 21:15:51,839] {processor.py:163} INFO - Started process (PID=13360) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:15:51,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:15:51,841] {logging_mixin.py:109} INFO - [2022-04-07 21:15:51,841] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:15:52,720] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:15:52,747] {logging_mixin.py:109} INFO - [2022-04-07 21:15:52,746] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:15:52,767] {logging_mixin.py:109} INFO - [2022-04-07 21:15:52,767] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:15:52,778] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 21:16:22,881] {processor.py:163} INFO - Started process (PID=13401) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:16:22,884] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:16:22,886] {logging_mixin.py:109} INFO - [2022-04-07 21:16:22,885] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:16:23,823] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:16:23,851] {logging_mixin.py:109} INFO - [2022-04-07 21:16:23,851] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:16:23,875] {logging_mixin.py:109} INFO - [2022-04-07 21:16:23,875] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:16:23,886] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.010 seconds
[2022-04-07 21:16:54,001] {processor.py:163} INFO - Started process (PID=13429) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:16:54,002] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:16:54,003] {logging_mixin.py:109} INFO - [2022-04-07 21:16:54,003] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:16:54,889] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:16:54,912] {logging_mixin.py:109} INFO - [2022-04-07 21:16:54,911] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:16:54,931] {logging_mixin.py:109} INFO - [2022-04-07 21:16:54,931] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:16:54,940] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 21:17:25,053] {processor.py:163} INFO - Started process (PID=13467) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:17:25,056] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:17:25,058] {logging_mixin.py:109} INFO - [2022-04-07 21:17:25,057] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:17:26,021] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:17:26,048] {logging_mixin.py:109} INFO - [2022-04-07 21:17:26,047] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:17:26,069] {logging_mixin.py:109} INFO - [2022-04-07 21:17:26,069] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:17:26,080] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.032 seconds
[2022-04-07 21:17:56,223] {processor.py:163} INFO - Started process (PID=13499) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:17:56,226] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:17:56,227] {logging_mixin.py:109} INFO - [2022-04-07 21:17:56,227] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:17:57,178] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:17:57,204] {logging_mixin.py:109} INFO - [2022-04-07 21:17:57,203] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:17:57,226] {logging_mixin.py:109} INFO - [2022-04-07 21:17:57,226] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:17:57,236] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.018 seconds
[2022-04-07 21:18:27,339] {processor.py:163} INFO - Started process (PID=13537) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:18:27,341] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:18:27,342] {logging_mixin.py:109} INFO - [2022-04-07 21:18:27,342] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:18:28,275] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:18:28,306] {logging_mixin.py:109} INFO - [2022-04-07 21:18:28,305] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:18:28,329] {logging_mixin.py:109} INFO - [2022-04-07 21:18:28,329] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:18:28,340] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.005 seconds
[2022-04-07 21:18:58,461] {processor.py:163} INFO - Started process (PID=13567) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:18:58,464] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:18:58,465] {logging_mixin.py:109} INFO - [2022-04-07 21:18:58,464] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:18:59,369] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:18:59,394] {logging_mixin.py:109} INFO - [2022-04-07 21:18:59,394] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:18:59,413] {logging_mixin.py:109} INFO - [2022-04-07 21:18:59,413] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:18:59,423] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.966 seconds
[2022-04-07 21:19:29,576] {processor.py:163} INFO - Started process (PID=13607) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:19:29,578] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:19:29,579] {logging_mixin.py:109} INFO - [2022-04-07 21:19:29,579] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:19:30,504] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:19:30,531] {logging_mixin.py:109} INFO - [2022-04-07 21:19:30,531] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:19:30,553] {logging_mixin.py:109} INFO - [2022-04-07 21:19:30,553] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:19:30,563] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.993 seconds
[2022-04-07 21:20:00,715] {processor.py:163} INFO - Started process (PID=13634) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:20:00,716] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:20:00,717] {logging_mixin.py:109} INFO - [2022-04-07 21:20:00,717] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:20:01,602] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:20:01,626] {logging_mixin.py:109} INFO - [2022-04-07 21:20:01,626] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:20:01,646] {logging_mixin.py:109} INFO - [2022-04-07 21:20:01,645] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:20:01,656] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.948 seconds
[2022-04-07 21:20:31,819] {processor.py:163} INFO - Started process (PID=13672) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:20:31,822] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:20:31,823] {logging_mixin.py:109} INFO - [2022-04-07 21:20:31,823] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:20:32,702] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:20:32,727] {logging_mixin.py:109} INFO - [2022-04-07 21:20:32,726] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:20:32,745] {logging_mixin.py:109} INFO - [2022-04-07 21:20:32,745] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:20:32,755] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.940 seconds
[2022-04-07 21:21:02,865] {processor.py:163} INFO - Started process (PID=13701) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:21:02,867] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:21:02,868] {logging_mixin.py:109} INFO - [2022-04-07 21:21:02,867] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:21:03,708] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:21:03,735] {logging_mixin.py:109} INFO - [2022-04-07 21:21:03,735] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:21:03,760] {logging_mixin.py:109} INFO - [2022-04-07 21:21:03,760] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:21:03,773] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.914 seconds
[2022-04-07 21:21:33,878] {processor.py:163} INFO - Started process (PID=13740) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:21:33,883] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:21:33,884] {logging_mixin.py:109} INFO - [2022-04-07 21:21:33,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:21:34,751] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:21:34,773] {logging_mixin.py:109} INFO - [2022-04-07 21:21:34,773] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:21:34,792] {logging_mixin.py:109} INFO - [2022-04-07 21:21:34,792] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:21:34,802] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.929 seconds
[2022-04-07 21:22:04,902] {processor.py:163} INFO - Started process (PID=13767) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:22:04,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:22:04,905] {logging_mixin.py:109} INFO - [2022-04-07 21:22:04,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:22:05,781] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:22:05,806] {logging_mixin.py:109} INFO - [2022-04-07 21:22:05,805] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:22:05,825] {logging_mixin.py:109} INFO - [2022-04-07 21:22:05,824] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:22:05,834] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.937 seconds
[2022-04-07 21:22:35,934] {processor.py:163} INFO - Started process (PID=13804) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:22:35,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:22:35,938] {logging_mixin.py:109} INFO - [2022-04-07 21:22:35,938] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:22:36,812] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:22:36,836] {logging_mixin.py:109} INFO - [2022-04-07 21:22:36,835] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:22:36,854] {logging_mixin.py:109} INFO - [2022-04-07 21:22:36,854] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:22:36,864] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.935 seconds
[2022-04-07 21:23:06,962] {processor.py:163} INFO - Started process (PID=13832) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:23:06,965] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:23:06,965] {logging_mixin.py:109} INFO - [2022-04-07 21:23:06,965] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:23:07,827] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:23:07,849] {logging_mixin.py:109} INFO - [2022-04-07 21:23:07,849] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:23:07,868] {logging_mixin.py:109} INFO - [2022-04-07 21:23:07,867] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:23:07,877] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.920 seconds
[2022-04-07 21:23:37,980] {processor.py:163} INFO - Started process (PID=13872) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:23:37,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:23:37,983] {logging_mixin.py:109} INFO - [2022-04-07 21:23:37,983] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:23:38,854] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:23:38,878] {logging_mixin.py:109} INFO - [2022-04-07 21:23:38,877] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:23:38,898] {logging_mixin.py:109} INFO - [2022-04-07 21:23:38,897] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:23:38,909] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.935 seconds
[2022-04-07 21:24:09,008] {processor.py:163} INFO - Started process (PID=13902) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:24:09,011] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:24:09,012] {logging_mixin.py:109} INFO - [2022-04-07 21:24:09,012] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:24:09,884] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:24:09,907] {logging_mixin.py:109} INFO - [2022-04-07 21:24:09,906] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:24:09,925] {logging_mixin.py:109} INFO - [2022-04-07 21:24:09,925] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:24:09,935] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.932 seconds
[2022-04-07 21:24:40,038] {processor.py:163} INFO - Started process (PID=13939) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:24:40,040] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:24:40,041] {logging_mixin.py:109} INFO - [2022-04-07 21:24:40,041] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:24:40,913] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:24:40,936] {logging_mixin.py:109} INFO - [2022-04-07 21:24:40,936] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:24:40,954] {logging_mixin.py:109} INFO - [2022-04-07 21:24:40,954] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:24:40,963] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.931 seconds
[2022-04-07 21:25:11,075] {processor.py:163} INFO - Started process (PID=13966) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:25:11,078] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:25:11,079] {logging_mixin.py:109} INFO - [2022-04-07 21:25:11,079] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:25:11,949] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:25:11,972] {logging_mixin.py:109} INFO - [2022-04-07 21:25:11,971] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:25:11,990] {logging_mixin.py:109} INFO - [2022-04-07 21:25:11,990] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:25:11,999] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.930 seconds
[2022-04-07 21:25:42,106] {processor.py:163} INFO - Started process (PID=14004) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:25:42,108] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:25:42,109] {logging_mixin.py:109} INFO - [2022-04-07 21:25:42,108] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:25:42,962] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:25:42,984] {logging_mixin.py:109} INFO - [2022-04-07 21:25:42,984] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:25:43,006] {logging_mixin.py:109} INFO - [2022-04-07 21:25:43,006] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:25:43,018] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.917 seconds
[2022-04-07 21:26:13,137] {processor.py:163} INFO - Started process (PID=14032) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:26:13,139] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:26:13,140] {logging_mixin.py:109} INFO - [2022-04-07 21:26:13,140] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:26:13,998] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:26:14,021] {logging_mixin.py:109} INFO - [2022-04-07 21:26:14,020] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:26:14,039] {logging_mixin.py:109} INFO - [2022-04-07 21:26:14,039] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:26:14,049] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.917 seconds
[2022-04-07 21:26:44,146] {processor.py:163} INFO - Started process (PID=14069) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:26:44,147] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:26:44,148] {logging_mixin.py:109} INFO - [2022-04-07 21:26:44,148] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:26:45,026] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:26:45,049] {logging_mixin.py:109} INFO - [2022-04-07 21:26:45,049] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:26:45,068] {logging_mixin.py:109} INFO - [2022-04-07 21:26:45,068] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:26:45,078] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.937 seconds
[2022-04-07 21:27:15,177] {processor.py:163} INFO - Started process (PID=14097) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:27:15,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:27:15,180] {logging_mixin.py:109} INFO - [2022-04-07 21:27:15,179] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:27:16,015] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:27:16,039] {logging_mixin.py:109} INFO - [2022-04-07 21:27:16,038] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:27:16,058] {logging_mixin.py:109} INFO - [2022-04-07 21:27:16,058] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:27:16,070] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.897 seconds
[2022-04-07 21:27:46,216] {processor.py:163} INFO - Started process (PID=14135) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:27:46,219] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:27:46,220] {logging_mixin.py:109} INFO - [2022-04-07 21:27:46,220] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:27:47,131] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:27:47,155] {logging_mixin.py:109} INFO - [2022-04-07 21:27:47,154] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:27:47,174] {logging_mixin.py:109} INFO - [2022-04-07 21:27:47,174] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:27:47,184] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.973 seconds
[2022-04-07 21:28:17,332] {processor.py:163} INFO - Started process (PID=14164) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:28:17,335] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:28:17,336] {logging_mixin.py:109} INFO - [2022-04-07 21:28:17,336] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:28:18,200] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:28:18,224] {logging_mixin.py:109} INFO - [2022-04-07 21:28:18,224] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:28:18,242] {logging_mixin.py:109} INFO - [2022-04-07 21:28:18,242] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:28:18,252] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.924 seconds
[2022-04-07 21:28:48,360] {processor.py:163} INFO - Started process (PID=14202) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:28:48,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:28:48,364] {logging_mixin.py:109} INFO - [2022-04-07 21:28:48,364] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:28:49,218] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:28:49,241] {logging_mixin.py:109} INFO - [2022-04-07 21:28:49,241] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:28:49,262] {logging_mixin.py:109} INFO - [2022-04-07 21:28:49,261] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:28:49,271] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.916 seconds
[2022-04-07 21:29:19,388] {processor.py:163} INFO - Started process (PID=14231) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:29:19,393] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:29:19,394] {logging_mixin.py:109} INFO - [2022-04-07 21:29:19,394] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:29:20,278] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:29:20,307] {logging_mixin.py:109} INFO - [2022-04-07 21:29:20,307] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:29:20,327] {logging_mixin.py:109} INFO - [2022-04-07 21:29:20,326] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:29:20,337] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.956 seconds
[2022-04-07 21:29:50,441] {processor.py:163} INFO - Started process (PID=14271) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:29:50,444] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:29:50,445] {logging_mixin.py:109} INFO - [2022-04-07 21:29:50,445] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:29:51,478] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:29:51,503] {logging_mixin.py:109} INFO - [2022-04-07 21:29:51,502] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:29:51,526] {logging_mixin.py:109} INFO - [2022-04-07 21:29:51,526] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:29:51,539] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.104 seconds
[2022-04-07 21:30:21,642] {processor.py:163} INFO - Started process (PID=14300) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:30:21,644] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:30:21,645] {logging_mixin.py:109} INFO - [2022-04-07 21:30:21,645] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:30:22,606] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:30:22,634] {logging_mixin.py:109} INFO - [2022-04-07 21:30:22,633] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:30:22,655] {logging_mixin.py:109} INFO - [2022-04-07 21:30:22,655] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:30:22,668] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.032 seconds
[2022-04-07 21:30:52,758] {processor.py:163} INFO - Started process (PID=14339) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:30:52,761] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:30:52,762] {logging_mixin.py:109} INFO - [2022-04-07 21:30:52,762] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:30:53,727] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:30:53,751] {logging_mixin.py:109} INFO - [2022-04-07 21:30:53,751] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:30:53,771] {logging_mixin.py:109} INFO - [2022-04-07 21:30:53,770] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:30:53,781] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.028 seconds
[2022-04-07 21:31:23,894] {processor.py:163} INFO - Started process (PID=14366) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:31:23,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:31:23,897] {logging_mixin.py:109} INFO - [2022-04-07 21:31:23,897] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:31:24,818] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:31:24,843] {logging_mixin.py:109} INFO - [2022-04-07 21:31:24,843] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:31:24,862] {logging_mixin.py:109} INFO - [2022-04-07 21:31:24,862] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:31:24,873] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.983 seconds
[2022-04-07 21:31:55,024] {processor.py:163} INFO - Started process (PID=14404) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:31:55,026] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:31:55,027] {logging_mixin.py:109} INFO - [2022-04-07 21:31:55,026] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:31:55,961] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:31:55,984] {logging_mixin.py:109} INFO - [2022-04-07 21:31:55,984] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:31:56,004] {logging_mixin.py:109} INFO - [2022-04-07 21:31:56,003] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:31:56,014] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.994 seconds
[2022-04-07 21:32:26,149] {processor.py:163} INFO - Started process (PID=14432) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:32:26,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:32:26,153] {logging_mixin.py:109} INFO - [2022-04-07 21:32:26,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:32:27,127] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:32:27,155] {logging_mixin.py:109} INFO - [2022-04-07 21:32:27,154] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:32:27,175] {logging_mixin.py:109} INFO - [2022-04-07 21:32:27,175] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:32:27,185] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.040 seconds
[2022-04-07 21:32:57,261] {processor.py:163} INFO - Started process (PID=14472) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:32:57,263] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:32:57,264] {logging_mixin.py:109} INFO - [2022-04-07 21:32:57,264] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:32:58,235] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:32:58,263] {logging_mixin.py:109} INFO - [2022-04-07 21:32:58,263] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:32:58,286] {logging_mixin.py:109} INFO - [2022-04-07 21:32:58,286] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:32:58,297] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.041 seconds
[2022-04-07 21:33:28,391] {processor.py:163} INFO - Started process (PID=14511) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:33:28,393] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:33:28,394] {logging_mixin.py:109} INFO - [2022-04-07 21:33:28,394] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:33:29,324] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:33:29,350] {logging_mixin.py:109} INFO - [2022-04-07 21:33:29,350] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:33:29,372] {logging_mixin.py:109} INFO - [2022-04-07 21:33:29,372] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:33:29,384] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.997 seconds
[2022-04-07 21:33:59,513] {processor.py:163} INFO - Started process (PID=14540) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:33:59,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:33:59,516] {logging_mixin.py:109} INFO - [2022-04-07 21:33:59,516] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:34:00,457] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:34:00,483] {logging_mixin.py:109} INFO - [2022-04-07 21:34:00,482] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:34:00,504] {logging_mixin.py:109} INFO - [2022-04-07 21:34:00,504] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:34:00,515] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 21:34:30,636] {processor.py:163} INFO - Started process (PID=14576) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:34:30,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:34:30,640] {logging_mixin.py:109} INFO - [2022-04-07 21:34:30,639] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:34:31,474] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:34:31,496] {logging_mixin.py:109} INFO - [2022-04-07 21:34:31,495] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:34:31,518] {logging_mixin.py:109} INFO - [2022-04-07 21:34:31,518] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:34:31,527] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.896 seconds
[2022-04-07 21:35:01,654] {processor.py:163} INFO - Started process (PID=14603) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:35:01,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:35:01,657] {logging_mixin.py:109} INFO - [2022-04-07 21:35:01,657] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:35:02,521] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:35:02,547] {logging_mixin.py:109} INFO - [2022-04-07 21:35:02,546] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:35:02,565] {logging_mixin.py:109} INFO - [2022-04-07 21:35:02,565] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:35:02,575] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.925 seconds
[2022-04-07 21:35:32,681] {processor.py:163} INFO - Started process (PID=14642) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:35:32,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:35:32,685] {logging_mixin.py:109} INFO - [2022-04-07 21:35:32,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:35:33,536] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:35:33,560] {logging_mixin.py:109} INFO - [2022-04-07 21:35:33,560] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:35:33,578] {logging_mixin.py:109} INFO - [2022-04-07 21:35:33,577] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:35:33,587] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.912 seconds
[2022-04-07 21:36:03,686] {processor.py:163} INFO - Started process (PID=14672) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:36:03,688] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:36:03,689] {logging_mixin.py:109} INFO - [2022-04-07 21:36:03,689] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:36:04,532] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:36:04,555] {logging_mixin.py:109} INFO - [2022-04-07 21:36:04,555] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:36:04,573] {logging_mixin.py:109} INFO - [2022-04-07 21:36:04,573] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:36:04,582] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.901 seconds
[2022-04-07 21:36:34,689] {processor.py:163} INFO - Started process (PID=14708) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:36:34,691] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:36:34,692] {logging_mixin.py:109} INFO - [2022-04-07 21:36:34,692] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:36:35,536] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:36:35,560] {logging_mixin.py:109} INFO - [2022-04-07 21:36:35,559] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:36:35,577] {logging_mixin.py:109} INFO - [2022-04-07 21:36:35,577] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:36:35,586] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.902 seconds
[2022-04-07 21:37:05,680] {processor.py:163} INFO - Started process (PID=14734) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:37:05,681] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:37:05,682] {logging_mixin.py:109} INFO - [2022-04-07 21:37:05,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:37:06,501] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:37:06,523] {logging_mixin.py:109} INFO - [2022-04-07 21:37:06,523] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:37:06,540] {logging_mixin.py:109} INFO - [2022-04-07 21:37:06,540] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:37:06,549] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.875 seconds
[2022-04-07 21:37:36,647] {processor.py:163} INFO - Started process (PID=14772) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:37:36,649] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:37:36,650] {logging_mixin.py:109} INFO - [2022-04-07 21:37:36,649] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:37:37,482] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:37:37,505] {logging_mixin.py:109} INFO - [2022-04-07 21:37:37,504] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:37:37,522] {logging_mixin.py:109} INFO - [2022-04-07 21:37:37,522] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:37:37,532] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.890 seconds
[2022-04-07 21:38:07,629] {processor.py:163} INFO - Started process (PID=14800) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:38:07,632] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:38:07,633] {logging_mixin.py:109} INFO - [2022-04-07 21:38:07,633] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:38:08,495] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:38:08,517] {logging_mixin.py:109} INFO - [2022-04-07 21:38:08,517] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:38:08,537] {logging_mixin.py:109} INFO - [2022-04-07 21:38:08,537] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:38:08,547] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.924 seconds
[2022-04-07 21:38:38,641] {processor.py:163} INFO - Started process (PID=14838) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:38:38,646] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:38:38,647] {logging_mixin.py:109} INFO - [2022-04-07 21:38:38,647] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:38:39,507] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:38:39,531] {logging_mixin.py:109} INFO - [2022-04-07 21:38:39,531] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:38:39,549] {logging_mixin.py:109} INFO - [2022-04-07 21:38:39,549] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:38:39,559] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.923 seconds
[2022-04-07 21:39:09,651] {processor.py:163} INFO - Started process (PID=14867) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:39:09,652] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:39:09,654] {logging_mixin.py:109} INFO - [2022-04-07 21:39:09,653] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:39:10,517] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:39:10,541] {logging_mixin.py:109} INFO - [2022-04-07 21:39:10,540] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:39:10,560] {logging_mixin.py:109} INFO - [2022-04-07 21:39:10,560] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:39:10,570] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.924 seconds
[2022-04-07 21:39:40,625] {processor.py:163} INFO - Started process (PID=14907) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:39:40,627] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:39:40,628] {logging_mixin.py:109} INFO - [2022-04-07 21:39:40,628] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:39:41,480] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:39:41,526] {logging_mixin.py:109} INFO - [2022-04-07 21:39:41,526] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:39:41,546] {logging_mixin.py:109} INFO - [2022-04-07 21:39:41,546] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:39:41,554] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 21:40:11,660] {processor.py:163} INFO - Started process (PID=14935) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:40:11,666] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:40:11,667] {logging_mixin.py:109} INFO - [2022-04-07 21:40:11,667] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:40:12,514] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:40:12,537] {logging_mixin.py:109} INFO - [2022-04-07 21:40:12,536] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:40:12,554] {logging_mixin.py:109} INFO - [2022-04-07 21:40:12,554] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:40:12,563] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.908 seconds
[2022-04-07 21:40:42,666] {processor.py:163} INFO - Started process (PID=14974) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:40:42,669] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:40:42,670] {logging_mixin.py:109} INFO - [2022-04-07 21:40:42,670] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:40:43,525] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:40:43,548] {logging_mixin.py:109} INFO - [2022-04-07 21:40:43,548] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:40:43,566] {logging_mixin.py:109} INFO - [2022-04-07 21:40:43,566] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:40:43,576] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.914 seconds
[2022-04-07 21:41:13,676] {processor.py:163} INFO - Started process (PID=15003) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:41:13,679] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:41:13,680] {logging_mixin.py:109} INFO - [2022-04-07 21:41:13,679] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:41:14,547] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:41:14,569] {logging_mixin.py:109} INFO - [2022-04-07 21:41:14,568] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:41:14,586] {logging_mixin.py:109} INFO - [2022-04-07 21:41:14,585] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:41:14,594] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.923 seconds
[2022-04-07 21:41:44,694] {processor.py:163} INFO - Started process (PID=15041) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:41:44,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:41:44,698] {logging_mixin.py:109} INFO - [2022-04-07 21:41:44,698] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:41:45,548] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:41:45,572] {logging_mixin.py:109} INFO - [2022-04-07 21:41:45,571] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:41:45,590] {logging_mixin.py:109} INFO - [2022-04-07 21:41:45,590] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:41:45,598] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.910 seconds
[2022-04-07 21:42:15,697] {processor.py:163} INFO - Started process (PID=15069) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:42:15,700] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:42:15,701] {logging_mixin.py:109} INFO - [2022-04-07 21:42:15,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:42:16,557] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:42:16,581] {logging_mixin.py:109} INFO - [2022-04-07 21:42:16,580] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:42:16,599] {logging_mixin.py:109} INFO - [2022-04-07 21:42:16,598] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:42:16,609] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.917 seconds
[2022-04-07 21:42:46,706] {processor.py:163} INFO - Started process (PID=15106) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:42:46,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:42:46,709] {logging_mixin.py:109} INFO - [2022-04-07 21:42:46,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:42:47,587] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:42:47,609] {logging_mixin.py:109} INFO - [2022-04-07 21:42:47,608] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:42:47,627] {logging_mixin.py:109} INFO - [2022-04-07 21:42:47,627] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:42:47,638] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.937 seconds
[2022-04-07 21:43:17,739] {processor.py:163} INFO - Started process (PID=15135) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:43:17,743] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:43:17,744] {logging_mixin.py:109} INFO - [2022-04-07 21:43:17,743] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:43:18,615] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:43:18,638] {logging_mixin.py:109} INFO - [2022-04-07 21:43:18,638] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:43:18,657] {logging_mixin.py:109} INFO - [2022-04-07 21:43:18,657] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:43:18,670] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.936 seconds
[2022-04-07 21:43:48,771] {processor.py:163} INFO - Started process (PID=15174) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:43:48,774] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:43:48,775] {logging_mixin.py:109} INFO - [2022-04-07 21:43:48,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:43:49,651] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:43:49,674] {logging_mixin.py:109} INFO - [2022-04-07 21:43:49,674] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:43:49,699] {logging_mixin.py:109} INFO - [2022-04-07 21:43:49,698] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:43:49,714] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.947 seconds
[2022-04-07 21:44:19,843] {processor.py:163} INFO - Started process (PID=15202) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:44:19,845] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:44:19,846] {logging_mixin.py:109} INFO - [2022-04-07 21:44:19,846] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:44:20,728] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:44:20,761] {logging_mixin.py:109} INFO - [2022-04-07 21:44:20,760] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:44:20,780] {logging_mixin.py:109} INFO - [2022-04-07 21:44:20,780] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:44:20,793] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.955 seconds
[2022-04-07 21:44:50,899] {processor.py:163} INFO - Started process (PID=15240) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:44:50,902] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:44:50,903] {logging_mixin.py:109} INFO - [2022-04-07 21:44:50,903] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:44:51,884] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:44:51,908] {logging_mixin.py:109} INFO - [2022-04-07 21:44:51,907] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:44:51,927] {logging_mixin.py:109} INFO - [2022-04-07 21:44:51,927] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:44:51,938] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.044 seconds
[2022-04-07 21:45:22,050] {processor.py:163} INFO - Started process (PID=15268) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:45:22,053] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:45:22,053] {logging_mixin.py:109} INFO - [2022-04-07 21:45:22,053] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:45:22,977] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:45:23,000] {logging_mixin.py:109} INFO - [2022-04-07 21:45:23,000] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:45:23,019] {logging_mixin.py:109} INFO - [2022-04-07 21:45:23,019] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:45:23,029] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.983 seconds
[2022-04-07 21:45:53,179] {processor.py:163} INFO - Started process (PID=15308) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:45:53,181] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:45:53,182] {logging_mixin.py:109} INFO - [2022-04-07 21:45:53,182] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:45:54,093] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:45:54,121] {logging_mixin.py:109} INFO - [2022-04-07 21:45:54,121] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:45:54,141] {logging_mixin.py:109} INFO - [2022-04-07 21:45:54,141] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:45:54,151] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.977 seconds
[2022-04-07 21:46:24,298] {processor.py:163} INFO - Started process (PID=15345) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:46:24,303] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:46:24,304] {logging_mixin.py:109} INFO - [2022-04-07 21:46:24,304] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:46:25,188] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:46:25,211] {logging_mixin.py:109} INFO - [2022-04-07 21:46:25,211] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:46:25,236] {logging_mixin.py:109} INFO - [2022-04-07 21:46:25,236] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:46:25,245] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.952 seconds
[2022-04-07 21:46:55,393] {processor.py:163} INFO - Started process (PID=15373) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:46:55,394] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:46:55,395] {logging_mixin.py:109} INFO - [2022-04-07 21:46:55,395] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:46:56,257] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:46:56,280] {logging_mixin.py:109} INFO - [2022-04-07 21:46:56,279] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:46:56,297] {logging_mixin.py:109} INFO - [2022-04-07 21:46:56,297] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:46:56,307] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.919 seconds
[2022-04-07 21:47:26,417] {processor.py:163} INFO - Started process (PID=15411) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:47:26,423] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:47:26,423] {logging_mixin.py:109} INFO - [2022-04-07 21:47:26,423] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:47:27,327] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:47:27,351] {logging_mixin.py:109} INFO - [2022-04-07 21:47:27,350] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:47:27,370] {logging_mixin.py:109} INFO - [2022-04-07 21:47:27,370] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:47:27,381] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.969 seconds
[2022-04-07 21:47:57,485] {processor.py:163} INFO - Started process (PID=15440) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:47:57,486] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:47:57,487] {logging_mixin.py:109} INFO - [2022-04-07 21:47:57,487] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:47:58,464] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:47:58,491] {logging_mixin.py:109} INFO - [2022-04-07 21:47:58,491] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:47:58,511] {logging_mixin.py:109} INFO - [2022-04-07 21:47:58,511] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:47:58,521] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.041 seconds
[2022-04-07 21:48:28,616] {processor.py:163} INFO - Started process (PID=15477) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:48:28,620] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:48:28,622] {logging_mixin.py:109} INFO - [2022-04-07 21:48:28,622] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:48:29,566] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:48:29,589] {logging_mixin.py:109} INFO - [2022-04-07 21:48:29,588] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:48:29,609] {logging_mixin.py:109} INFO - [2022-04-07 21:48:29,609] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:48:29,619] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 21:48:59,751] {processor.py:163} INFO - Started process (PID=15505) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:48:59,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:48:59,753] {logging_mixin.py:109} INFO - [2022-04-07 21:48:59,753] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:49:00,632] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:49:00,655] {logging_mixin.py:109} INFO - [2022-04-07 21:49:00,654] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:49:00,675] {logging_mixin.py:109} INFO - [2022-04-07 21:49:00,675] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:49:00,685] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.939 seconds
[2022-04-07 21:49:30,802] {processor.py:163} INFO - Started process (PID=15542) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:49:30,803] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:49:30,804] {logging_mixin.py:109} INFO - [2022-04-07 21:49:30,804] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:49:31,669] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:49:31,694] {logging_mixin.py:109} INFO - [2022-04-07 21:49:31,693] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:49:31,716] {logging_mixin.py:109} INFO - [2022-04-07 21:49:31,715] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:49:31,728] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.932 seconds
[2022-04-07 21:50:01,841] {processor.py:163} INFO - Started process (PID=15570) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:50:01,843] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:50:01,844] {logging_mixin.py:109} INFO - [2022-04-07 21:50:01,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:50:02,716] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:50:02,749] {logging_mixin.py:109} INFO - [2022-04-07 21:50:02,749] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:50:02,769] {logging_mixin.py:109} INFO - [2022-04-07 21:50:02,769] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:50:02,778] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.942 seconds
[2022-04-07 21:50:32,885] {processor.py:163} INFO - Started process (PID=15608) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:50:32,888] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:50:32,889] {logging_mixin.py:109} INFO - [2022-04-07 21:50:32,889] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:50:33,770] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:50:33,795] {logging_mixin.py:109} INFO - [2022-04-07 21:50:33,795] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:50:33,814] {logging_mixin.py:109} INFO - [2022-04-07 21:50:33,814] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:50:33,824] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.945 seconds
[2022-04-07 21:51:03,927] {processor.py:163} INFO - Started process (PID=15636) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:51:03,930] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:51:03,931] {logging_mixin.py:109} INFO - [2022-04-07 21:51:03,931] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:51:04,811] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:51:04,838] {logging_mixin.py:109} INFO - [2022-04-07 21:51:04,837] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:51:04,857] {logging_mixin.py:109} INFO - [2022-04-07 21:51:04,857] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:51:04,873] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.951 seconds
[2022-04-07 21:51:34,975] {processor.py:163} INFO - Started process (PID=15673) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:51:34,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:51:34,979] {logging_mixin.py:109} INFO - [2022-04-07 21:51:34,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:51:35,827] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:51:35,850] {logging_mixin.py:109} INFO - [2022-04-07 21:51:35,850] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:51:35,868] {logging_mixin.py:109} INFO - [2022-04-07 21:51:35,868] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:51:35,879] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.910 seconds
[2022-04-07 21:52:05,982] {processor.py:163} INFO - Started process (PID=15702) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:52:05,985] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:52:05,986] {logging_mixin.py:109} INFO - [2022-04-07 21:52:05,985] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:52:06,874] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:52:06,901] {logging_mixin.py:109} INFO - [2022-04-07 21:52:06,900] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:52:06,920] {logging_mixin.py:109} INFO - [2022-04-07 21:52:06,920] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:52:06,932] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.955 seconds
[2022-04-07 21:52:37,034] {processor.py:163} INFO - Started process (PID=15741) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:52:37,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:52:37,038] {logging_mixin.py:109} INFO - [2022-04-07 21:52:37,038] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:52:37,896] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:52:37,921] {logging_mixin.py:109} INFO - [2022-04-07 21:52:37,921] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:52:37,941] {logging_mixin.py:109} INFO - [2022-04-07 21:52:37,941] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:52:37,952] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.922 seconds
[2022-04-07 21:53:08,059] {processor.py:163} INFO - Started process (PID=15769) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:53:08,063] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:53:08,064] {logging_mixin.py:109} INFO - [2022-04-07 21:53:08,064] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:53:08,996] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:53:09,024] {logging_mixin.py:109} INFO - [2022-04-07 21:53:09,023] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:53:09,045] {logging_mixin.py:109} INFO - [2022-04-07 21:53:09,045] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:53:09,061] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.008 seconds
[2022-04-07 21:53:39,187] {processor.py:163} INFO - Started process (PID=15808) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:53:39,189] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:53:39,189] {logging_mixin.py:109} INFO - [2022-04-07 21:53:39,189] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:53:40,082] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:53:40,108] {logging_mixin.py:109} INFO - [2022-04-07 21:53:40,108] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:53:40,127] {logging_mixin.py:109} INFO - [2022-04-07 21:53:40,127] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:53:40,137] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.956 seconds
[2022-04-07 21:54:10,284] {processor.py:163} INFO - Started process (PID=15835) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:54:10,287] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:54:10,288] {logging_mixin.py:109} INFO - [2022-04-07 21:54:10,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:54:11,259] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:54:11,282] {logging_mixin.py:109} INFO - [2022-04-07 21:54:11,282] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:54:11,301] {logging_mixin.py:109} INFO - [2022-04-07 21:54:11,301] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:54:11,311] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.032 seconds
[2022-04-07 21:54:41,415] {processor.py:163} INFO - Started process (PID=15874) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:54:41,418] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:54:41,419] {logging_mixin.py:109} INFO - [2022-04-07 21:54:41,418] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:54:42,294] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:54:42,318] {logging_mixin.py:109} INFO - [2022-04-07 21:54:42,317] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:54:42,337] {logging_mixin.py:109} INFO - [2022-04-07 21:54:42,337] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:54:42,348] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.937 seconds
[2022-04-07 21:55:12,474] {processor.py:163} INFO - Started process (PID=15902) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:55:12,477] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:55:12,478] {logging_mixin.py:109} INFO - [2022-04-07 21:55:12,478] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:55:13,436] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:55:13,466] {logging_mixin.py:109} INFO - [2022-04-07 21:55:13,466] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:55:13,493] {logging_mixin.py:109} INFO - [2022-04-07 21:55:13,493] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:55:13,508] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.040 seconds
[2022-04-07 21:55:43,646] {processor.py:163} INFO - Started process (PID=15941) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:55:43,650] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:55:43,651] {logging_mixin.py:109} INFO - [2022-04-07 21:55:43,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:55:44,603] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:55:44,626] {logging_mixin.py:109} INFO - [2022-04-07 21:55:44,626] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:55:44,645] {logging_mixin.py:109} INFO - [2022-04-07 21:55:44,645] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:55:44,656] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.016 seconds
[2022-04-07 21:56:14,765] {processor.py:163} INFO - Started process (PID=15970) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:56:14,768] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:56:14,768] {logging_mixin.py:109} INFO - [2022-04-07 21:56:14,768] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:56:15,645] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:56:15,668] {logging_mixin.py:109} INFO - [2022-04-07 21:56:15,668] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:56:15,689] {logging_mixin.py:109} INFO - [2022-04-07 21:56:15,689] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:56:15,700] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.939 seconds
[2022-04-07 21:56:45,814] {processor.py:163} INFO - Started process (PID=16008) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:56:45,817] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:56:45,818] {logging_mixin.py:109} INFO - [2022-04-07 21:56:45,818] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:56:46,679] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:56:46,700] {logging_mixin.py:109} INFO - [2022-04-07 21:56:46,700] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:56:46,718] {logging_mixin.py:109} INFO - [2022-04-07 21:56:46,718] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:56:46,727] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.918 seconds
[2022-04-07 21:57:16,831] {processor.py:163} INFO - Started process (PID=16037) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:57:16,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:57:16,833] {logging_mixin.py:109} INFO - [2022-04-07 21:57:16,833] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:57:17,677] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:57:17,701] {logging_mixin.py:109} INFO - [2022-04-07 21:57:17,700] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:57:17,719] {logging_mixin.py:109} INFO - [2022-04-07 21:57:17,718] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:57:17,729] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.903 seconds
[2022-04-07 21:57:47,841] {processor.py:163} INFO - Started process (PID=16074) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:57:47,846] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:57:47,847] {logging_mixin.py:109} INFO - [2022-04-07 21:57:47,847] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:57:48,746] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:57:48,770] {logging_mixin.py:109} INFO - [2022-04-07 21:57:48,769] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:57:48,789] {logging_mixin.py:109} INFO - [2022-04-07 21:57:48,789] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:57:48,803] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.967 seconds
[2022-04-07 21:58:18,906] {processor.py:163} INFO - Started process (PID=16103) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:58:18,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:58:18,909] {logging_mixin.py:109} INFO - [2022-04-07 21:58:18,909] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:58:19,769] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:58:19,793] {logging_mixin.py:109} INFO - [2022-04-07 21:58:19,793] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:58:19,815] {logging_mixin.py:109} INFO - [2022-04-07 21:58:19,815] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:58:19,825] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.924 seconds
[2022-04-07 21:58:49,941] {processor.py:163} INFO - Started process (PID=16142) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:58:49,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:58:49,946] {logging_mixin.py:109} INFO - [2022-04-07 21:58:49,945] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:58:50,850] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:58:50,883] {logging_mixin.py:109} INFO - [2022-04-07 21:58:50,882] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:58:50,908] {logging_mixin.py:109} INFO - [2022-04-07 21:58:50,908] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:58:50,920] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.987 seconds
[2022-04-07 21:59:21,058] {processor.py:163} INFO - Started process (PID=16171) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:59:21,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 21:59:21,060] {logging_mixin.py:109} INFO - [2022-04-07 21:59:21,060] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:59:21,900] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 21:59:21,923] {logging_mixin.py:109} INFO - [2022-04-07 21:59:21,922] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 21:59:21,942] {logging_mixin.py:109} INFO - [2022-04-07 21:59:21,942] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 21:59:21,951] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.897 seconds
[2022-04-07 22:01:34,884] {processor.py:163} INFO - Started process (PID=196) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:01:34,898] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:01:34,901] {logging_mixin.py:109} INFO - [2022-04-07 22:01:34,900] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:01:37,982] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:01:38,011] {logging_mixin.py:109} INFO - [2022-04-07 22:01:38,011] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:01:38,036] {logging_mixin.py:109} INFO - [2022-04-07 22:01:38,036] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:01:38,047] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.178 seconds
[2022-04-07 22:02:08,105] {processor.py:163} INFO - Started process (PID=227) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:02:08,106] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:02:08,107] {logging_mixin.py:109} INFO - [2022-04-07 22:02:08,107] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:02:08,940] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:02:08,966] {logging_mixin.py:109} INFO - [2022-04-07 22:02:08,966] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:02:09,088] {logging_mixin.py:109} INFO - [2022-04-07 22:02:09,088] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:02:09,106] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 22:02:39,226] {processor.py:163} INFO - Started process (PID=265) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:02:39,227] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:02:39,228] {logging_mixin.py:109} INFO - [2022-04-07 22:02:39,228] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:02:40,077] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:02:40,104] {logging_mixin.py:109} INFO - [2022-04-07 22:02:40,103] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:02:40,246] {logging_mixin.py:109} INFO - [2022-04-07 22:02:40,245] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:02:40,259] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.038 seconds
[2022-04-07 22:03:10,337] {processor.py:163} INFO - Started process (PID=292) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:03:10,340] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:03:10,341] {logging_mixin.py:109} INFO - [2022-04-07 22:03:10,341] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:03:11,179] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:03:11,203] {logging_mixin.py:109} INFO - [2022-04-07 22:03:11,203] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:03:11,327] {logging_mixin.py:109} INFO - [2022-04-07 22:03:11,327] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:03:11,337] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.003 seconds
[2022-04-07 22:03:41,466] {processor.py:163} INFO - Started process (PID=332) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:03:41,470] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:03:41,471] {logging_mixin.py:109} INFO - [2022-04-07 22:03:41,471] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:03:42,359] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:03:42,491] {logging_mixin.py:109} INFO - [2022-04-07 22:03:42,490] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:03:42,510] {logging_mixin.py:109} INFO - [2022-04-07 22:03:42,510] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:03:42,521] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.059 seconds
[2022-04-07 22:04:12,577] {processor.py:163} INFO - Started process (PID=362) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:04:12,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:04:12,580] {logging_mixin.py:109} INFO - [2022-04-07 22:04:12,580] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:04:13,446] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:04:13,574] {logging_mixin.py:109} INFO - [2022-04-07 22:04:13,574] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:04:13,594] {logging_mixin.py:109} INFO - [2022-04-07 22:04:13,594] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:04:13,604] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.032 seconds
[2022-04-07 22:04:43,726] {processor.py:163} INFO - Started process (PID=400) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:04:43,729] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:04:43,730] {logging_mixin.py:109} INFO - [2022-04-07 22:04:43,729] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:04:44,566] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:04:44,694] {logging_mixin.py:109} INFO - [2022-04-07 22:04:44,693] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:04:44,712] {logging_mixin.py:109} INFO - [2022-04-07 22:04:44,711] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:04:44,721] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.000 seconds
[2022-04-07 22:05:14,843] {processor.py:163} INFO - Started process (PID=427) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:05:14,844] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:05:14,845] {logging_mixin.py:109} INFO - [2022-04-07 22:05:14,845] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:05:15,799] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:05:15,821] {logging_mixin.py:109} INFO - [2022-04-07 22:05:15,821] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:05:15,841] {logging_mixin.py:109} INFO - [2022-04-07 22:05:15,841] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:05:15,850] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.012 seconds
[2022-04-07 22:05:45,981] {processor.py:163} INFO - Started process (PID=463) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:05:45,984] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:05:45,985] {logging_mixin.py:109} INFO - [2022-04-07 22:05:45,984] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:05:46,958] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:05:46,982] {logging_mixin.py:109} INFO - [2022-04-07 22:05:46,982] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:05:47,004] {logging_mixin.py:109} INFO - [2022-04-07 22:05:47,004] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-07-01T00:00:00+00:00
[2022-04-07 22:05:47,018] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.042 seconds
[2022-04-07 22:06:17,105] {processor.py:163} INFO - Started process (PID=490) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:06:17,110] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:06:17,111] {logging_mixin.py:109} INFO - [2022-04-07 22:06:17,111] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:06:18,106] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:06:18,174] {logging_mixin.py:109} INFO - [2022-04-07 22:06:18,166] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:06:18,220] {logging_mixin.py:109} INFO - [2022-04-07 22:06:18,220] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2008-09-01T00:00:00+00:00
[2022-04-07 22:06:18,238] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.137 seconds
[2022-04-07 22:06:48,559] {processor.py:163} INFO - Started process (PID=729) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:06:48,561] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:06:48,562] {logging_mixin.py:109} INFO - [2022-04-07 22:06:48,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:06:54,965] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:06:55,028] {logging_mixin.py:109} INFO - [2022-04-07 22:06:55,028] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:06:55,173] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.620 seconds
[2022-04-07 22:07:25,455] {processor.py:163} INFO - Started process (PID=994) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:07:25,480] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:07:25,494] {logging_mixin.py:109} INFO - [2022-04-07 22:07:25,493] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:07:32,734] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:07:32,837] {logging_mixin.py:109} INFO - [2022-04-07 22:07:32,836] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:07:32,976] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 7.544 seconds
[2022-04-07 22:08:03,244] {processor.py:163} INFO - Started process (PID=1306) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:08:03,246] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:08:03,247] {logging_mixin.py:109} INFO - [2022-04-07 22:08:03,247] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:08:10,384] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:08:10,672] {logging_mixin.py:109} INFO - [2022-04-07 22:08:10,672] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:08:11,036] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 7.827 seconds
[2022-04-07 22:08:41,482] {processor.py:163} INFO - Started process (PID=1544) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:08:41,484] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:08:41,484] {logging_mixin.py:109} INFO - [2022-04-07 22:08:41,484] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:08:42,500] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:08:42,521] {logging_mixin.py:109} INFO - [2022-04-07 22:08:42,521] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:08:42,540] {logging_mixin.py:109} INFO - [2022-04-07 22:08:42,540] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2010-02-01T00:00:00+00:00
[2022-04-07 22:08:42,550] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.073 seconds
[2022-04-07 22:09:12,800] {processor.py:163} INFO - Started process (PID=1787) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:09:12,803] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:09:12,804] {logging_mixin.py:109} INFO - [2022-04-07 22:09:12,804] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:09:15,930] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:09:15,995] {logging_mixin.py:109} INFO - [2022-04-07 22:09:15,995] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:09:16,025] {logging_mixin.py:109} INFO - [2022-04-07 22:09:16,025] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2010-09-01T00:00:00+00:00
[2022-04-07 22:09:16,048] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.253 seconds
[2022-04-07 22:09:46,276] {processor.py:163} INFO - Started process (PID=2055) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:09:46,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:09:46,288] {logging_mixin.py:109} INFO - [2022-04-07 22:09:46,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:09:51,588] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:09:51,665] {logging_mixin.py:109} INFO - [2022-04-07 22:09:51,664] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:09:51,716] {logging_mixin.py:109} INFO - [2022-04-07 22:09:51,716] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2011-02-01T00:00:00+00:00
[2022-04-07 22:09:51,741] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.473 seconds
[2022-04-07 22:10:22,090] {processor.py:163} INFO - Started process (PID=2352) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:10:22,114] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:10:22,128] {logging_mixin.py:109} INFO - [2022-04-07 22:10:22,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:10:31,002] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:10:31,173] {logging_mixin.py:109} INFO - [2022-04-07 22:10:31,172] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:10:31,328] {logging_mixin.py:109} INFO - [2022-04-07 22:10:31,307] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2011-07-01T00:00:00+00:00
[2022-04-07 22:10:31,371] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 9.316 seconds
[2022-04-07 22:11:01,647] {processor.py:163} INFO - Started process (PID=2692) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:11:01,665] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:11:01,666] {logging_mixin.py:109} INFO - [2022-04-07 22:11:01,666] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:11:06,400] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:11:06,462] {logging_mixin.py:109} INFO - [2022-04-07 22:11:06,462] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:11:06,556] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.916 seconds
[2022-04-07 22:11:36,894] {processor.py:163} INFO - Started process (PID=2974) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:11:36,905] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:11:36,906] {logging_mixin.py:109} INFO - [2022-04-07 22:11:36,906] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:11:43,163] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:11:43,290] {logging_mixin.py:109} INFO - [2022-04-07 22:11:43,289] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:11:43,438] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.550 seconds
[2022-04-07 22:12:13,738] {processor.py:163} INFO - Started process (PID=3311) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:12:13,753] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:12:13,755] {logging_mixin.py:109} INFO - [2022-04-07 22:12:13,754] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:12:21,095] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:12:21,147] {logging_mixin.py:109} INFO - [2022-04-07 22:12:21,147] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:12:21,218] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 7.490 seconds
[2022-04-07 22:12:51,459] {processor.py:163} INFO - Started process (PID=3607) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:12:51,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:12:51,463] {logging_mixin.py:109} INFO - [2022-04-07 22:12:51,463] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:12:52,561] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:12:52,591] {logging_mixin.py:109} INFO - [2022-04-07 22:12:52,590] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:12:52,625] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.173 seconds
[2022-04-07 22:13:22,730] {processor.py:163} INFO - Started process (PID=3829) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:13:22,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:13:22,733] {logging_mixin.py:109} INFO - [2022-04-07 22:13:22,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:13:24,393] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:13:24,473] {logging_mixin.py:109} INFO - [2022-04-07 22:13:24,472] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:13:24,539] {logging_mixin.py:109} INFO - [2022-04-07 22:13:24,538] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2013-12-01T00:00:00+00:00
[2022-04-07 22:13:24,579] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.853 seconds
[2022-04-07 22:13:54,890] {processor.py:163} INFO - Started process (PID=4126) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:13:54,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:13:54,905] {logging_mixin.py:109} INFO - [2022-04-07 22:13:54,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:14:01,675] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:14:01,716] {logging_mixin.py:109} INFO - [2022-04-07 22:14:01,716] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:14:01,767] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.882 seconds
[2022-04-07 22:14:32,084] {processor.py:163} INFO - Started process (PID=4453) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:14:32,101] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:14:32,102] {logging_mixin.py:109} INFO - [2022-04-07 22:14:32,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:14:35,454] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:14:35,478] {logging_mixin.py:109} INFO - [2022-04-07 22:14:35,477] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:14:35,504] {logging_mixin.py:109} INFO - [2022-04-07 22:14:35,504] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2014-09-01T00:00:00+00:00
[2022-04-07 22:14:35,517] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.444 seconds
[2022-04-07 22:15:05,695] {processor.py:163} INFO - Started process (PID=4742) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:15:05,700] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:15:05,701] {logging_mixin.py:109} INFO - [2022-04-07 22:15:05,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:15:11,359] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:15:11,449] {logging_mixin.py:109} INFO - [2022-04-07 22:15:11,448] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:15:11,639] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.967 seconds
[2022-04-07 22:15:41,991] {processor.py:163} INFO - Started process (PID=5058) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:15:42,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:15:42,015] {logging_mixin.py:109} INFO - [2022-04-07 22:15:42,014] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:15:48,254] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:15:48,357] {logging_mixin.py:109} INFO - [2022-04-07 22:15:48,357] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:15:48,479] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.494 seconds
[2022-04-07 22:16:18,621] {processor.py:163} INFO - Started process (PID=5331) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:16:18,624] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:16:18,625] {logging_mixin.py:109} INFO - [2022-04-07 22:16:18,625] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:16:20,039] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:16:20,075] {logging_mixin.py:109} INFO - [2022-04-07 22:16:20,075] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:16:20,116] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.502 seconds
[2022-04-07 22:16:50,457] {processor.py:163} INFO - Started process (PID=5616) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:16:50,460] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:16:50,461] {logging_mixin.py:109} INFO - [2022-04-07 22:16:50,460] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:16:53,371] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:16:53,467] {logging_mixin.py:109} INFO - [2022-04-07 22:16:53,466] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:16:53,604] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.155 seconds
[2022-04-07 22:17:23,843] {processor.py:163} INFO - Started process (PID=5870) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:17:23,858] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:17:23,860] {logging_mixin.py:109} INFO - [2022-04-07 22:17:23,859] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:17:28,241] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:17:28,372] {logging_mixin.py:109} INFO - [2022-04-07 22:17:28,372] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:17:28,512] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.679 seconds
[2022-04-07 22:17:59,002] {processor.py:163} INFO - Started process (PID=6166) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:17:59,004] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:17:59,006] {logging_mixin.py:109} INFO - [2022-04-07 22:17:59,005] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:18:01,975] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:18:02,059] {logging_mixin.py:109} INFO - [2022-04-07 22:18:02,058] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:18:02,166] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.170 seconds
[2022-04-07 22:18:32,464] {processor.py:163} INFO - Started process (PID=6471) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:18:32,470] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:18:32,471] {logging_mixin.py:109} INFO - [2022-04-07 22:18:32,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:18:36,366] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:18:36,433] {logging_mixin.py:109} INFO - [2022-04-07 22:18:36,432] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:18:36,515] {logging_mixin.py:109} INFO - [2022-04-07 22:18:36,514] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2017-12-01T00:00:00+00:00
[2022-04-07 22:18:36,555] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.114 seconds
[2022-04-07 22:19:06,822] {processor.py:163} INFO - Started process (PID=6801) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:19:06,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:19:06,843] {logging_mixin.py:109} INFO - [2022-04-07 22:19:06,842] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:19:10,717] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:19:10,768] {logging_mixin.py:109} INFO - [2022-04-07 22:19:10,767] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:19:10,796] {logging_mixin.py:109} INFO - [2022-04-07 22:19:10,796] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2018-06-01T00:00:00+00:00
[2022-04-07 22:19:10,817] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.001 seconds
[2022-04-07 22:19:41,053] {processor.py:163} INFO - Started process (PID=7088) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:19:41,060] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:19:41,061] {logging_mixin.py:109} INFO - [2022-04-07 22:19:41,061] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:19:44,893] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:19:45,033] {logging_mixin.py:109} INFO - [2022-04-07 22:19:45,032] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:19:45,246] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.213 seconds
[2022-04-07 22:20:15,574] {processor.py:163} INFO - Started process (PID=7414) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:20:15,589] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:20:15,591] {logging_mixin.py:109} INFO - [2022-04-07 22:20:15,590] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:20:21,344] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:20:21,458] {logging_mixin.py:109} INFO - [2022-04-07 22:20:21,450] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:20:21,615] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.080 seconds
[2022-04-07 22:20:51,848] {processor.py:163} INFO - Started process (PID=7721) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:20:51,855] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:20:51,856] {logging_mixin.py:109} INFO - [2022-04-07 22:20:51,856] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:20:54,671] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:20:54,717] {logging_mixin.py:109} INFO - [2022-04-07 22:20:54,717] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:20:54,772] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 2.930 seconds
[2022-04-07 22:21:25,341] {processor.py:163} INFO - Started process (PID=8034) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:21:25,396] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:21:25,398] {logging_mixin.py:109} INFO - [2022-04-07 22:21:25,397] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:21:31,274] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:21:31,340] {logging_mixin.py:109} INFO - [2022-04-07 22:21:31,339] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:21:31,382] {logging_mixin.py:109} INFO - [2022-04-07 22:21:31,382] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2020-06-01T00:00:00+00:00
[2022-04-07 22:21:31,412] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 6.137 seconds
[2022-04-07 22:22:01,583] {processor.py:163} INFO - Started process (PID=8347) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:22:01,597] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:22:01,599] {logging_mixin.py:109} INFO - [2022-04-07 22:22:01,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:22:05,606] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:22:05,697] {logging_mixin.py:109} INFO - [2022-04-07 22:22:05,696] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:22:05,760] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 4.192 seconds
[2022-04-07 22:22:35,965] {processor.py:163} INFO - Started process (PID=8648) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:22:35,971] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:22:35,976] {logging_mixin.py:109} INFO - [2022-04-07 22:22:35,976] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:22:41,152] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:22:41,206] {logging_mixin.py:109} INFO - [2022-04-07 22:22:41,206] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:22:41,235] {logging_mixin.py:109} INFO - [2022-04-07 22:22:41,235] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2021-06-01T00:00:00+00:00
[2022-04-07 22:22:41,248] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.290 seconds
[2022-04-07 22:23:11,521] {processor.py:163} INFO - Started process (PID=8980) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:23:11,537] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:23:11,538] {logging_mixin.py:109} INFO - [2022-04-07 22:23:11,538] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:23:16,989] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:23:17,058] {logging_mixin.py:109} INFO - [2022-04-07 22:23:17,057] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:23:17,148] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 5.658 seconds
[2022-04-07 22:23:47,438] {processor.py:163} INFO - Started process (PID=9262) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:23:47,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:23:47,444] {logging_mixin.py:109} INFO - [2022-04-07 22:23:47,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:23:51,133] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:23:51,227] {logging_mixin.py:109} INFO - [2022-04-07 22:23:51,227] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:23:51,301] {logging_mixin.py:109} INFO - [2022-04-07 22:23:51,301] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:23:51,354] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 3.921 seconds
[2022-04-07 22:24:21,487] {processor.py:163} INFO - Started process (PID=9314) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:24:21,489] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:24:21,490] {logging_mixin.py:109} INFO - [2022-04-07 22:24:21,489] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:24:22,497] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:24:22,519] {logging_mixin.py:109} INFO - [2022-04-07 22:24:22,519] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:24:22,539] {logging_mixin.py:109} INFO - [2022-04-07 22:24:22,538] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:24:22,548] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.066 seconds
[2022-04-07 22:24:52,603] {processor.py:163} INFO - Started process (PID=9343) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:24:52,605] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:24:52,606] {logging_mixin.py:109} INFO - [2022-04-07 22:24:52,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:24:53,620] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:24:53,650] {logging_mixin.py:109} INFO - [2022-04-07 22:24:53,649] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:24:53,679] {logging_mixin.py:109} INFO - [2022-04-07 22:24:53,679] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:24:53,690] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.093 seconds
[2022-04-07 22:25:23,760] {processor.py:163} INFO - Started process (PID=9380) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:25:23,762] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:25:23,763] {logging_mixin.py:109} INFO - [2022-04-07 22:25:23,763] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:25:24,770] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:25:24,792] {logging_mixin.py:109} INFO - [2022-04-07 22:25:24,792] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:25:24,812] {logging_mixin.py:109} INFO - [2022-04-07 22:25:24,812] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:25:24,821] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.067 seconds
[2022-04-07 22:25:54,906] {processor.py:163} INFO - Started process (PID=9409) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:25:54,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:25:54,909] {logging_mixin.py:109} INFO - [2022-04-07 22:25:54,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:25:55,976] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:25:56,006] {logging_mixin.py:109} INFO - [2022-04-07 22:25:56,006] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:25:56,030] {logging_mixin.py:109} INFO - [2022-04-07 22:25:56,030] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:25:56,041] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.140 seconds
[2022-04-07 22:26:26,149] {processor.py:163} INFO - Started process (PID=9447) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:26:26,153] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:26:26,153] {logging_mixin.py:109} INFO - [2022-04-07 22:26:26,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:26:27,129] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:26:27,154] {logging_mixin.py:109} INFO - [2022-04-07 22:26:27,153] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:26:27,178] {logging_mixin.py:109} INFO - [2022-04-07 22:26:27,178] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:26:27,189] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.045 seconds
[2022-04-07 22:26:57,281] {processor.py:163} INFO - Started process (PID=9475) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:26:57,283] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:26:57,284] {logging_mixin.py:109} INFO - [2022-04-07 22:26:57,284] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:26:58,298] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:26:58,322] {logging_mixin.py:109} INFO - [2022-04-07 22:26:58,322] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:26:58,345] {logging_mixin.py:109} INFO - [2022-04-07 22:26:58,345] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:26:58,355] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.080 seconds
[2022-04-07 22:27:28,402] {processor.py:163} INFO - Started process (PID=9514) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:27:28,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:27:28,407] {logging_mixin.py:109} INFO - [2022-04-07 22:27:28,406] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:27:29,454] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:27:29,480] {logging_mixin.py:109} INFO - [2022-04-07 22:27:29,479] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:27:29,502] {logging_mixin.py:109} INFO - [2022-04-07 22:27:29,502] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:27:29,514] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.118 seconds
[2022-04-07 22:27:59,566] {processor.py:163} INFO - Started process (PID=9552) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:27:59,568] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:27:59,569] {logging_mixin.py:109} INFO - [2022-04-07 22:27:59,569] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:28:00,599] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:28:00,622] {logging_mixin.py:109} INFO - [2022-04-07 22:28:00,621] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:28:00,642] {logging_mixin.py:109} INFO - [2022-04-07 22:28:00,642] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:28:00,654] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.093 seconds
[2022-04-07 22:28:30,712] {processor.py:163} INFO - Started process (PID=9581) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:28:30,715] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:28:30,716] {logging_mixin.py:109} INFO - [2022-04-07 22:28:30,715] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:28:31,678] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:28:31,701] {logging_mixin.py:109} INFO - [2022-04-07 22:28:31,701] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:28:31,722] {logging_mixin.py:109} INFO - [2022-04-07 22:28:31,721] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:28:31,734] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.027 seconds
[2022-04-07 22:29:01,860] {processor.py:163} INFO - Started process (PID=9618) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:29:01,863] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:29:01,864] {logging_mixin.py:109} INFO - [2022-04-07 22:29:01,863] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:29:02,925] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:29:02,947] {logging_mixin.py:109} INFO - [2022-04-07 22:29:02,947] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:29:02,965] {logging_mixin.py:109} INFO - [2022-04-07 22:29:02,965] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:29:02,974] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.119 seconds
[2022-04-07 22:29:33,072] {processor.py:163} INFO - Started process (PID=9647) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:29:33,075] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:29:33,076] {logging_mixin.py:109} INFO - [2022-04-07 22:29:33,076] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:29:34,034] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:29:34,057] {logging_mixin.py:109} INFO - [2022-04-07 22:29:34,057] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:29:34,078] {logging_mixin.py:109} INFO - [2022-04-07 22:29:34,077] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:29:34,088] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.021 seconds
[2022-04-07 22:30:04,197] {processor.py:163} INFO - Started process (PID=9685) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:30:04,199] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:30:04,200] {logging_mixin.py:109} INFO - [2022-04-07 22:30:04,200] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:30:05,261] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:30:05,285] {logging_mixin.py:109} INFO - [2022-04-07 22:30:05,284] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:30:05,305] {logging_mixin.py:109} INFO - [2022-04-07 22:30:05,305] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:30:05,318] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.125 seconds
[2022-04-07 22:30:35,419] {processor.py:163} INFO - Started process (PID=9715) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:30:35,421] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:30:35,421] {logging_mixin.py:109} INFO - [2022-04-07 22:30:35,421] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:30:36,361] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:30:36,385] {logging_mixin.py:109} INFO - [2022-04-07 22:30:36,385] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:30:36,405] {logging_mixin.py:109} INFO - [2022-04-07 22:30:36,405] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:30:36,415] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.001 seconds
[2022-04-07 22:31:06,547] {processor.py:163} INFO - Started process (PID=9754) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:31:06,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:31:06,551] {logging_mixin.py:109} INFO - [2022-04-07 22:31:06,551] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:31:07,611] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:31:07,634] {logging_mixin.py:109} INFO - [2022-04-07 22:31:07,633] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:31:07,656] {logging_mixin.py:109} INFO - [2022-04-07 22:31:07,656] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:31:07,672] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.129 seconds
[2022-04-07 22:31:37,787] {processor.py:163} INFO - Started process (PID=9782) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:31:37,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:31:37,790] {logging_mixin.py:109} INFO - [2022-04-07 22:31:37,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:31:38,787] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:31:38,811] {logging_mixin.py:109} INFO - [2022-04-07 22:31:38,811] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:31:38,832] {logging_mixin.py:109} INFO - [2022-04-07 22:31:38,832] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:31:38,843] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.062 seconds
[2022-04-07 22:32:08,906] {processor.py:163} INFO - Started process (PID=9821) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:32:08,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:32:08,909] {logging_mixin.py:109} INFO - [2022-04-07 22:32:08,909] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:32:10,010] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:32:10,036] {logging_mixin.py:109} INFO - [2022-04-07 22:32:10,036] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:32:10,058] {logging_mixin.py:109} INFO - [2022-04-07 22:32:10,058] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:32:10,069] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.169 seconds
[2022-04-07 22:32:40,173] {processor.py:163} INFO - Started process (PID=9849) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:32:40,175] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:32:40,176] {logging_mixin.py:109} INFO - [2022-04-07 22:32:40,175] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:32:41,166] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:32:41,190] {logging_mixin.py:109} INFO - [2022-04-07 22:32:41,190] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:32:41,212] {logging_mixin.py:109} INFO - [2022-04-07 22:32:41,212] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:32:41,221] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.054 seconds
[2022-04-07 22:33:11,288] {processor.py:163} INFO - Started process (PID=9888) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:33:11,291] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:33:11,292] {logging_mixin.py:109} INFO - [2022-04-07 22:33:11,292] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:33:12,279] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:33:12,312] {logging_mixin.py:109} INFO - [2022-04-07 22:33:12,311] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:33:12,339] {logging_mixin.py:109} INFO - [2022-04-07 22:33:12,339] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:33:12,349] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.067 seconds
[2022-04-07 22:33:42,466] {processor.py:163} INFO - Started process (PID=9916) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:33:42,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:33:42,470] {logging_mixin.py:109} INFO - [2022-04-07 22:33:42,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:33:43,537] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:33:43,559] {logging_mixin.py:109} INFO - [2022-04-07 22:33:43,559] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:33:43,580] {logging_mixin.py:109} INFO - [2022-04-07 22:33:43,579] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:33:43,589] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.134 seconds
[2022-04-07 22:34:13,686] {processor.py:163} INFO - Started process (PID=9945) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:34:13,688] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:34:13,689] {logging_mixin.py:109} INFO - [2022-04-07 22:34:13,689] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:34:14,682] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:34:14,704] {logging_mixin.py:109} INFO - [2022-04-07 22:34:14,704] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:34:14,725] {logging_mixin.py:109} INFO - [2022-04-07 22:34:14,725] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:34:14,735] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.054 seconds
[2022-04-07 22:34:44,815] {processor.py:163} INFO - Started process (PID=9983) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:34:44,818] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:34:44,819] {logging_mixin.py:109} INFO - [2022-04-07 22:34:44,819] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:34:45,911] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:34:45,942] {logging_mixin.py:109} INFO - [2022-04-07 22:34:45,941] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:34:45,961] {logging_mixin.py:109} INFO - [2022-04-07 22:34:45,960] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:34:45,970] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.164 seconds
[2022-04-07 22:35:16,064] {processor.py:163} INFO - Started process (PID=10012) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:35:16,066] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:35:16,067] {logging_mixin.py:109} INFO - [2022-04-07 22:35:16,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:35:17,088] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:35:17,117] {logging_mixin.py:109} INFO - [2022-04-07 22:35:17,116] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:35:17,139] {logging_mixin.py:109} INFO - [2022-04-07 22:35:17,139] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:35:17,153] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.094 seconds
[2022-04-07 22:35:47,250] {processor.py:163} INFO - Started process (PID=10050) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:35:47,254] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:35:47,255] {logging_mixin.py:109} INFO - [2022-04-07 22:35:47,255] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:35:48,424] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:35:48,449] {logging_mixin.py:109} INFO - [2022-04-07 22:35:48,448] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:35:48,470] {logging_mixin.py:109} INFO - [2022-04-07 22:35:48,470] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:35:48,481] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.236 seconds
[2022-04-07 22:36:18,589] {processor.py:163} INFO - Started process (PID=10077) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:36:18,590] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:36:18,591] {logging_mixin.py:109} INFO - [2022-04-07 22:36:18,591] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:36:19,624] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:36:19,648] {logging_mixin.py:109} INFO - [2022-04-07 22:36:19,648] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:36:19,669] {logging_mixin.py:109} INFO - [2022-04-07 22:36:19,669] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:36:19,680] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.097 seconds
[2022-04-07 22:36:49,779] {processor.py:163} INFO - Started process (PID=10114) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:36:49,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:36:49,784] {logging_mixin.py:109} INFO - [2022-04-07 22:36:49,784] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:36:50,878] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:36:50,901] {logging_mixin.py:109} INFO - [2022-04-07 22:36:50,901] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:36:50,921] {logging_mixin.py:109} INFO - [2022-04-07 22:36:50,921] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:36:50,931] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.157 seconds
[2022-04-07 22:37:21,026] {processor.py:163} INFO - Started process (PID=10144) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:37:21,029] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:37:21,030] {logging_mixin.py:109} INFO - [2022-04-07 22:37:21,030] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:37:22,011] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:37:22,034] {logging_mixin.py:109} INFO - [2022-04-07 22:37:22,034] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:37:22,059] {logging_mixin.py:109} INFO - [2022-04-07 22:37:22,059] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:37:22,071] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.050 seconds
[2022-04-07 22:37:52,163] {processor.py:163} INFO - Started process (PID=10182) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:37:52,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:37:52,171] {logging_mixin.py:109} INFO - [2022-04-07 22:37:52,171] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:37:53,301] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:37:53,326] {logging_mixin.py:109} INFO - [2022-04-07 22:37:53,325] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:37:53,347] {logging_mixin.py:109} INFO - [2022-04-07 22:37:53,347] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:37:53,360] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.204 seconds
[2022-04-07 22:38:23,460] {processor.py:163} INFO - Started process (PID=10211) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:38:23,464] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:38:23,465] {logging_mixin.py:109} INFO - [2022-04-07 22:38:23,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:38:24,419] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:38:24,443] {logging_mixin.py:109} INFO - [2022-04-07 22:38:24,443] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:38:24,464] {logging_mixin.py:109} INFO - [2022-04-07 22:38:24,464] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:38:24,474] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.019 seconds
[2022-04-07 22:38:54,593] {processor.py:163} INFO - Started process (PID=10248) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:38:54,596] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:38:54,597] {logging_mixin.py:109} INFO - [2022-04-07 22:38:54,596] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:38:55,636] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:38:55,660] {logging_mixin.py:109} INFO - [2022-04-07 22:38:55,659] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:38:55,680] {logging_mixin.py:109} INFO - [2022-04-07 22:38:55,680] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:38:55,690] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.101 seconds
[2022-04-07 22:39:25,792] {processor.py:163} INFO - Started process (PID=10276) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:39:25,794] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:39:25,795] {logging_mixin.py:109} INFO - [2022-04-07 22:39:25,795] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:39:26,789] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:39:26,812] {logging_mixin.py:109} INFO - [2022-04-07 22:39:26,812] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:39:26,833] {logging_mixin.py:109} INFO - [2022-04-07 22:39:26,833] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:39:26,843] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.056 seconds
[2022-04-07 22:39:56,919] {processor.py:163} INFO - Started process (PID=10313) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:39:56,920] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:39:56,921] {logging_mixin.py:109} INFO - [2022-04-07 22:39:56,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:39:58,032] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:39:58,060] {logging_mixin.py:109} INFO - [2022-04-07 22:39:58,060] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:39:58,082] {logging_mixin.py:109} INFO - [2022-04-07 22:39:58,082] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:39:58,093] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.181 seconds
[2022-04-07 22:40:28,198] {processor.py:163} INFO - Started process (PID=10342) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:40:28,200] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:40:28,201] {logging_mixin.py:109} INFO - [2022-04-07 22:40:28,201] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:40:29,216] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:40:29,239] {logging_mixin.py:109} INFO - [2022-04-07 22:40:29,238] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:40:29,258] {logging_mixin.py:109} INFO - [2022-04-07 22:40:29,258] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:40:29,268] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.075 seconds
[2022-04-07 22:40:59,368] {processor.py:163} INFO - Started process (PID=10380) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:40:59,370] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:40:59,371] {logging_mixin.py:109} INFO - [2022-04-07 22:40:59,371] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:41:00,399] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:41:00,438] {logging_mixin.py:109} INFO - [2022-04-07 22:41:00,437] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:41:00,467] {logging_mixin.py:109} INFO - [2022-04-07 22:41:00,466] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:41:00,483] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.122 seconds
[2022-04-07 22:41:30,588] {processor.py:163} INFO - Started process (PID=10410) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:41:30,591] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:41:30,592] {logging_mixin.py:109} INFO - [2022-04-07 22:41:30,592] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:41:31,571] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:41:31,595] {logging_mixin.py:109} INFO - [2022-04-07 22:41:31,595] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:41:31,615] {logging_mixin.py:109} INFO - [2022-04-07 22:41:31,615] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:41:31,628] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.045 seconds
[2022-04-07 22:42:01,722] {processor.py:163} INFO - Started process (PID=10446) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:42:01,724] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:42:01,725] {logging_mixin.py:109} INFO - [2022-04-07 22:42:01,725] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:42:02,755] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:42:02,777] {logging_mixin.py:109} INFO - [2022-04-07 22:42:02,777] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:42:02,799] {logging_mixin.py:109} INFO - [2022-04-07 22:42:02,798] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:42:02,809] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.094 seconds
[2022-04-07 22:42:32,916] {processor.py:163} INFO - Started process (PID=10473) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:42:32,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:42:32,919] {logging_mixin.py:109} INFO - [2022-04-07 22:42:32,919] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:42:33,884] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:42:33,910] {logging_mixin.py:109} INFO - [2022-04-07 22:42:33,910] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:42:33,930] {logging_mixin.py:109} INFO - [2022-04-07 22:42:33,930] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:42:33,941] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.030 seconds
[2022-04-07 22:43:04,038] {processor.py:163} INFO - Started process (PID=10511) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:43:04,039] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:43:04,040] {logging_mixin.py:109} INFO - [2022-04-07 22:43:04,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:43:05,062] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:43:05,096] {logging_mixin.py:109} INFO - [2022-04-07 22:43:05,096] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:43:05,128] {logging_mixin.py:109} INFO - [2022-04-07 22:43:05,128] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:43:05,140] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.107 seconds
[2022-04-07 22:43:35,238] {processor.py:163} INFO - Started process (PID=10540) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:43:35,241] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:43:35,242] {logging_mixin.py:109} INFO - [2022-04-07 22:43:35,242] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:43:36,160] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:43:36,183] {logging_mixin.py:109} INFO - [2022-04-07 22:43:36,182] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:43:36,204] {logging_mixin.py:109} INFO - [2022-04-07 22:43:36,204] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:43:36,214] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.981 seconds
[2022-04-07 22:44:06,369] {processor.py:163} INFO - Started process (PID=10578) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:44:06,370] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:44:06,371] {logging_mixin.py:109} INFO - [2022-04-07 22:44:06,371] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:44:07,359] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:44:07,383] {logging_mixin.py:109} INFO - [2022-04-07 22:44:07,382] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:44:07,403] {logging_mixin.py:109} INFO - [2022-04-07 22:44:07,403] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:44:07,416] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.052 seconds
[2022-04-07 22:44:37,487] {processor.py:163} INFO - Started process (PID=10607) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:44:37,489] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:44:37,490] {logging_mixin.py:109} INFO - [2022-04-07 22:44:37,490] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:44:38,443] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:44:38,467] {logging_mixin.py:109} INFO - [2022-04-07 22:44:38,466] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:44:38,489] {logging_mixin.py:109} INFO - [2022-04-07 22:44:38,489] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:44:38,499] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.017 seconds
[2022-04-07 22:45:08,629] {processor.py:163} INFO - Started process (PID=10645) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:45:08,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:45:08,631] {logging_mixin.py:109} INFO - [2022-04-07 22:45:08,631] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:45:09,674] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:45:09,698] {logging_mixin.py:109} INFO - [2022-04-07 22:45:09,697] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:45:09,718] {logging_mixin.py:109} INFO - [2022-04-07 22:45:09,718] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:45:09,730] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.106 seconds
[2022-04-07 22:45:39,826] {processor.py:163} INFO - Started process (PID=10672) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:45:39,828] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:45:39,829] {logging_mixin.py:109} INFO - [2022-04-07 22:45:39,829] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:45:40,843] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:45:40,867] {logging_mixin.py:109} INFO - [2022-04-07 22:45:40,866] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:45:40,895] {logging_mixin.py:109} INFO - [2022-04-07 22:45:40,894] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:45:40,907] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.086 seconds
[2022-04-07 22:46:11,023] {processor.py:163} INFO - Started process (PID=10711) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:46:11,024] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:46:11,025] {logging_mixin.py:109} INFO - [2022-04-07 22:46:11,025] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:46:12,080] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:46:12,103] {logging_mixin.py:109} INFO - [2022-04-07 22:46:12,103] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:46:12,123] {logging_mixin.py:109} INFO - [2022-04-07 22:46:12,123] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:46:12,134] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.117 seconds
[2022-04-07 22:46:42,233] {processor.py:163} INFO - Started process (PID=10740) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:46:42,236] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:46:42,236] {logging_mixin.py:109} INFO - [2022-04-07 22:46:42,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:46:43,165] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:46:43,187] {logging_mixin.py:109} INFO - [2022-04-07 22:46:43,187] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:46:43,207] {logging_mixin.py:109} INFO - [2022-04-07 22:46:43,207] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:46:43,218] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.990 seconds
[2022-04-07 22:47:13,363] {processor.py:163} INFO - Started process (PID=10779) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:47:13,365] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:47:13,366] {logging_mixin.py:109} INFO - [2022-04-07 22:47:13,366] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:47:14,374] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:47:14,396] {logging_mixin.py:109} INFO - [2022-04-07 22:47:14,395] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:47:14,417] {logging_mixin.py:109} INFO - [2022-04-07 22:47:14,417] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:47:14,427] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.070 seconds
[2022-04-07 22:47:44,498] {processor.py:163} INFO - Started process (PID=10808) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:47:44,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:47:44,501] {logging_mixin.py:109} INFO - [2022-04-07 22:47:44,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:47:45,422] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:47:45,445] {logging_mixin.py:109} INFO - [2022-04-07 22:47:45,444] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:47:45,466] {logging_mixin.py:109} INFO - [2022-04-07 22:47:45,465] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:47:45,474] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.982 seconds
[2022-04-07 22:48:15,626] {processor.py:163} INFO - Started process (PID=10846) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:48:15,627] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:48:15,628] {logging_mixin.py:109} INFO - [2022-04-07 22:48:15,628] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:48:16,592] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:48:16,617] {logging_mixin.py:109} INFO - [2022-04-07 22:48:16,617] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:48:16,640] {logging_mixin.py:109} INFO - [2022-04-07 22:48:16,640] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:48:16,650] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.029 seconds
[2022-04-07 22:48:46,745] {processor.py:163} INFO - Started process (PID=10875) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:48:46,748] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:48:46,748] {logging_mixin.py:109} INFO - [2022-04-07 22:48:46,748] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:48:47,670] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:48:47,693] {logging_mixin.py:109} INFO - [2022-04-07 22:48:47,692] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:48:47,714] {logging_mixin.py:109} INFO - [2022-04-07 22:48:47,714] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:48:47,724] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.983 seconds
[2022-04-07 22:49:17,866] {processor.py:163} INFO - Started process (PID=10914) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:49:17,868] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:49:17,869] {logging_mixin.py:109} INFO - [2022-04-07 22:49:17,869] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:49:18,812] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:49:18,838] {logging_mixin.py:109} INFO - [2022-04-07 22:49:18,838] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:49:18,858] {logging_mixin.py:109} INFO - [2022-04-07 22:49:18,857] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:49:18,868] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.008 seconds
[2022-04-07 22:49:48,985] {processor.py:163} INFO - Started process (PID=10944) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:49:48,987] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:49:48,988] {logging_mixin.py:109} INFO - [2022-04-07 22:49:48,988] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:49:49,952] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:49:49,997] {logging_mixin.py:109} INFO - [2022-04-07 22:49:49,996] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:49:50,019] {logging_mixin.py:109} INFO - [2022-04-07 22:49:50,019] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:49:50,030] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.050 seconds
[2022-04-07 22:50:20,107] {processor.py:163} INFO - Started process (PID=10982) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:50:20,109] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:50:20,110] {logging_mixin.py:109} INFO - [2022-04-07 22:50:20,110] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:50:21,035] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:50:21,065] {logging_mixin.py:109} INFO - [2022-04-07 22:50:21,064] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:50:21,085] {logging_mixin.py:109} INFO - [2022-04-07 22:50:21,085] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:50:21,095] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.994 seconds
[2022-04-07 22:50:51,233] {processor.py:163} INFO - Started process (PID=11011) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:50:51,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:50:51,236] {logging_mixin.py:109} INFO - [2022-04-07 22:50:51,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:50:52,203] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:50:52,228] {logging_mixin.py:109} INFO - [2022-04-07 22:50:52,228] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:50:52,247] {logging_mixin.py:109} INFO - [2022-04-07 22:50:52,247] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:50:52,258] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.030 seconds
[2022-04-07 22:51:22,366] {processor.py:163} INFO - Started process (PID=11051) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:51:22,368] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:51:22,369] {logging_mixin.py:109} INFO - [2022-04-07 22:51:22,368] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:51:23,318] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:51:23,341] {logging_mixin.py:109} INFO - [2022-04-07 22:51:23,341] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:51:23,363] {logging_mixin.py:109} INFO - [2022-04-07 22:51:23,363] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:51:23,373] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.011 seconds
[2022-04-07 22:51:53,511] {processor.py:163} INFO - Started process (PID=11081) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:51:53,514] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:51:53,515] {logging_mixin.py:109} INFO - [2022-04-07 22:51:53,514] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:51:54,508] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:51:54,530] {logging_mixin.py:109} INFO - [2022-04-07 22:51:54,530] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:51:54,550] {logging_mixin.py:109} INFO - [2022-04-07 22:51:54,550] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:51:54,561] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.055 seconds
[2022-04-07 22:52:24,636] {processor.py:163} INFO - Started process (PID=11119) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:52:24,637] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:52:24,638] {logging_mixin.py:109} INFO - [2022-04-07 22:52:24,638] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:52:25,610] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:52:25,641] {logging_mixin.py:109} INFO - [2022-04-07 22:52:25,640] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:52:25,665] {logging_mixin.py:109} INFO - [2022-04-07 22:52:25,665] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:52:25,675] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.045 seconds
[2022-04-07 22:52:55,775] {processor.py:163} INFO - Started process (PID=11148) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:52:55,777] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:52:55,778] {logging_mixin.py:109} INFO - [2022-04-07 22:52:55,778] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:52:56,836] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:52:56,860] {logging_mixin.py:109} INFO - [2022-04-07 22:52:56,859] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:52:56,880] {logging_mixin.py:109} INFO - [2022-04-07 22:52:56,880] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:52:56,891] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.121 seconds
[2022-04-07 22:53:26,992] {processor.py:163} INFO - Started process (PID=11187) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:53:26,994] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:53:26,995] {logging_mixin.py:109} INFO - [2022-04-07 22:53:26,995] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:53:28,001] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:53:28,029] {logging_mixin.py:109} INFO - [2022-04-07 22:53:28,029] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:53:28,053] {logging_mixin.py:109} INFO - [2022-04-07 22:53:28,053] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:53:28,062] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.076 seconds
[2022-04-07 22:53:58,170] {processor.py:163} INFO - Started process (PID=11215) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:53:58,172] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:53:58,174] {logging_mixin.py:109} INFO - [2022-04-07 22:53:58,173] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:53:59,372] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:53:59,398] {logging_mixin.py:109} INFO - [2022-04-07 22:53:59,398] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:53:59,420] {logging_mixin.py:109} INFO - [2022-04-07 22:53:59,419] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:53:59,433] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.269 seconds
[2022-04-07 22:54:29,540] {processor.py:163} INFO - Started process (PID=11252) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:54:29,542] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:54:29,543] {logging_mixin.py:109} INFO - [2022-04-07 22:54:29,543] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:54:30,508] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:54:30,532] {logging_mixin.py:109} INFO - [2022-04-07 22:54:30,532] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:54:30,553] {logging_mixin.py:109} INFO - [2022-04-07 22:54:30,553] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:54:30,563] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.029 seconds
[2022-04-07 22:55:00,661] {processor.py:163} INFO - Started process (PID=11280) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:55:00,663] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:55:00,664] {logging_mixin.py:109} INFO - [2022-04-07 22:55:00,664] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:55:01,619] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:55:01,643] {logging_mixin.py:109} INFO - [2022-04-07 22:55:01,643] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:55:01,666] {logging_mixin.py:109} INFO - [2022-04-07 22:55:01,666] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:55:01,677] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.021 seconds
[2022-04-07 22:55:31,788] {processor.py:163} INFO - Started process (PID=11318) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:55:31,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:55:31,790] {logging_mixin.py:109} INFO - [2022-04-07 22:55:31,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:55:32,739] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:55:32,761] {logging_mixin.py:109} INFO - [2022-04-07 22:55:32,761] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:55:32,781] {logging_mixin.py:109} INFO - [2022-04-07 22:55:32,780] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:55:32,790] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.007 seconds
[2022-04-07 22:56:02,906] {processor.py:163} INFO - Started process (PID=11345) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:56:02,909] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:56:02,909] {logging_mixin.py:109} INFO - [2022-04-07 22:56:02,909] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:56:03,875] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:56:03,898] {logging_mixin.py:109} INFO - [2022-04-07 22:56:03,898] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:56:03,917] {logging_mixin.py:109} INFO - [2022-04-07 22:56:03,917] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:56:03,928] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.026 seconds
[2022-04-07 22:56:34,036] {processor.py:163} INFO - Started process (PID=11381) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:56:34,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:56:34,039] {logging_mixin.py:109} INFO - [2022-04-07 22:56:34,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:56:34,967] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:56:34,990] {logging_mixin.py:109} INFO - [2022-04-07 22:56:34,989] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:56:35,009] {logging_mixin.py:109} INFO - [2022-04-07 22:56:35,009] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:56:35,019] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.987 seconds
[2022-04-07 22:57:05,169] {processor.py:163} INFO - Started process (PID=11410) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:57:05,171] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:57:05,172] {logging_mixin.py:109} INFO - [2022-04-07 22:57:05,172] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:57:06,114] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:57:06,136] {logging_mixin.py:109} INFO - [2022-04-07 22:57:06,135] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:57:06,155] {logging_mixin.py:109} INFO - [2022-04-07 22:57:06,154] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:57:06,164] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.000 seconds
[2022-04-07 22:57:36,301] {processor.py:163} INFO - Started process (PID=11449) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:57:36,304] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:57:36,305] {logging_mixin.py:109} INFO - [2022-04-07 22:57:36,304] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:57:37,245] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:57:37,268] {logging_mixin.py:109} INFO - [2022-04-07 22:57:37,267] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:57:37,287] {logging_mixin.py:109} INFO - [2022-04-07 22:57:37,287] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:57:37,297] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.001 seconds
[2022-04-07 22:58:07,437] {processor.py:163} INFO - Started process (PID=11484) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:58:07,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:58:07,439] {logging_mixin.py:109} INFO - [2022-04-07 22:58:07,439] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:58:08,411] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:58:08,436] {logging_mixin.py:109} INFO - [2022-04-07 22:58:08,435] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:58:08,456] {logging_mixin.py:109} INFO - [2022-04-07 22:58:08,456] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:58:08,466] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.034 seconds
[2022-04-07 22:58:38,555] {processor.py:163} INFO - Started process (PID=11516) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:58:38,558] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:58:38,559] {logging_mixin.py:109} INFO - [2022-04-07 22:58:38,559] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:58:39,485] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:58:39,512] {logging_mixin.py:109} INFO - [2022-04-07 22:58:39,511] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:58:39,534] {logging_mixin.py:109} INFO - [2022-04-07 22:58:39,534] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:58:39,547] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.996 seconds
[2022-04-07 22:59:09,677] {processor.py:163} INFO - Started process (PID=11544) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:59:09,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:59:09,679] {logging_mixin.py:109} INFO - [2022-04-07 22:59:09,679] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:59:10,647] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:59:10,672] {logging_mixin.py:109} INFO - [2022-04-07 22:59:10,671] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:59:10,690] {logging_mixin.py:109} INFO - [2022-04-07 22:59:10,690] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:59:10,700] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.030 seconds
[2022-04-07 22:59:40,795] {processor.py:163} INFO - Started process (PID=11582) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:59:40,797] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 22:59:40,798] {logging_mixin.py:109} INFO - [2022-04-07 22:59:40,798] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:59:41,730] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 22:59:41,752] {logging_mixin.py:109} INFO - [2022-04-07 22:59:41,752] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 22:59:41,771] {logging_mixin.py:109} INFO - [2022-04-07 22:59:41,771] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 22:59:41,780] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.990 seconds
[2022-04-07 23:00:11,915] {processor.py:163} INFO - Started process (PID=11610) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:00:11,917] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:00:11,918] {logging_mixin.py:109} INFO - [2022-04-07 23:00:11,918] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:00:12,926] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:00:12,948] {logging_mixin.py:109} INFO - [2022-04-07 23:00:12,948] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:00:12,967] {logging_mixin.py:109} INFO - [2022-04-07 23:00:12,967] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:00:12,977] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.066 seconds
[2022-04-07 23:00:43,031] {processor.py:163} INFO - Started process (PID=11649) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:00:43,033] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:00:43,034] {logging_mixin.py:109} INFO - [2022-04-07 23:00:43,034] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:00:43,953] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:00:43,975] {logging_mixin.py:109} INFO - [2022-04-07 23:00:43,975] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:00:43,994] {logging_mixin.py:109} INFO - [2022-04-07 23:00:43,994] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:00:44,002] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.977 seconds
[2022-04-07 23:01:14,160] {processor.py:163} INFO - Started process (PID=11683) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:01:14,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:01:14,164] {logging_mixin.py:109} INFO - [2022-04-07 23:01:14,163] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:01:15,214] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:01:15,236] {logging_mixin.py:109} INFO - [2022-04-07 23:01:15,236] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:01:15,257] {logging_mixin.py:109} INFO - [2022-04-07 23:01:15,257] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:01:15,267] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.113 seconds
[2022-04-07 23:01:45,373] {processor.py:163} INFO - Started process (PID=11716) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:01:45,376] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:01:45,377] {logging_mixin.py:109} INFO - [2022-04-07 23:01:45,376] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:01:46,344] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:01:46,372] {logging_mixin.py:109} INFO - [2022-04-07 23:01:46,372] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:01:46,396] {logging_mixin.py:109} INFO - [2022-04-07 23:01:46,395] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:01:46,406] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.039 seconds
[2022-04-07 23:02:16,489] {processor.py:163} INFO - Started process (PID=11752) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:02:16,492] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:02:16,493] {logging_mixin.py:109} INFO - [2022-04-07 23:02:16,493] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:02:17,502] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:02:17,529] {logging_mixin.py:109} INFO - [2022-04-07 23:02:17,528] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:02:17,556] {logging_mixin.py:109} INFO - [2022-04-07 23:02:17,555] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:02:17,569] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.085 seconds
[2022-04-07 23:02:47,672] {processor.py:163} INFO - Started process (PID=11783) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:02:47,675] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:02:47,676] {logging_mixin.py:109} INFO - [2022-04-07 23:02:47,675] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:02:48,623] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:02:48,647] {logging_mixin.py:109} INFO - [2022-04-07 23:02:48,646] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:02:48,667] {logging_mixin.py:109} INFO - [2022-04-07 23:02:48,666] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:02:48,677] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.010 seconds
[2022-04-07 23:03:18,790] {processor.py:163} INFO - Started process (PID=11811) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:03:18,791] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:03:18,792] {logging_mixin.py:109} INFO - [2022-04-07 23:03:18,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:03:19,811] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:03:19,837] {logging_mixin.py:109} INFO - [2022-04-07 23:03:19,836] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:03:19,863] {logging_mixin.py:109} INFO - [2022-04-07 23:03:19,862] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:03:19,875] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.090 seconds
[2022-04-07 23:03:50,036] {processor.py:163} INFO - Started process (PID=11848) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:03:50,038] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:03:50,039] {logging_mixin.py:109} INFO - [2022-04-07 23:03:50,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:03:50,910] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:03:50,933] {logging_mixin.py:109} INFO - [2022-04-07 23:03:50,933] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:03:50,953] {logging_mixin.py:109} INFO - [2022-04-07 23:03:50,952] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:03:50,962] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.931 seconds
[2022-04-07 23:04:21,077] {processor.py:163} INFO - Started process (PID=11877) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:04:21,080] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:04:21,080] {logging_mixin.py:109} INFO - [2022-04-07 23:04:21,080] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:04:22,079] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:04:22,111] {logging_mixin.py:109} INFO - [2022-04-07 23:04:22,110] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:04:22,140] {logging_mixin.py:109} INFO - [2022-04-07 23:04:22,140] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:04:22,153] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.081 seconds
[2022-04-07 23:04:52,251] {processor.py:163} INFO - Started process (PID=11914) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:04:52,253] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:04:52,254] {logging_mixin.py:109} INFO - [2022-04-07 23:04:52,253] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:04:53,123] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:04:53,145] {logging_mixin.py:109} INFO - [2022-04-07 23:04:53,144] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:04:53,164] {logging_mixin.py:109} INFO - [2022-04-07 23:04:53,163] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:04:53,173] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.926 seconds
[2022-04-07 23:05:23,283] {processor.py:163} INFO - Started process (PID=11943) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:05:23,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:05:23,286] {logging_mixin.py:109} INFO - [2022-04-07 23:05:23,286] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:05:24,185] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:05:24,211] {logging_mixin.py:109} INFO - [2022-04-07 23:05:24,210] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:05:24,241] {logging_mixin.py:109} INFO - [2022-04-07 23:05:24,241] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:05:24,254] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.976 seconds
[2022-04-07 23:05:54,405] {processor.py:163} INFO - Started process (PID=11981) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:05:54,409] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:05:54,409] {logging_mixin.py:109} INFO - [2022-04-07 23:05:54,409] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:05:55,255] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:05:55,278] {logging_mixin.py:109} INFO - [2022-04-07 23:05:55,278] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:05:55,298] {logging_mixin.py:109} INFO - [2022-04-07 23:05:55,297] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:05:55,309] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.908 seconds
[2022-04-07 23:06:25,424] {processor.py:163} INFO - Started process (PID=12009) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:06:25,426] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:06:25,427] {logging_mixin.py:109} INFO - [2022-04-07 23:06:25,427] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:06:26,338] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:06:26,362] {logging_mixin.py:109} INFO - [2022-04-07 23:06:26,362] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:06:26,384] {logging_mixin.py:109} INFO - [2022-04-07 23:06:26,384] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:06:26,394] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.975 seconds
[2022-04-07 23:06:56,571] {processor.py:163} INFO - Started process (PID=12046) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:06:56,573] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:06:56,574] {logging_mixin.py:109} INFO - [2022-04-07 23:06:56,574] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:06:57,481] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:06:57,507] {logging_mixin.py:109} INFO - [2022-04-07 23:06:57,506] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:06:57,531] {logging_mixin.py:109} INFO - [2022-04-07 23:06:57,531] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:06:57,543] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.977 seconds
[2022-04-07 23:07:27,692] {processor.py:163} INFO - Started process (PID=12074) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:07:27,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:07:27,694] {logging_mixin.py:109} INFO - [2022-04-07 23:07:27,694] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:07:28,590] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:07:28,614] {logging_mixin.py:109} INFO - [2022-04-07 23:07:28,614] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:07:28,635] {logging_mixin.py:109} INFO - [2022-04-07 23:07:28,634] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:07:28,645] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.959 seconds
[2022-04-07 23:07:58,803] {processor.py:163} INFO - Started process (PID=12111) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:07:58,806] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:07:58,807] {logging_mixin.py:109} INFO - [2022-04-07 23:07:58,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:07:59,690] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:07:59,713] {logging_mixin.py:109} INFO - [2022-04-07 23:07:59,713] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:07:59,733] {logging_mixin.py:109} INFO - [2022-04-07 23:07:59,733] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:07:59,744] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.946 seconds
[2022-04-07 23:08:29,891] {processor.py:163} INFO - Started process (PID=12138) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:08:29,892] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:08:29,893] {logging_mixin.py:109} INFO - [2022-04-07 23:08:29,893] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:08:30,743] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:08:30,772] {logging_mixin.py:109} INFO - [2022-04-07 23:08:30,771] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:08:30,793] {logging_mixin.py:109} INFO - [2022-04-07 23:08:30,793] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:08:30,806] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.920 seconds
[2022-04-07 23:09:00,925] {processor.py:163} INFO - Started process (PID=12177) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:09:00,926] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:09:00,927] {logging_mixin.py:109} INFO - [2022-04-07 23:09:00,927] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:09:01,800] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:09:01,823] {logging_mixin.py:109} INFO - [2022-04-07 23:09:01,823] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:09:01,845] {logging_mixin.py:109} INFO - [2022-04-07 23:09:01,845] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:09:01,858] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.939 seconds
[2022-04-07 23:09:31,967] {processor.py:163} INFO - Started process (PID=12206) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:09:31,969] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:09:31,970] {logging_mixin.py:109} INFO - [2022-04-07 23:09:31,970] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:09:32,867] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:09:32,893] {logging_mixin.py:109} INFO - [2022-04-07 23:09:32,893] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:09:32,916] {logging_mixin.py:109} INFO - [2022-04-07 23:09:32,916] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:09:32,928] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.966 seconds
[2022-04-07 23:10:03,039] {processor.py:163} INFO - Started process (PID=12243) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:10:03,041] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:10:03,042] {logging_mixin.py:109} INFO - [2022-04-07 23:10:03,042] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:10:03,926] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:10:03,952] {logging_mixin.py:109} INFO - [2022-04-07 23:10:03,951] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:10:03,972] {logging_mixin.py:109} INFO - [2022-04-07 23:10:03,972] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:10:03,982] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 23:10:34,086] {processor.py:163} INFO - Started process (PID=12270) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:10:34,088] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:10:34,089] {logging_mixin.py:109} INFO - [2022-04-07 23:10:34,089] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:10:34,961] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:10:34,983] {logging_mixin.py:109} INFO - [2022-04-07 23:10:34,983] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:10:35,003] {logging_mixin.py:109} INFO - [2022-04-07 23:10:35,002] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:10:35,012] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.932 seconds
[2022-04-07 23:11:05,120] {processor.py:163} INFO - Started process (PID=12307) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:11:05,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:11:05,123] {logging_mixin.py:109} INFO - [2022-04-07 23:11:05,123] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:11:05,983] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:11:06,005] {logging_mixin.py:109} INFO - [2022-04-07 23:11:06,004] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:11:06,023] {logging_mixin.py:109} INFO - [2022-04-07 23:11:06,023] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:11:06,034] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.919 seconds
[2022-04-07 23:11:36,135] {processor.py:163} INFO - Started process (PID=12335) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:11:36,138] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:11:36,139] {logging_mixin.py:109} INFO - [2022-04-07 23:11:36,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:11:37,021] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:11:37,045] {logging_mixin.py:109} INFO - [2022-04-07 23:11:37,044] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:11:37,064] {logging_mixin.py:109} INFO - [2022-04-07 23:11:37,064] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:11:37,075] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 23:12:07,185] {processor.py:163} INFO - Started process (PID=12371) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:12:07,187] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:12:07,188] {logging_mixin.py:109} INFO - [2022-04-07 23:12:07,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:12:08,080] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:12:08,103] {logging_mixin.py:109} INFO - [2022-04-07 23:12:08,102] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:12:08,123] {logging_mixin.py:109} INFO - [2022-04-07 23:12:08,123] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:12:08,132] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.952 seconds
[2022-04-07 23:12:38,231] {processor.py:163} INFO - Started process (PID=12400) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:12:38,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:12:38,234] {logging_mixin.py:109} INFO - [2022-04-07 23:12:38,234] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:12:39,089] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:12:39,114] {logging_mixin.py:109} INFO - [2022-04-07 23:12:39,113] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:12:39,134] {logging_mixin.py:109} INFO - [2022-04-07 23:12:39,134] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:12:39,145] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.919 seconds
[2022-04-07 23:13:09,245] {processor.py:163} INFO - Started process (PID=12440) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:13:09,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:13:09,248] {logging_mixin.py:109} INFO - [2022-04-07 23:13:09,248] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:13:10,099] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:13:10,121] {logging_mixin.py:109} INFO - [2022-04-07 23:13:10,121] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:13:10,140] {logging_mixin.py:109} INFO - [2022-04-07 23:13:10,140] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:13:10,150] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.909 seconds
[2022-04-07 23:13:40,248] {processor.py:163} INFO - Started process (PID=12466) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:13:40,250] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:13:40,251] {logging_mixin.py:109} INFO - [2022-04-07 23:13:40,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:13:41,158] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:13:41,182] {logging_mixin.py:109} INFO - [2022-04-07 23:13:41,181] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:13:41,201] {logging_mixin.py:109} INFO - [2022-04-07 23:13:41,200] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:13:41,210] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.967 seconds
[2022-04-07 23:14:11,311] {processor.py:163} INFO - Started process (PID=12505) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:14:11,313] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:14:11,314] {logging_mixin.py:109} INFO - [2022-04-07 23:14:11,314] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:14:12,196] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:14:12,220] {logging_mixin.py:109} INFO - [2022-04-07 23:14:12,219] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:14:12,239] {logging_mixin.py:109} INFO - [2022-04-07 23:14:12,239] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:14:12,250] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 23:14:42,345] {processor.py:163} INFO - Started process (PID=12534) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:14:42,347] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:14:42,348] {logging_mixin.py:109} INFO - [2022-04-07 23:14:42,347] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:14:43,215] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:14:43,236] {logging_mixin.py:109} INFO - [2022-04-07 23:14:43,236] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:14:43,255] {logging_mixin.py:109} INFO - [2022-04-07 23:14:43,255] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:14:43,265] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.926 seconds
[2022-04-07 23:15:13,364] {processor.py:163} INFO - Started process (PID=12572) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:15:13,368] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:15:13,369] {logging_mixin.py:109} INFO - [2022-04-07 23:15:13,369] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:15:14,249] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:15:14,271] {logging_mixin.py:109} INFO - [2022-04-07 23:15:14,271] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:15:14,292] {logging_mixin.py:109} INFO - [2022-04-07 23:15:14,292] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:15:14,302] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.942 seconds
[2022-04-07 23:15:44,372] {processor.py:163} INFO - Started process (PID=12601) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:15:44,374] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:15:44,376] {logging_mixin.py:109} INFO - [2022-04-07 23:15:44,375] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:15:45,220] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:15:45,243] {logging_mixin.py:109} INFO - [2022-04-07 23:15:45,243] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:15:45,265] {logging_mixin.py:109} INFO - [2022-04-07 23:15:45,265] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:15:45,274] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.908 seconds
[2022-04-07 23:16:15,388] {processor.py:163} INFO - Started process (PID=12637) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:16:15,391] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:16:15,392] {logging_mixin.py:109} INFO - [2022-04-07 23:16:15,392] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:16:16,291] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:16:16,315] {logging_mixin.py:109} INFO - [2022-04-07 23:16:16,314] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:16:16,337] {logging_mixin.py:109} INFO - [2022-04-07 23:16:16,336] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:16:16,348] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.965 seconds
[2022-04-07 23:16:46,453] {processor.py:163} INFO - Started process (PID=12666) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:16:46,455] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:16:46,456] {logging_mixin.py:109} INFO - [2022-04-07 23:16:46,456] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:16:47,314] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:16:47,339] {logging_mixin.py:109} INFO - [2022-04-07 23:16:47,339] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:16:47,363] {logging_mixin.py:109} INFO - [2022-04-07 23:16:47,363] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:16:47,376] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.928 seconds
[2022-04-07 23:17:17,484] {processor.py:163} INFO - Started process (PID=12705) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:17:17,487] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:17:17,488] {logging_mixin.py:109} INFO - [2022-04-07 23:17:17,488] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:17:18,362] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:17:18,387] {logging_mixin.py:109} INFO - [2022-04-07 23:17:18,386] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:17:18,409] {logging_mixin.py:109} INFO - [2022-04-07 23:17:18,409] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:17:18,420] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.941 seconds
[2022-04-07 23:17:48,532] {processor.py:163} INFO - Started process (PID=12734) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:17:48,535] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:17:48,536] {logging_mixin.py:109} INFO - [2022-04-07 23:17:48,535] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:17:49,481] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:17:49,512] {logging_mixin.py:109} INFO - [2022-04-07 23:17:49,512] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:17:49,534] {logging_mixin.py:109} INFO - [2022-04-07 23:17:49,534] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:17:49,548] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.021 seconds
[2022-04-07 23:18:19,661] {processor.py:163} INFO - Started process (PID=12773) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:18:19,664] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:18:19,665] {logging_mixin.py:109} INFO - [2022-04-07 23:18:19,665] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:18:20,558] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:18:20,584] {logging_mixin.py:109} INFO - [2022-04-07 23:18:20,583] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:18:20,605] {logging_mixin.py:109} INFO - [2022-04-07 23:18:20,604] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:18:20,615] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.959 seconds
[2022-04-07 23:18:50,767] {processor.py:163} INFO - Started process (PID=12802) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:18:50,769] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:18:50,770] {logging_mixin.py:109} INFO - [2022-04-07 23:18:50,770] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:18:51,618] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:18:51,643] {logging_mixin.py:109} INFO - [2022-04-07 23:18:51,643] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:18:51,663] {logging_mixin.py:109} INFO - [2022-04-07 23:18:51,663] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:18:51,675] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.913 seconds
[2022-04-07 23:19:21,783] {processor.py:163} INFO - Started process (PID=12839) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:19:21,785] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:19:21,786] {logging_mixin.py:109} INFO - [2022-04-07 23:19:21,786] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:19:22,639] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:19:22,662] {logging_mixin.py:109} INFO - [2022-04-07 23:19:22,661] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:19:22,682] {logging_mixin.py:109} INFO - [2022-04-07 23:19:22,682] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:19:22,692] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.914 seconds
[2022-04-07 23:19:52,794] {processor.py:163} INFO - Started process (PID=12869) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:19:52,796] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:19:52,797] {logging_mixin.py:109} INFO - [2022-04-07 23:19:52,797] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:19:53,662] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:19:53,690] {logging_mixin.py:109} INFO - [2022-04-07 23:19:53,689] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:19:53,717] {logging_mixin.py:109} INFO - [2022-04-07 23:19:53,716] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:19:53,727] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.938 seconds
[2022-04-07 23:20:23,835] {processor.py:163} INFO - Started process (PID=12907) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:20:23,837] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:20:23,838] {logging_mixin.py:109} INFO - [2022-04-07 23:20:23,837] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:20:24,738] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:20:24,761] {logging_mixin.py:109} INFO - [2022-04-07 23:20:24,761] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:20:24,782] {logging_mixin.py:109} INFO - [2022-04-07 23:20:24,782] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:20:24,794] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.964 seconds
[2022-04-07 23:20:54,896] {processor.py:163} INFO - Started process (PID=12939) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:20:54,899] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:20:54,900] {logging_mixin.py:109} INFO - [2022-04-07 23:20:54,900] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:20:55,815] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:20:55,838] {logging_mixin.py:109} INFO - [2022-04-07 23:20:55,837] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:20:55,856] {logging_mixin.py:109} INFO - [2022-04-07 23:20:55,856] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:20:55,866] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.975 seconds
[2022-04-07 23:21:25,972] {processor.py:163} INFO - Started process (PID=12978) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:21:25,974] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:21:25,975] {logging_mixin.py:109} INFO - [2022-04-07 23:21:25,975] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:21:26,871] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:21:26,893] {logging_mixin.py:109} INFO - [2022-04-07 23:21:26,893] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:21:26,912] {logging_mixin.py:109} INFO - [2022-04-07 23:21:26,912] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:21:26,923] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.957 seconds
[2022-04-07 23:21:57,038] {processor.py:163} INFO - Started process (PID=13006) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:21:57,041] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:21:57,042] {logging_mixin.py:109} INFO - [2022-04-07 23:21:57,042] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:21:57,928] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:21:57,951] {logging_mixin.py:109} INFO - [2022-04-07 23:21:57,950] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:21:57,970] {logging_mixin.py:109} INFO - [2022-04-07 23:21:57,970] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:21:57,980] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.947 seconds
[2022-04-07 23:22:28,089] {processor.py:163} INFO - Started process (PID=13043) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:22:28,090] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:22:28,091] {logging_mixin.py:109} INFO - [2022-04-07 23:22:28,091] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:22:29,038] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:22:29,062] {logging_mixin.py:109} INFO - [2022-04-07 23:22:29,061] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:22:29,084] {logging_mixin.py:109} INFO - [2022-04-07 23:22:29,084] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:22:29,095] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.011 seconds
[2022-04-07 23:22:59,208] {processor.py:163} INFO - Started process (PID=13073) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:22:59,210] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:22:59,211] {logging_mixin.py:109} INFO - [2022-04-07 23:22:59,211] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:23:00,073] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:23:00,099] {logging_mixin.py:109} INFO - [2022-04-07 23:23:00,099] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:23:00,119] {logging_mixin.py:109} INFO - [2022-04-07 23:23:00,119] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:23:00,130] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.926 seconds
[2022-04-07 23:23:30,242] {processor.py:163} INFO - Started process (PID=13113) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:23:30,245] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:23:30,246] {logging_mixin.py:109} INFO - [2022-04-07 23:23:30,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:23:31,142] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:23:31,169] {logging_mixin.py:109} INFO - [2022-04-07 23:23:31,169] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:23:31,191] {logging_mixin.py:109} INFO - [2022-04-07 23:23:31,191] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:23:31,201] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.963 seconds
[2022-04-07 23:24:01,320] {processor.py:163} INFO - Started process (PID=13140) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:24:01,322] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:24:01,323] {logging_mixin.py:109} INFO - [2022-04-07 23:24:01,323] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:24:02,213] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:24:02,237] {logging_mixin.py:109} INFO - [2022-04-07 23:24:02,237] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:24:02,258] {logging_mixin.py:109} INFO - [2022-04-07 23:24:02,258] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:24:02,268] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.953 seconds
[2022-04-07 23:24:32,377] {processor.py:163} INFO - Started process (PID=13178) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:24:32,380] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:24:32,381] {logging_mixin.py:109} INFO - [2022-04-07 23:24:32,380] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:24:33,250] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:24:33,273] {logging_mixin.py:109} INFO - [2022-04-07 23:24:33,273] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:24:33,293] {logging_mixin.py:109} INFO - [2022-04-07 23:24:33,293] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:24:33,302] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.932 seconds
[2022-04-07 23:25:03,412] {processor.py:163} INFO - Started process (PID=13206) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:25:03,416] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:25:03,416] {logging_mixin.py:109} INFO - [2022-04-07 23:25:03,416] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:25:04,323] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:25:04,351] {logging_mixin.py:109} INFO - [2022-04-07 23:25:04,351] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:25:04,376] {logging_mixin.py:109} INFO - [2022-04-07 23:25:04,376] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:25:04,391] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.984 seconds
[2022-04-07 23:25:34,540] {processor.py:163} INFO - Started process (PID=13244) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:25:34,543] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:25:34,544] {logging_mixin.py:109} INFO - [2022-04-07 23:25:34,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:25:35,494] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:25:35,523] {logging_mixin.py:109} INFO - [2022-04-07 23:25:35,522] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:25:35,550] {logging_mixin.py:109} INFO - [2022-04-07 23:25:35,550] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:25:35,562] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.027 seconds
[2022-04-07 23:26:05,665] {processor.py:163} INFO - Started process (PID=13272) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:26:05,668] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:26:05,669] {logging_mixin.py:109} INFO - [2022-04-07 23:26:05,669] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:26:06,497] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:26:06,519] {logging_mixin.py:109} INFO - [2022-04-07 23:26:06,519] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:26:06,538] {logging_mixin.py:109} INFO - [2022-04-07 23:26:06,537] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:26:06,546] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.886 seconds
[2022-04-07 23:26:36,651] {processor.py:163} INFO - Started process (PID=13309) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:26:36,654] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:26:36,655] {logging_mixin.py:109} INFO - [2022-04-07 23:26:36,655] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:26:37,597] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:26:37,620] {logging_mixin.py:109} INFO - [2022-04-07 23:26:37,620] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:26:37,643] {logging_mixin.py:109} INFO - [2022-04-07 23:26:37,643] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:26:37,656] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.010 seconds
[2022-04-07 23:27:07,800] {processor.py:163} INFO - Started process (PID=13336) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:27:07,802] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:27:07,803] {logging_mixin.py:109} INFO - [2022-04-07 23:27:07,803] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:27:08,721] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:27:08,744] {logging_mixin.py:109} INFO - [2022-04-07 23:27:08,744] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:27:08,765] {logging_mixin.py:109} INFO - [2022-04-07 23:27:08,764] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:27:08,775] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.980 seconds
[2022-04-07 23:27:38,936] {processor.py:163} INFO - Started process (PID=13376) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:27:38,937] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:27:38,938] {logging_mixin.py:109} INFO - [2022-04-07 23:27:38,938] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:27:39,874] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:27:39,898] {logging_mixin.py:109} INFO - [2022-04-07 23:27:39,898] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:27:39,919] {logging_mixin.py:109} INFO - [2022-04-07 23:27:39,919] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:27:39,929] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.999 seconds
[2022-04-07 23:28:10,064] {processor.py:163} INFO - Started process (PID=13405) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:28:10,066] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:28:10,067] {logging_mixin.py:109} INFO - [2022-04-07 23:28:10,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:28:10,945] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:28:10,969] {logging_mixin.py:109} INFO - [2022-04-07 23:28:10,968] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:28:10,994] {logging_mixin.py:109} INFO - [2022-04-07 23:28:10,994] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:28:11,003] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 23:28:41,149] {processor.py:163} INFO - Started process (PID=13445) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:28:41,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:28:41,152] {logging_mixin.py:109} INFO - [2022-04-07 23:28:41,152] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:28:42,078] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:28:42,103] {logging_mixin.py:109} INFO - [2022-04-07 23:28:42,103] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:28:42,126] {logging_mixin.py:109} INFO - [2022-04-07 23:28:42,126] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:28:42,137] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.992 seconds
[2022-04-07 23:29:12,269] {processor.py:163} INFO - Started process (PID=13473) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:29:12,271] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:29:12,272] {logging_mixin.py:109} INFO - [2022-04-07 23:29:12,271] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:29:13,132] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:29:13,158] {logging_mixin.py:109} INFO - [2022-04-07 23:29:13,157] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:29:13,182] {logging_mixin.py:109} INFO - [2022-04-07 23:29:13,182] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:29:13,194] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.930 seconds
[2022-04-07 23:29:43,315] {processor.py:163} INFO - Started process (PID=13511) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:29:43,317] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:29:43,317] {logging_mixin.py:109} INFO - [2022-04-07 23:29:43,317] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:29:44,280] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:29:44,306] {logging_mixin.py:109} INFO - [2022-04-07 23:29:44,306] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:29:44,326] {logging_mixin.py:109} INFO - [2022-04-07 23:29:44,326] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:29:44,338] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.028 seconds
[2022-04-07 23:30:14,489] {processor.py:163} INFO - Started process (PID=13539) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:30:14,492] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:30:14,492] {logging_mixin.py:109} INFO - [2022-04-07 23:30:14,492] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:30:15,333] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:30:15,357] {logging_mixin.py:109} INFO - [2022-04-07 23:30:15,357] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:30:15,376] {logging_mixin.py:109} INFO - [2022-04-07 23:30:15,376] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:30:15,387] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.902 seconds
[2022-04-07 23:30:45,498] {processor.py:163} INFO - Started process (PID=13575) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:30:45,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:30:45,501] {logging_mixin.py:109} INFO - [2022-04-07 23:30:45,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:30:46,496] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:30:46,519] {logging_mixin.py:109} INFO - [2022-04-07 23:30:46,519] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:30:46,538] {logging_mixin.py:109} INFO - [2022-04-07 23:30:46,538] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:30:46,549] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.056 seconds
[2022-04-07 23:31:16,682] {processor.py:163} INFO - Started process (PID=13603) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:31:16,685] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:31:16,685] {logging_mixin.py:109} INFO - [2022-04-07 23:31:16,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:31:17,568] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:31:17,591] {logging_mixin.py:109} INFO - [2022-04-07 23:31:17,591] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:31:17,613] {logging_mixin.py:109} INFO - [2022-04-07 23:31:17,613] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:31:17,623] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.947 seconds
[2022-04-07 23:31:47,790] {processor.py:163} INFO - Started process (PID=13640) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:31:47,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:31:47,794] {logging_mixin.py:109} INFO - [2022-04-07 23:31:47,793] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:31:48,687] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:31:48,711] {logging_mixin.py:109} INFO - [2022-04-07 23:31:48,711] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:31:48,732] {logging_mixin.py:109} INFO - [2022-04-07 23:31:48,732] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:31:48,742] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.958 seconds
[2022-04-07 23:32:18,882] {processor.py:163} INFO - Started process (PID=13668) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:32:18,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:32:18,886] {logging_mixin.py:109} INFO - [2022-04-07 23:32:18,886] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:32:19,781] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:32:19,811] {logging_mixin.py:109} INFO - [2022-04-07 23:32:19,811] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:32:19,835] {logging_mixin.py:109} INFO - [2022-04-07 23:32:19,835] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:32:19,849] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.972 seconds
[2022-04-07 23:32:49,991] {processor.py:163} INFO - Started process (PID=13706) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:32:49,994] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:32:49,995] {logging_mixin.py:109} INFO - [2022-04-07 23:32:49,995] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:32:50,893] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:32:50,917] {logging_mixin.py:109} INFO - [2022-04-07 23:32:50,917] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:32:50,937] {logging_mixin.py:109} INFO - [2022-04-07 23:32:50,937] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:32:50,947] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.961 seconds
[2022-04-07 23:33:21,087] {processor.py:163} INFO - Started process (PID=13734) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:33:21,089] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:33:21,090] {logging_mixin.py:109} INFO - [2022-04-07 23:33:21,090] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:33:21,947] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:33:21,969] {logging_mixin.py:109} INFO - [2022-04-07 23:33:21,969] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:33:21,989] {logging_mixin.py:109} INFO - [2022-04-07 23:33:21,989] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:33:21,998] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.916 seconds
[2022-04-07 23:33:52,097] {processor.py:163} INFO - Started process (PID=13771) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:33:52,099] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:33:52,099] {logging_mixin.py:109} INFO - [2022-04-07 23:33:52,099] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:33:52,991] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:33:53,018] {logging_mixin.py:109} INFO - [2022-04-07 23:33:53,018] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:33:53,038] {logging_mixin.py:109} INFO - [2022-04-07 23:33:53,038] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:33:53,048] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.957 seconds
[2022-04-07 23:34:23,146] {processor.py:163} INFO - Started process (PID=13799) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:34:23,149] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:34:23,150] {logging_mixin.py:109} INFO - [2022-04-07 23:34:23,150] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:34:24,067] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:34:24,096] {logging_mixin.py:109} INFO - [2022-04-07 23:34:24,096] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:34:24,116] {logging_mixin.py:109} INFO - [2022-04-07 23:34:24,116] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:34:24,128] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.987 seconds
[2022-04-07 23:34:54,263] {processor.py:163} INFO - Started process (PID=13838) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:34:54,265] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:34:54,266] {logging_mixin.py:109} INFO - [2022-04-07 23:34:54,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:34:55,116] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:34:55,139] {logging_mixin.py:109} INFO - [2022-04-07 23:34:55,139] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:34:55,159] {logging_mixin.py:109} INFO - [2022-04-07 23:34:55,159] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:34:55,170] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.911 seconds
[2022-04-07 23:35:25,286] {processor.py:163} INFO - Started process (PID=13866) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:35:25,288] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:35:25,289] {logging_mixin.py:109} INFO - [2022-04-07 23:35:25,289] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:35:26,172] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:35:26,197] {logging_mixin.py:109} INFO - [2022-04-07 23:35:26,196] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:35:26,215] {logging_mixin.py:109} INFO - [2022-04-07 23:35:26,215] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:35:26,224] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 23:35:56,327] {processor.py:163} INFO - Started process (PID=13904) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:35:56,329] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:35:56,330] {logging_mixin.py:109} INFO - [2022-04-07 23:35:56,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:35:57,255] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:35:57,281] {logging_mixin.py:109} INFO - [2022-04-07 23:35:57,281] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:35:57,301] {logging_mixin.py:109} INFO - [2022-04-07 23:35:57,301] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:35:57,312] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.990 seconds
[2022-04-07 23:36:27,447] {processor.py:163} INFO - Started process (PID=13934) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:36:27,449] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:36:27,450] {logging_mixin.py:109} INFO - [2022-04-07 23:36:27,450] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:36:28,364] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:36:28,392] {logging_mixin.py:109} INFO - [2022-04-07 23:36:28,392] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:36:28,413] {logging_mixin.py:109} INFO - [2022-04-07 23:36:28,413] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:36:28,424] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.982 seconds
[2022-04-07 23:36:58,587] {processor.py:163} INFO - Started process (PID=13971) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:36:58,588] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:36:58,589] {logging_mixin.py:109} INFO - [2022-04-07 23:36:58,589] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:36:59,464] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:36:59,487] {logging_mixin.py:109} INFO - [2022-04-07 23:36:59,487] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:36:59,508] {logging_mixin.py:109} INFO - [2022-04-07 23:36:59,508] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:36:59,521] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.939 seconds
[2022-04-07 23:37:29,633] {processor.py:163} INFO - Started process (PID=13998) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:37:29,635] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:37:29,636] {logging_mixin.py:109} INFO - [2022-04-07 23:37:29,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:37:30,592] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:37:30,618] {logging_mixin.py:109} INFO - [2022-04-07 23:37:30,618] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:37:30,640] {logging_mixin.py:109} INFO - [2022-04-07 23:37:30,639] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:37:30,656] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.028 seconds
[2022-04-07 23:38:00,805] {processor.py:163} INFO - Started process (PID=14035) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:38:00,806] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:38:00,807] {logging_mixin.py:109} INFO - [2022-04-07 23:38:00,807] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:38:01,663] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:38:01,688] {logging_mixin.py:109} INFO - [2022-04-07 23:38:01,688] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:38:01,709] {logging_mixin.py:109} INFO - [2022-04-07 23:38:01,709] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:38:01,720] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.920 seconds
[2022-04-07 23:38:31,835] {processor.py:163} INFO - Started process (PID=14073) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:38:31,837] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:38:31,838] {logging_mixin.py:109} INFO - [2022-04-07 23:38:31,838] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:38:32,779] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:38:32,803] {logging_mixin.py:109} INFO - [2022-04-07 23:38:32,802] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:38:32,823] {logging_mixin.py:109} INFO - [2022-04-07 23:38:32,823] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:38:32,835] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 23:39:02,951] {processor.py:163} INFO - Started process (PID=14104) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:39:02,953] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:39:02,954] {logging_mixin.py:109} INFO - [2022-04-07 23:39:02,954] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:39:03,831] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:39:03,859] {logging_mixin.py:109} INFO - [2022-04-07 23:39:03,859] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:39:03,880] {logging_mixin.py:109} INFO - [2022-04-07 23:39:03,880] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:39:03,891] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.944 seconds
[2022-04-07 23:39:34,064] {processor.py:163} INFO - Started process (PID=14141) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:39:34,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:39:34,068] {logging_mixin.py:109} INFO - [2022-04-07 23:39:34,068] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:39:35,065] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:39:35,089] {logging_mixin.py:109} INFO - [2022-04-07 23:39:35,089] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:39:35,109] {logging_mixin.py:109} INFO - [2022-04-07 23:39:35,109] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:39:35,120] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.062 seconds
[2022-04-07 23:40:05,179] {processor.py:163} INFO - Started process (PID=14168) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:40:05,182] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:40:05,183] {logging_mixin.py:109} INFO - [2022-04-07 23:40:05,182] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:40:06,069] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:40:06,093] {logging_mixin.py:109} INFO - [2022-04-07 23:40:06,093] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:40:06,113] {logging_mixin.py:109} INFO - [2022-04-07 23:40:06,113] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:40:06,124] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.949 seconds
[2022-04-07 23:40:36,265] {processor.py:163} INFO - Started process (PID=14207) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:40:36,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:40:36,268] {logging_mixin.py:109} INFO - [2022-04-07 23:40:36,268] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:40:37,156] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:40:37,201] {logging_mixin.py:109} INFO - [2022-04-07 23:40:37,200] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:40:37,227] {logging_mixin.py:109} INFO - [2022-04-07 23:40:37,226] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:40:37,239] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.979 seconds
[2022-04-07 23:41:07,385] {processor.py:163} INFO - Started process (PID=14235) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:41:07,387] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:41:07,388] {logging_mixin.py:109} INFO - [2022-04-07 23:41:07,388] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:41:08,269] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:41:08,291] {logging_mixin.py:109} INFO - [2022-04-07 23:41:08,291] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:41:08,312] {logging_mixin.py:109} INFO - [2022-04-07 23:41:08,312] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:41:08,321] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.940 seconds
[2022-04-07 23:41:38,436] {processor.py:163} INFO - Started process (PID=14273) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:41:38,439] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:41:38,440] {logging_mixin.py:109} INFO - [2022-04-07 23:41:38,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:41:39,410] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:41:39,437] {logging_mixin.py:109} INFO - [2022-04-07 23:41:39,437] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:41:39,457] {logging_mixin.py:109} INFO - [2022-04-07 23:41:39,457] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:41:39,468] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.039 seconds
[2022-04-07 23:42:09,611] {processor.py:163} INFO - Started process (PID=14302) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:42:09,613] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:42:09,614] {logging_mixin.py:109} INFO - [2022-04-07 23:42:09,614] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:42:10,502] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:42:10,525] {logging_mixin.py:109} INFO - [2022-04-07 23:42:10,524] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:42:10,545] {logging_mixin.py:109} INFO - [2022-04-07 23:42:10,545] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:42:10,558] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.952 seconds
[2022-04-07 23:42:40,714] {processor.py:163} INFO - Started process (PID=14334) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:42:40,716] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:42:40,718] {logging_mixin.py:109} INFO - [2022-04-07 23:42:40,717] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:42:41,645] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:42:41,673] {logging_mixin.py:109} INFO - [2022-04-07 23:42:41,673] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:42:41,699] {logging_mixin.py:109} INFO - [2022-04-07 23:42:41,698] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:42:41,713] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.006 seconds
[2022-04-07 23:43:11,841] {processor.py:163} INFO - Started process (PID=14367) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:43:11,843] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:43:11,844] {logging_mixin.py:109} INFO - [2022-04-07 23:43:11,844] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:43:12,755] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:43:12,779] {logging_mixin.py:109} INFO - [2022-04-07 23:43:12,779] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:43:12,798] {logging_mixin.py:109} INFO - [2022-04-07 23:43:12,798] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:43:12,811] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.975 seconds
[2022-04-07 23:43:42,993] {processor.py:163} INFO - Started process (PID=14397) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:43:42,995] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:43:42,996] {logging_mixin.py:109} INFO - [2022-04-07 23:43:42,996] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:43:43,888] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:43:43,917] {logging_mixin.py:109} INFO - [2022-04-07 23:43:43,917] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:43:43,939] {logging_mixin.py:109} INFO - [2022-04-07 23:43:43,939] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:43:43,951] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.964 seconds
[2022-04-07 23:44:14,098] {processor.py:163} INFO - Started process (PID=14436) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:44:14,100] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:44:14,101] {logging_mixin.py:109} INFO - [2022-04-07 23:44:14,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:44:14,999] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:44:15,025] {logging_mixin.py:109} INFO - [2022-04-07 23:44:15,025] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:44:15,044] {logging_mixin.py:109} INFO - [2022-04-07 23:44:15,044] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:44:15,054] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.961 seconds
[2022-04-07 23:44:45,219] {processor.py:163} INFO - Started process (PID=14471) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:44:45,222] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:44:45,223] {logging_mixin.py:109} INFO - [2022-04-07 23:44:45,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:44:46,128] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:44:46,151] {logging_mixin.py:109} INFO - [2022-04-07 23:44:46,151] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:44:46,170] {logging_mixin.py:109} INFO - [2022-04-07 23:44:46,170] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:44:46,180] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.968 seconds
[2022-04-07 23:45:16,330] {processor.py:163} INFO - Started process (PID=14504) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:45:16,331] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:45:16,332] {logging_mixin.py:109} INFO - [2022-04-07 23:45:16,332] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:45:17,212] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:45:17,234] {logging_mixin.py:109} INFO - [2022-04-07 23:45:17,234] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:45:17,254] {logging_mixin.py:109} INFO - [2022-04-07 23:45:17,254] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:45:17,265] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.939 seconds
[2022-04-07 23:45:47,379] {processor.py:163} INFO - Started process (PID=14534) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:45:47,381] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:45:47,382] {logging_mixin.py:109} INFO - [2022-04-07 23:45:47,382] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:45:48,318] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:45:48,341] {logging_mixin.py:109} INFO - [2022-04-07 23:45:48,340] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:45:48,362] {logging_mixin.py:109} INFO - [2022-04-07 23:45:48,362] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:45:48,373] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.000 seconds
[2022-04-07 23:46:18,495] {processor.py:163} INFO - Started process (PID=14571) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:46:18,497] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:46:18,498] {logging_mixin.py:109} INFO - [2022-04-07 23:46:18,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:46:19,361] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:46:19,385] {logging_mixin.py:109} INFO - [2022-04-07 23:46:19,384] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:46:19,404] {logging_mixin.py:109} INFO - [2022-04-07 23:46:19,404] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:46:19,414] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.924 seconds
[2022-04-07 23:46:49,524] {processor.py:163} INFO - Started process (PID=14600) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:46:49,526] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:46:49,527] {logging_mixin.py:109} INFO - [2022-04-07 23:46:49,527] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:46:50,413] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:46:50,447] {logging_mixin.py:109} INFO - [2022-04-07 23:46:50,447] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:46:50,476] {logging_mixin.py:109} INFO - [2022-04-07 23:46:50,476] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:46:50,489] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.971 seconds
[2022-04-07 23:47:20,660] {processor.py:163} INFO - Started process (PID=14637) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:47:20,662] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:47:20,663] {logging_mixin.py:109} INFO - [2022-04-07 23:47:20,663] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:47:21,576] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:47:21,600] {logging_mixin.py:109} INFO - [2022-04-07 23:47:21,599] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:47:21,620] {logging_mixin.py:109} INFO - [2022-04-07 23:47:21,620] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:47:21,630] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.976 seconds
[2022-04-07 23:47:51,798] {processor.py:163} INFO - Started process (PID=14667) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:47:51,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:47:51,802] {logging_mixin.py:109} INFO - [2022-04-07 23:47:51,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:47:52,706] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:47:52,733] {logging_mixin.py:109} INFO - [2022-04-07 23:47:52,733] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:47:52,757] {logging_mixin.py:109} INFO - [2022-04-07 23:47:52,757] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:47:52,771] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.978 seconds
[2022-04-07 23:48:22,932] {processor.py:163} INFO - Started process (PID=14705) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:48:22,935] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:48:22,936] {logging_mixin.py:109} INFO - [2022-04-07 23:48:22,936] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:48:23,841] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:48:23,867] {logging_mixin.py:109} INFO - [2022-04-07 23:48:23,867] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:48:23,892] {logging_mixin.py:109} INFO - [2022-04-07 23:48:23,892] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:48:23,907] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.979 seconds
[2022-04-07 23:48:54,055] {processor.py:163} INFO - Started process (PID=14734) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:48:54,057] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:48:54,058] {logging_mixin.py:109} INFO - [2022-04-07 23:48:54,058] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:48:55,001] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:48:55,034] {logging_mixin.py:109} INFO - [2022-04-07 23:48:55,033] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:48:55,063] {logging_mixin.py:109} INFO - [2022-04-07 23:48:55,063] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:48:55,074] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.024 seconds
[2022-04-07 23:49:25,185] {processor.py:163} INFO - Started process (PID=14771) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:49:25,187] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:49:25,188] {logging_mixin.py:109} INFO - [2022-04-07 23:49:25,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:49:26,131] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:49:26,157] {logging_mixin.py:109} INFO - [2022-04-07 23:49:26,157] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:49:26,178] {logging_mixin.py:109} INFO - [2022-04-07 23:49:26,178] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:49:26,190] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.009 seconds
[2022-04-07 23:49:56,324] {processor.py:163} INFO - Started process (PID=14799) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:49:56,326] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:49:56,327] {logging_mixin.py:109} INFO - [2022-04-07 23:49:56,327] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:49:57,216] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:49:57,242] {logging_mixin.py:109} INFO - [2022-04-07 23:49:57,242] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:49:57,263] {logging_mixin.py:109} INFO - [2022-04-07 23:49:57,263] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:49:57,277] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.958 seconds
[2022-04-07 23:50:27,426] {processor.py:163} INFO - Started process (PID=14837) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:50:27,429] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:50:27,430] {logging_mixin.py:109} INFO - [2022-04-07 23:50:27,430] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:50:28,362] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:50:28,388] {logging_mixin.py:109} INFO - [2022-04-07 23:50:28,388] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:50:28,411] {logging_mixin.py:109} INFO - [2022-04-07 23:50:28,411] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:50:28,423] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 1.003 seconds
[2022-04-07 23:50:58,558] {processor.py:163} INFO - Started process (PID=14864) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:50:58,560] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:50:58,560] {logging_mixin.py:109} INFO - [2022-04-07 23:50:58,560] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:50:59,479] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:50:59,507] {logging_mixin.py:109} INFO - [2022-04-07 23:50:59,506] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:50:59,527] {logging_mixin.py:109} INFO - [2022-04-07 23:50:59,527] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:50:59,538] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.985 seconds
[2022-04-07 23:51:29,678] {processor.py:163} INFO - Started process (PID=14902) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:51:29,680] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:51:29,681] {logging_mixin.py:109} INFO - [2022-04-07 23:51:29,681] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:51:30,550] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:51:30,574] {logging_mixin.py:109} INFO - [2022-04-07 23:51:30,574] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:51:30,594] {logging_mixin.py:109} INFO - [2022-04-07 23:51:30,593] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:51:30,603] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.930 seconds
[2022-04-07 23:52:00,728] {processor.py:163} INFO - Started process (PID=14930) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:52:00,730] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:52:00,731] {logging_mixin.py:109} INFO - [2022-04-07 23:52:00,731] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:52:01,640] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:52:01,665] {logging_mixin.py:109} INFO - [2022-04-07 23:52:01,665] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:52:01,686] {logging_mixin.py:109} INFO - [2022-04-07 23:52:01,686] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:52:01,697] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.975 seconds
[2022-04-07 23:52:31,807] {processor.py:163} INFO - Started process (PID=14969) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:52:31,809] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:52:31,810] {logging_mixin.py:109} INFO - [2022-04-07 23:52:31,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:52:32,656] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:52:32,679] {logging_mixin.py:109} INFO - [2022-04-07 23:52:32,678] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:52:32,698] {logging_mixin.py:109} INFO - [2022-04-07 23:52:32,698] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:52:32,708] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.906 seconds
[2022-04-07 23:53:02,811] {processor.py:163} INFO - Started process (PID=14998) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:53:02,812] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:53:02,813] {logging_mixin.py:109} INFO - [2022-04-07 23:53:02,813] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:53:03,691] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:53:03,713] {logging_mixin.py:109} INFO - [2022-04-07 23:53:03,713] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:53:03,733] {logging_mixin.py:109} INFO - [2022-04-07 23:53:03,733] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:53:03,742] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.937 seconds
[2022-04-07 23:53:33,847] {processor.py:163} INFO - Started process (PID=15039) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:53:33,849] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:53:33,850] {logging_mixin.py:109} INFO - [2022-04-07 23:53:33,850] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:53:34,740] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:53:34,763] {logging_mixin.py:109} INFO - [2022-04-07 23:53:34,763] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:53:34,783] {logging_mixin.py:109} INFO - [2022-04-07 23:53:34,783] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:53:34,793] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.952 seconds
[2022-04-07 23:54:04,898] {processor.py:163} INFO - Started process (PID=15067) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:54:04,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:54:04,901] {logging_mixin.py:109} INFO - [2022-04-07 23:54:04,901] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:54:05,745] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:54:05,767] {logging_mixin.py:109} INFO - [2022-04-07 23:54:05,767] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:54:05,785] {logging_mixin.py:109} INFO - [2022-04-07 23:54:05,785] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:54:05,795] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.901 seconds
[2022-04-07 23:54:35,900] {processor.py:163} INFO - Started process (PID=15103) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:54:35,902] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:54:35,903] {logging_mixin.py:109} INFO - [2022-04-07 23:54:35,903] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:54:36,751] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:54:36,775] {logging_mixin.py:109} INFO - [2022-04-07 23:54:36,775] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:54:36,795] {logging_mixin.py:109} INFO - [2022-04-07 23:54:36,794] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:54:36,806] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.913 seconds
[2022-04-07 23:55:06,915] {processor.py:163} INFO - Started process (PID=15132) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:55:06,917] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:55:06,918] {logging_mixin.py:109} INFO - [2022-04-07 23:55:06,918] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:55:07,767] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:55:07,789] {logging_mixin.py:109} INFO - [2022-04-07 23:55:07,789] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:55:07,810] {logging_mixin.py:109} INFO - [2022-04-07 23:55:07,810] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:55:07,820] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.913 seconds
[2022-04-07 23:55:37,927] {processor.py:163} INFO - Started process (PID=15169) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:55:37,930] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:55:37,931] {logging_mixin.py:109} INFO - [2022-04-07 23:55:37,931] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:55:38,807] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:55:38,830] {logging_mixin.py:109} INFO - [2022-04-07 23:55:38,830] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:55:38,851] {logging_mixin.py:109} INFO - [2022-04-07 23:55:38,850] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:55:38,860] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.938 seconds
[2022-04-07 23:56:08,967] {processor.py:163} INFO - Started process (PID=15198) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:56:08,969] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:56:08,970] {logging_mixin.py:109} INFO - [2022-04-07 23:56:08,970] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:56:09,821] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:56:09,848] {logging_mixin.py:109} INFO - [2022-04-07 23:56:09,848] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:56:09,871] {logging_mixin.py:109} INFO - [2022-04-07 23:56:09,871] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:56:09,887] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.925 seconds
[2022-04-07 23:56:39,985] {processor.py:163} INFO - Started process (PID=15236) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:56:39,988] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:56:39,989] {logging_mixin.py:109} INFO - [2022-04-07 23:56:39,989] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:56:40,888] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:56:40,911] {logging_mixin.py:109} INFO - [2022-04-07 23:56:40,911] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:56:40,931] {logging_mixin.py:109} INFO - [2022-04-07 23:56:40,931] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:56:40,944] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.964 seconds
[2022-04-07 23:57:11,045] {processor.py:163} INFO - Started process (PID=15265) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:57:11,047] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:57:11,048] {logging_mixin.py:109} INFO - [2022-04-07 23:57:11,047] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:57:11,912] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:57:11,936] {logging_mixin.py:109} INFO - [2022-04-07 23:57:11,935] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:57:11,956] {logging_mixin.py:109} INFO - [2022-04-07 23:57:11,956] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:57:11,966] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.926 seconds
[2022-04-07 23:57:42,067] {processor.py:163} INFO - Started process (PID=15303) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:57:42,069] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:57:42,070] {logging_mixin.py:109} INFO - [2022-04-07 23:57:42,070] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:57:42,938] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:57:42,962] {logging_mixin.py:109} INFO - [2022-04-07 23:57:42,962] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:57:42,983] {logging_mixin.py:109} INFO - [2022-04-07 23:57:42,983] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:57:42,995] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 23:58:13,097] {processor.py:163} INFO - Started process (PID=15330) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:58:13,100] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:58:13,101] {logging_mixin.py:109} INFO - [2022-04-07 23:58:13,101] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:58:13,957] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:58:13,982] {logging_mixin.py:109} INFO - [2022-04-07 23:58:13,981] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:58:14,001] {logging_mixin.py:109} INFO - [2022-04-07 23:58:14,001] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:58:14,011] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.920 seconds
[2022-04-07 23:58:44,127] {processor.py:163} INFO - Started process (PID=15368) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:58:44,130] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:58:44,131] {logging_mixin.py:109} INFO - [2022-04-07 23:58:44,130] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:58:44,983] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:58:45,007] {logging_mixin.py:109} INFO - [2022-04-07 23:58:45,007] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:58:45,027] {logging_mixin.py:109} INFO - [2022-04-07 23:58:45,027] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:58:45,037] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.914 seconds
[2022-04-07 23:59:15,152] {processor.py:163} INFO - Started process (PID=15396) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:59:15,155] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:59:15,156] {logging_mixin.py:109} INFO - [2022-04-07 23:59:15,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:59:16,025] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:59:16,048] {logging_mixin.py:109} INFO - [2022-04-07 23:59:16,047] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:59:16,068] {logging_mixin.py:109} INFO - [2022-04-07 23:59:16,067] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:59:16,079] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.934 seconds
[2022-04-07 23:59:46,190] {processor.py:163} INFO - Started process (PID=15435) to work on /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:59:46,193] {processor.py:642} INFO - Processing file /opt/airflow/dags/load_to_BigQuery_dag.py for tasks to queue
[2022-04-07 23:59:46,193] {logging_mixin.py:109} INFO - [2022-04-07 23:59:46,193] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:59:47,043] {processor.py:652} INFO - DAG(s) dict_keys(['load_to_BigQuery']) retrieved from /opt/airflow/dags/load_to_BigQuery_dag.py
[2022-04-07 23:59:47,068] {logging_mixin.py:109} INFO - [2022-04-07 23:59:47,067] {dag.py:2398} INFO - Sync 1 DAGs
[2022-04-07 23:59:47,090] {logging_mixin.py:109} INFO - [2022-04-07 23:59:47,090] {dag.py:2937} INFO - Setting next_dagrun for load_to_BigQuery to 2022-04-01T00:00:00+00:00
[2022-04-07 23:59:47,102] {processor.py:171} INFO - Processing /opt/airflow/dags/load_to_BigQuery_dag.py took 0.918 seconds
